# -*- coding: utf-8 -*-
"""Copy of Copy of EVA_4_S15_A_Final_Mask_Depth_T1_depth.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-LHhVsGym-Dkdo5RNzTx6lg1mBPKS-Te

# Assignment 15 - Final

### Summary
- Create dataset 
  - Only background (bg)
  - Background + Foreground (bg_fg)
  - Foreground Mask (fg_mask)
- Load Dataset
- Display sample images 
- Create Network
- Train Model
- Display Images
"""

import torch
from IPython.display import Image, clear_output 

print('PyTorch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))

"""### 1. Mount google drive"""

# Load data from Google drive
from google.colab import drive
drive.mount('/content/drive')

"""### 2. Load helper library

- autotime : Prints cell execution time
- torchsummary : Prints model summary
- hiddenlayer: Print Model graph
- torchviz : Visualize model
- tensorboard : Tensorboard for visualizaton
- tensorboardX : Pytorch tensorboard
"""

# Commented out IPython magic to ensure Python compatibility.
# Library to print cell execution time
!pip install ipython-autotime
# %load_ext autotime

!pip install torchsummary

!pip install hiddenlayer

!pip install torchviz

!pip install tensorboard

!pip install tensorboardx

"""### 3. Set the directory path of google drive"""

import sys

sys.path.append('/content/drive/My Drive/eva-4/assignment-15')
sys.path.append('/content/drive/My Drive/eva-4/assignment-15/assignemnt-15-final')
sys.path.append('/content/drive/My Drive/eva-4/assignment-15/assignemnt-15-final/trial-1')
sys.path.append('/content/drive/My Drive/eva-4/assignment-15/assignemnt-15-final/trial-1/dataset')
sys.path.append('/content/drive/My Drive/eva-4/assignment-15/assignemnt-15-final/trial-1/dataset/bg')
sys.path.append('/content/drive/My Drive/eva-4/assignment-15/assignemnt-15-final/trial-1/dataset/bg_fg')
sys.path.append('/content/drive/My Drive/eva-4/assignment-15/assignemnt-15-final/trial-1/dataset/bg_fg_mask')

cd '/content/drive/My Drive/eva-4/assignment-15/assignment-15-final'

!ls

"""### 4. Load and Import all modules and libraries"""

import numpy as np
import matplotlib.pyplot as plt
import torch
import torch.nn as nn
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms

from torchvision.utils import make_grid
from torchsummary import summary

# New 
from torchvision import models

"""### 5. Hyperparameters : TODO - Move it to config file"""

# Define hyper paramteres and constants
EPOCHS=10
trainaccuracies = []
trainlosses = []
testlosses = []
testaccuracies = []
lr_values = []

"""### 4. Set Device"""

use_cuda = torch.cuda.is_available()
device = torch.device("cuda" if use_cuda else "cpu")
print(device)

"""###  5. Import all the functions"""



"""###  6. Load Transformations"""

import torchvision
import torchvision.transforms as transforms

def transformations():
    transform_train = transforms.Compose([
        # transforms.RandomCrop(32, padding=4),
        # transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
    ])

    transform_test = transforms.Compose([
        transforms.ToTensor(),
        # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),
    ])

    return (transform_train, transform_test)

"""###  7. Load Dataset"""

'''from pathlib import Path

# Set the dataset root path
data_root = Path('/content/drive/My Drive/eva-4/assignment-15/assignment-15-final/trial-1/dataset')
print('Dataset: {}'.format(data_root))

# Set path for various dataset
bg, bg_fg, masks, depths = data_root/'bg', data_root/'bg_fg', data_root/'masks', data_root/'depths'

print('Background images: {}'.format(len(list(bg.iterdir()))))
print('Background and Foreground images: {}'.format(len(list(bg_fg.iterdir()))))
print('Masks: {}'.format(len(list(masks.iterdir()))))
print('Depth maps: {}'.format(len(list(depths.iterdir()))))'''

from pathlib import Path

# Set the dataset root path
data_root = Path('/content/drive/My Drive/eva-4/assignment-15/asssignment-15-A/s_ds/extracted_partial')
print('Dataset: {}'.format(data_root))

# Set path for various dataset
bg, bg_fg, depths = data_root/'bg', data_root/'bg_fg', data_root/'depths'

print('Background and Foreground images: {}'.format(len(list(bg_fg.iterdir()))))
print('Masks: {}'.format(len(list(depths.iterdir()))))

"""##### Copy 500 images"""

# !bash -c 'cp /content/drive/My\ Drive/eva-4/assignment-15/asssignment-15-A/s_ds/extracted/output_0/bg_fg_1/1_bg_{1..500}_fg.jpg /content/drive/My\ Drive/eva-4/assignment-15/asssignment-15-A/s_ds/extracted_partial/bg_fg'
# !ls '/content/drive/My Drive/eva-4/assignment-15/asssignment-15-A/s_ds/extracted_partial/bg_fg' | wc -l

# !bash -c 'cp /content/drive/My\ Drive/eva-4/assignment-15/asssignment-15-A/s_ds/extracted/output_0/bg_fg_mask_1/1_bg_{1..500}_fg.jpg /content/drive/My\ Drive/eva-4/assignment-15/asssignment-15-A/s_ds/extracted_partial/masks'
# !ls '/content/drive/My Drive/eva-4/assignment-15/asssignment-15-A/s_ds/extracted_partial/masks' | wc -l

"""#### Prepare dataset : 500 images of 64 x 64"""

# Copy bg_fg
# !cp -R /content/drive/My\ Drive/eva-4/assignment-15/asssignment-15-A/s_ds/extracted_partial/bg_fg /content/drive/My\ Drive/eva-4/assignment-15/asssignment-15-A/s_ds/extracted_partial/64x64/bg_fg
# !ls '/content/drive/My Drive/eva-4/assignment-15/asssignment-15-A/s_ds/extracted_partial/64x64/bg_fg' | wc -l

# Copy masks
# !cp -R /content/drive/My\ Drive/eva-4/assignment-15/asssignment-15-A/s_ds/extracted_partial/masks /content/drive/My\ Drive/eva-4/assignment-15/asssignment-15-A/s_ds/extracted_partial/64x64
# !ls '/content/drive/My Drive/eva-4/assignment-15/asssignment-15-A/s_ds/extracted_partial/64x64/masks' | wc -l

# Copy depths
# !bash -c 'cp -n /content/drive/My\ Drive/eva-4/assignment-15/asssignment-15-A/s_ds/src/DenseDepth/depthMapOutput_0_1_2/1_bg_{1..500}_fg.jpg /content/drive/My\ Drive/eva-4/assignment-15/asssignment-15-A/s_ds/extracted_partial/64x64/depths'
#!ls '/content/drive/My Drive/eva-4/assignment-15/asssignment-15-A/s_ds/extracted_partial/64x64/depths' | wc -l

import os
from PIL import Image
os.getcwd()

# Resize to 64 x 64
'''os.chdir('/content/drive/My Drive/eva-4/assignment-15/asssignment-15-A/s_ds/extracted_partial/64x64/depths')
for im in os.listdir('.'):
    if im.endswith('.jpg'):
      print(im)
      img = Image.open(im)
      print(img.size)
      # img = img.convert('L')
      img = img.resize((64,64), Image.ANTIALIAS)
      img.save(im)'''

"""#### Perform transformations and load dataset"""

transform_train, transform_test = transformations()

from torch.utils.data import Dataset
from torchvision.transforms import transforms
from PIL import Image

class ImageDataset(Dataset):
  def __init__(self, root):
    self.bg_fg_files = list(bg_fg.glob('*.jpg'))
    self.depths_files = list(depths.glob('*.jpg'))

    self.transfrm = transform_train
    
  def __len__(self):
    return len(self.bg_fg_files)

  def __getitem__(self, index):
    bg_fg_img = self.transfrm(Image.open(self.bg_fg_files[index]))
    depth_img = self.transfrm(Image.open(self.depths_files[index]))

    return {'bg_fg': bg_fg_img, 'depth': depth_img}

from torch.utils.data import DataLoader

trainset = ImageDataset(data_root)

trainloader = DataLoader(trainset, batch_size = 16, shuffle =True, pin_memory=True)

"""###  8. Load Classes

### 9. Display sample images
"""

sample = next(iter(trainloader))

images = sample['bg_fg']
depths = sample['depth']

print(images.shape)
print(depths.shape)

import torchvision

def show(tensors, figsize=(10, 10), *args, **kwargs):
  grid_tensor = torchvision.utils.make_grid(tensors, *args, **kwargs)
  grid_image = grid_tensor.permute(1,2,0)
  plt.figure(figsize=figsize)
  plt.imshow(grid_image)
  plt.xticks([])
  plt.yticks([])
  plt.show()

def draw_and_save(tensors, name, figsize=(20,20), *args, **kwargs):
  try:
    tensors = tensors.detach().cpu()
  except:
    pass
  grid_tensor = torchvision.utils.make_grid(tensors, *args, **kwargs)
  grid_image = grid_tensor.permute(1, 2, 0)
  plt.figure(figsize=figsize)
  plt.imshow(grid_image)
  plt.xticks([])
  plt.yticks([])

  plt.savefig(name, bbox_inches='tight')
  plt.close()

show(images)

show(depths)

"""###### Sample Training Images

###### Sample Test Images

### 10. Load Model

#### Define Model

##### U-Net
"""

import torch
import torch.nn as nn

def double_conv(in_channels, out_channels):
    return nn.Sequential(
        nn.Conv2d(in_channels, out_channels, 3, padding=1),
        nn.ReLU(inplace=True),
        nn.Conv2d(out_channels, out_channels, 3, padding=1),
        nn.ReLU(inplace=True)
    )   


class UNet(nn.Module):

    def __init__(self, n_class):
        super().__init__()
                
        self.dconv_down1 = double_conv(3, 64)
        self.dconv_down2 = double_conv(64, 128)
        self.dconv_down3 = double_conv(128, 256)
        self.dconv_down4 = double_conv(256, 512)        

        self.maxpool = nn.MaxPool2d(2)
        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)        
        
        self.dconv_up3 = double_conv(256 + 512, 256)
        self.dconv_up2 = double_conv(128 + 256, 128)
        self.dconv_up1 = double_conv(128 + 64, 64)
        
        self.conv_last = nn.Conv2d(64, n_class, 1)

        self.sigmoid = nn.Sigmoid()        
        
    def forward(self, sample):
        bgfgs = sample['bg_fg']

        conv1 = self.dconv_down1(bgfgs)
        x = self.maxpool(conv1)

        conv2 = self.dconv_down2(x)
        x = self.maxpool(conv2)
        
        conv3 = self.dconv_down3(x)
        x = self.maxpool(conv3)   
        
        x = self.dconv_down4(x)
        
        x = self.upsample(x)        
        x = torch.cat([x, conv3], dim=1)
        
        x = self.dconv_up3(x)
        x = self.upsample(x)        
        x = torch.cat([x, conv2], dim=1)       

        x = self.dconv_up2(x)
        x = self.upsample(x)        
        x = torch.cat([x, conv1], dim=1)   
        
        x = self.dconv_up1(x)
        x = self.sigmoid(x)
        out = self.conv_last(x)
        
        return out

# Custom Model

class CustomModel(nn.Module):

    def __init__(self):
      super(CustomModel, self).__init__()

      self.convBlock1 = nn.Sequential(
          nn.Conv2d(3, 32, 3, stride=1, padding=1, bias=False),
          nn.BatchNorm2d(32),
          nn.ReLU()
      )

      self.convBlock2 = nn.Sequential(
          nn.Conv2d(32, 32, 3, stride=1, padding=1, bias=False, groups=32),
          nn.Conv2d(32, 64, 1, stride=1, padding=0, bias=False),
          nn.BatchNorm2d(64),
          nn.ReLU()
      )

      self.convBlock3 = nn.Sequential(
          nn.Conv2d(64, 128, 3, stride=1, padding=1, bias=False),
          nn.BatchNorm2d(128),
          nn.ReLU()
      )

      self.convBlock4 = nn.Sequential(
          nn.Conv2d(128, 3, 3, stride=1, padding=1, bias=False),
      )

      self.conv1x1 = nn.Sequential(
          nn.Conv2d(3, 1, 1, stride=1, padding=0, bias=False),
      )

    def forward(self, sample):
          bgfgs = sample['bg_fg']

          f1 = self.convBlock4(self.convBlock3(self.convBlock2(self.convBlock1(bgfgs))))
          # f1 = self.conv1x1(f1)
          print(f1.shape)
          # f2 = self.convBlock4(self.convBlock3(self.convBlock2(self.convBlock1(bgfgs))))
          # f2 = self.conv1x1(f2)
          # print(f2.shape)
          return f1

print("Building Model")
net = CustomModel()
# net = UNet(1)

# Display Model Summary
model = net.to(device)

"""### 11. Define loss function and optimizer"""

criterion = nn.BCEWithLogitsLoss() #SSIM( 3, reduction ="mean")

optimizer = torch.optim.SGD(model.parameters(),lr= 0.01, momentum=0.9, weight_decay=1e-5)

"""### 12. Train Model"""

# Commented out IPython magic to ensure Python compatibility.
# ONLY MASK

# %matplotlib inline
import matplotlib.pyplot as plt
from tqdm import tqdm

def train(model,criterion,device,trainloader,optimizer,epoch):
  model.train()
  # pbar = tqdm(trainloader)
  for batch_idx, data in enumerate(trainloader):
    data["bg_fg"] = data["bg_fg"].to(device)
    data["depth"] = data["depth"].to(device)
    
    optimizer.zero_grad()
    output = model(data)
    loss = criterion(output,data["depth"])
    loss.backward()
    optimizer.step()

    if batch_idx %50 == 0 or epoch %10 == 0:
      print('Train Epoch: {}  [{}/{}  ({:.0f}%)]\tLoss:{:.6f}'.format(
          epoch,batch_idx*len(data),len(trainloader.dataset),
          100.*batch_idx/len(trainloader),loss.item()))
      
      print('loss: {}'.format(loss))
      # Mask
      print("\n\nActual depth")
      show(data['depth'].detach().cpu())
      print("\n\nPredicted depth")
      show(output.detach().cpu())

# train(model, criterion, device, trainloader, optimizer, epoch=1)

for epoch in range(1, 100):
    print('Training Epoch: {}'.format(epoch))
    train(model, criterion, device, trainloader, optimizer, epoch=epoch)































