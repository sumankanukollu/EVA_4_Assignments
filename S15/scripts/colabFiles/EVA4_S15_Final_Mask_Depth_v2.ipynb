{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "EVA4_S15_Final_Mask_Depth_v1.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "R3jaGHP4hh0q"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9K0vx-1EfSLX",
        "colab_type": "text"
      },
      "source": [
        "# Hardware details"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PtWeRI9vSrmq",
        "colab_type": "code",
        "outputId": "783fe463-d5b5-48e8-8044-b81b1e8f9569",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "import torch\n",
        "from IPython.display import Image, clear_output \n",
        "\n",
        "print('PyTorch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "PyTorch 1.5.0+cu101 _CudaDeviceProperties(name='Tesla P100-PCIE-16GB', major=6, minor=0, total_memory=16280MB, multi_processor_count=56)\n",
            "time: 1.88 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2oecG2ydhWcR",
        "colab_type": "code",
        "outputId": "54d2e596-a41b-495e-d283-06a30bb4099d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        }
      },
      "source": [
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.6/dist-packages (0.1)\n",
            "The autotime extension is already loaded. To reload it, use:\n",
            "  %reload_ext autotime\n",
            "time: 5.08 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IVwU7nl8fW1y",
        "colab_type": "text"
      },
      "source": [
        "# Upload modified files to Google Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CaneomQHYkbU",
        "colab_type": "code",
        "outputId": "84111807-a99e-42d5-9b9d-491143948b7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from pathlib import Path\n",
        "import os ,sys, gc ,tarfile ,zipfile,pickle\n",
        "from google.colab import files"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "time: 1.94 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QGGvlKc-hPt5",
        "colab_type": "code",
        "outputId": "340804e5-97a0-413d-b08e-72805bb602dc",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "os.chdir('/content/drive/My Drive/EVA4/S15/scripts/pythonFiles')\n",
        "\n",
        "if os.path.exists('train_mask_depth.py'):\n",
        "    os.remove('train_mask_depth.py')\n",
        "src = list(files.upload().values())[0]\n",
        "open('train_mask_depth.py','wb').write(src)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-dab78f36-9688-431f-9f13-ea3922761a39\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-dab78f36-9688-431f-9f13-ea3922761a39\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving train_mask_depth.py to train_mask_depth.py\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15428"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        },
        {
          "output_type": "stream",
          "text": [
            "time: 10.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "5c91df6d-4ae2-4eea-dcdf-6ec5b27023db",
        "id": "LsbzUj2_cIn5",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "os.chdir('/content/drive/My Drive/EVA4/S15/scripts/pythonFiles')\n",
        "\n",
        "if os.path.exists('model.py'):\n",
        "    os.remove('model.py')\n",
        "src = list(files.upload().values())[0]\n",
        "open('model.py','wb').write(src)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9ef594de-6b0e-49e0-a9cd-c92c90f1e329\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-9ef594de-6b0e-49e0-a9cd-c92c90f1e329\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving model.py to model.py\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5493"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        },
        {
          "output_type": "stream",
          "text": [
            "time: 11.1 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "N8lxSoNdaH35",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "os.chdir('/content/drive/My Drive/EVA4/S15/utils/')\n",
        "\n",
        "if os.path.exists('tfms.py'):\n",
        "    os.remove('tfms.py')\n",
        "src = list(files.upload().values())[0]\n",
        "open('tfms.py','wb').write(src)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4IFProSfpQi",
        "colab_type": "text"
      },
      "source": [
        "# Batch_1 dataset : \n",
        "        Dataset size : 30K\n",
        "            - Train (70%)  : 21K  \n",
        "            - Test  (30%)  : 9K\n",
        "        Batch Size   : 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OeDb7AWMeWs",
        "colab_type": "code",
        "outputId": "b9446fcc-7f89-49a2-fa23-86df7cf3f9ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "os.chdir(r'/content/drive/My Drive/EVA4/S15/scripts/pythonFiles')\n",
        "!python train_mask_depth.py -z '/content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_1.zip' -e 5  -bs 50"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are executing model on : cuda\n",
            "Dataset using : /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_1.zip\n",
            "Train Dataset : 21000\n",
            "Test Dataset : 9000\n",
            "\t In batch size of : 50\n",
            "cuda\n",
            "Loading model : batch_best.ckp.pt\n",
            "Model is loaded\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]          18,816\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "   ConvTranspose2d-5        [-1, 128, 111, 111]           8,192\n",
            "            Conv2d-6          [-1, 128, 28, 28]          73,728\n",
            "            Conv2d-7          [-1, 128, 28, 28]          16,384\n",
            "       BatchNorm2d-8          [-1, 128, 28, 28]             256\n",
            "              ReLU-9          [-1, 128, 28, 28]               0\n",
            "           Conv2d-10          [-1, 128, 14, 14]         147,456\n",
            "           Conv2d-11          [-1, 128, 14, 14]          16,384\n",
            "      BatchNorm2d-12          [-1, 128, 14, 14]             256\n",
            "             ReLU-13          [-1, 128, 14, 14]               0\n",
            "         Downsize-14          [-1, 128, 14, 14]               0\n",
            "  ConvTranspose2d-15          [-1, 256, 27, 27]          32,768\n",
            "           Conv2d-16            [-1, 256, 7, 7]         294,912\n",
            "           Conv2d-17            [-1, 256, 7, 7]          65,536\n",
            "      BatchNorm2d-18            [-1, 256, 7, 7]             512\n",
            "             ReLU-19            [-1, 256, 7, 7]               0\n",
            "           Conv2d-20            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-21            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-22            [-1, 256, 4, 4]             512\n",
            "             ReLU-23            [-1, 256, 4, 4]               0\n",
            "         Downsize-24            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-25            [-1, 512, 7, 7]         131,072\n",
            "           Conv2d-26            [-1, 512, 2, 2]       1,179,648\n",
            "           Conv2d-27            [-1, 512, 2, 2]         262,144\n",
            "      BatchNorm2d-28            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-29            [-1, 512, 2, 2]               0\n",
            "           Conv2d-30            [-1, 512, 1, 1]       2,359,296\n",
            "           Conv2d-31            [-1, 512, 1, 1]         262,144\n",
            "      BatchNorm2d-32            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-33            [-1, 512, 1, 1]               0\n",
            "         Downsize-34            [-1, 512, 1, 1]               0\n",
            "  ConvTranspose2d-35            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-36            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-37            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-38            [-1, 256, 4, 4]             512\n",
            "             ReLU-39            [-1, 256, 4, 4]               0\n",
            "           Conv2d-40            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-41            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-42            [-1, 256, 4, 4]             512\n",
            "             ReLU-43            [-1, 256, 4, 4]               0\n",
            "           Upsize-44            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-45          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-46          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-47          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-48          [-1, 128, 28, 28]             256\n",
            "             ReLU-49          [-1, 128, 28, 28]               0\n",
            "           Conv2d-50          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-51          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-52          [-1, 128, 28, 28]             256\n",
            "             ReLU-53          [-1, 128, 28, 28]               0\n",
            "           Upsize-54          [-1, 128, 28, 28]               0\n",
            "  ConvTranspose2d-55           [-1, 64, 56, 56]          73,728\n",
            "           Conv2d-56           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-57           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-58           [-1, 64, 56, 56]             128\n",
            "             ReLU-59           [-1, 64, 56, 56]               0\n",
            "           Conv2d-60           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-61           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-62           [-1, 64, 56, 56]             128\n",
            "             ReLU-63           [-1, 64, 56, 56]               0\n",
            "           Upsize-64           [-1, 64, 56, 56]               0\n",
            "  ConvTranspose2d-65         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-66         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-67         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-68         [-1, 64, 112, 112]             128\n",
            "             ReLU-69         [-1, 64, 112, 112]               0\n",
            "           Conv2d-70         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-71         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-72         [-1, 64, 112, 112]             128\n",
            "             ReLU-73         [-1, 64, 112, 112]               0\n",
            "           Upsize-74         [-1, 64, 112, 112]               0\n",
            "  ConvTranspose2d-75         [-1, 32, 224, 224]          18,432\n",
            "           Conv2d-76         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-77         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-78         [-1, 32, 224, 224]              64\n",
            "             ReLU-79         [-1, 32, 224, 224]               0\n",
            "           Conv2d-80         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-81         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-82         [-1, 32, 224, 224]              64\n",
            "             ReLU-83         [-1, 32, 224, 224]               0\n",
            "           Upsize-84         [-1, 32, 224, 224]               0\n",
            "           Conv2d-85          [-1, 1, 224, 224]              32\n",
            "  ConvTranspose2d-86            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-87            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-88            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-89            [-1, 256, 4, 4]             512\n",
            "             ReLU-90            [-1, 256, 4, 4]               0\n",
            "           Conv2d-91            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-92            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-93            [-1, 256, 4, 4]             512\n",
            "             ReLU-94            [-1, 256, 4, 4]               0\n",
            "           Upsize-95            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-96          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-97          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-98          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-99          [-1, 128, 28, 28]             256\n",
            "            ReLU-100          [-1, 128, 28, 28]               0\n",
            "          Conv2d-101          [-1, 128, 28, 28]         147,456\n",
            "          Conv2d-102          [-1, 128, 28, 28]          16,384\n",
            "     BatchNorm2d-103          [-1, 128, 28, 28]             256\n",
            "            ReLU-104          [-1, 128, 28, 28]               0\n",
            "          Upsize-105          [-1, 128, 28, 28]               0\n",
            " ConvTranspose2d-106           [-1, 64, 56, 56]          73,728\n",
            "          Conv2d-107           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-108           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-109           [-1, 64, 56, 56]             128\n",
            "            ReLU-110           [-1, 64, 56, 56]               0\n",
            "          Conv2d-111           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-112           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-113           [-1, 64, 56, 56]             128\n",
            "            ReLU-114           [-1, 64, 56, 56]               0\n",
            "          Upsize-115           [-1, 64, 56, 56]               0\n",
            " ConvTranspose2d-116         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-117         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-118         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-119         [-1, 64, 112, 112]             128\n",
            "            ReLU-120         [-1, 64, 112, 112]               0\n",
            "          Conv2d-121         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-122         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-123         [-1, 64, 112, 112]             128\n",
            "            ReLU-124         [-1, 64, 112, 112]               0\n",
            "          Upsize-125         [-1, 64, 112, 112]               0\n",
            " ConvTranspose2d-126         [-1, 32, 224, 224]          18,432\n",
            "          Conv2d-127         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-128         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-129         [-1, 32, 224, 224]              64\n",
            "            ReLU-130         [-1, 32, 224, 224]               0\n",
            "          Conv2d-131         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-132         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-133         [-1, 32, 224, 224]              64\n",
            "            ReLU-134         [-1, 32, 224, 224]               0\n",
            "          Upsize-135         [-1, 32, 224, 224]               0\n",
            "          Conv2d-136          [-1, 3, 224, 224]              99\n",
            "================================================================\n",
            "Total params: 12,384,643\n",
            "Trainable params: 12,384,643\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.15\n",
            "Forward/backward pass size (MB): 453.79\n",
            "Params size (MB): 47.24\n",
            "Estimated Total Size (MB): 502.18\n",
            "----------------------------------------------------------------\n",
            "You are running /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_1.zip dataset for 5 epochs\n",
            "EPOCH: 1\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3237 Mask loss=0.01 Depth loss=0.29:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3237420618534088\n",
            "Train Epoch: 1  [0/7000  (0%)]\tLoss:0.323742\n",
            "Overall Loss=0.3257 Mask loss=0.01 Depth loss=0.30:  36% 50/140 [00:35<01:00,  1.50it/s]batch_idx: 50\n",
            "loss: 0.3256778419017792\n",
            "Train Epoch: 1  [200/7000  (36%)]\tLoss:0.325678\n",
            "Overall Loss=0.3244 Mask loss=0.02 Depth loss=0.29:  71% 100/140 [01:09<00:26,  1.52it/s]batch_idx: 100\n",
            "loss: 0.32440775632858276\n",
            "Train Epoch: 1  [400/7000  (71%)]\tLoss:0.324408\n",
            "Overall Loss=0.3261 Mask loss=0.01 Depth loss=0.30: 100% 140/140 [01:35<00:00,  1.46it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Validation loss decreased (100000.000000 --> 0.326144).  Saving model ...\n",
            "Model saved\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3681779205799103\n",
            " 83% 50/60 [00:32<00:06,  1.55it/s]batch_idx: 50\n",
            "loss: 0.36107783392071724\n",
            "100% 60/60 [00:38<00:00,  1.56it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3657, Mask Loss: 0.03, Depth Loss: 0.31\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "EPOCH: 2\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3246 Mask loss=0.01 Depth loss=0.30:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.32464656233787537\n",
            "Train Epoch: 2  [0/7000  (0%)]\tLoss:0.324647\n",
            "Overall Loss=0.3286 Mask loss=0.01 Depth loss=0.30:  36% 50/140 [00:34<01:01,  1.47it/s]batch_idx: 50\n",
            "loss: 0.32860851287841797\n",
            "Train Epoch: 2  [200/7000  (36%)]\tLoss:0.328609\n",
            "Overall Loss=0.3237 Mask loss=0.01 Depth loss=0.29:  71% 100/140 [01:08<00:26,  1.50it/s]batch_idx: 100\n",
            "loss: 0.3237040936946869\n",
            "Train Epoch: 2  [400/7000  (71%)]\tLoss:0.323704\n",
            "Overall Loss=0.3213 Mask loss=0.01 Depth loss=0.29: 100% 140/140 [01:34<00:00,  1.48it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Validation loss decreased (0.326144 --> 0.321278).  Saving model ...\n",
            "Model saved\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.37166009098291397\n",
            " 83% 50/60 [00:32<00:06,  1.59it/s]batch_idx: 50\n",
            "loss: 0.37267135828733444\n",
            "100% 60/60 [00:38<00:00,  1.55it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3720, Mask Loss: 0.03, Depth Loss: 0.31\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "EPOCH: 3\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3195 Mask loss=0.01 Depth loss=0.29:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3195055425167084\n",
            "Train Epoch: 3  [0/7000  (0%)]\tLoss:0.319506\n",
            "Overall Loss=0.3222 Mask loss=0.01 Depth loss=0.29:  36% 50/140 [00:34<01:00,  1.49it/s]batch_idx: 50\n",
            "loss: 0.32216382026672363\n",
            "Train Epoch: 3  [200/7000  (36%)]\tLoss:0.322164\n",
            "Overall Loss=0.3246 Mask loss=0.01 Depth loss=0.30:  71% 100/140 [01:08<00:26,  1.51it/s]batch_idx: 100\n",
            "loss: 0.3245973289012909\n",
            "Train Epoch: 3  [400/7000  (71%)]\tLoss:0.324597\n",
            "Overall Loss=0.3167 Mask loss=0.01 Depth loss=0.29: 100% 140/140 [01:35<00:00,  1.47it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Validation loss decreased (0.321278 --> 0.316718).  Saving model ...\n",
            "Model saved\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.35576026886701584\n",
            " 83% 50/60 [00:32<00:06,  1.56it/s]batch_idx: 50\n",
            "loss: 0.3599172569811344\n",
            "100% 60/60 [00:38<00:00,  1.55it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3555, Mask Loss: 0.03, Depth Loss: 0.30\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "EPOCH: 4\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3211 Mask loss=0.01 Depth loss=0.29:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.32114365696907043\n",
            "Train Epoch: 4  [0/7000  (0%)]\tLoss:0.321144\n",
            "Overall Loss=0.3232 Mask loss=0.01 Depth loss=0.30:  36% 50/140 [00:34<00:59,  1.51it/s]batch_idx: 50\n",
            "loss: 0.32324743270874023\n",
            "Train Epoch: 4  [200/7000  (36%)]\tLoss:0.323247\n",
            "Overall Loss=0.3161 Mask loss=0.01 Depth loss=0.29:  71% 100/140 [01:08<00:26,  1.49it/s]batch_idx: 100\n",
            "loss: 0.3160918653011322\n",
            "Train Epoch: 4  [400/7000  (71%)]\tLoss:0.316092\n",
            "Overall Loss=0.3219 Mask loss=0.01 Depth loss=0.29: 100% 140/140 [01:35<00:00,  1.47it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3518768176436424\n",
            " 83% 50/60 [00:32<00:06,  1.57it/s]batch_idx: 50\n",
            "loss: 0.35129833593964577\n",
            "100% 60/60 [00:38<00:00,  1.55it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3534, Mask Loss: 0.03, Depth Loss: 0.30\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "EPOCH: 5\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3202 Mask loss=0.01 Depth loss=0.30:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3202245235443115\n",
            "Train Epoch: 5  [0/7000  (0%)]\tLoss:0.320225\n",
            "Overall Loss=0.3219 Mask loss=0.01 Depth loss=0.30:  36% 50/140 [00:34<00:59,  1.50it/s]batch_idx: 50\n",
            "loss: 0.32191571593284607\n",
            "Train Epoch: 5  [200/7000  (36%)]\tLoss:0.321916\n",
            "Overall Loss=0.3221 Mask loss=0.01 Depth loss=0.30:  71% 100/140 [01:08<00:26,  1.52it/s]batch_idx: 100\n",
            "loss: 0.32208508253097534\n",
            "Train Epoch: 5  [400/7000  (71%)]\tLoss:0.322085\n",
            "Overall Loss=0.3219 Mask loss=0.01 Depth loss=0.30: 100% 140/140 [01:34<00:00,  1.47it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.34675799310207367\n",
            " 83% 50/60 [00:31<00:06,  1.58it/s]batch_idx: 50\n",
            "loss: 0.34653420746326447\n",
            "100% 60/60 [00:38<00:00,  1.57it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3471, Mask Loss: 0.02, Depth Loss: 0.30\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "time: 12min 39s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "R3jaGHP4hh0q"
      },
      "source": [
        "# Batch_2 dataset : \n",
        "        Dataset size : 30K\n",
        "            - Train (70%)  : 21K  \n",
        "            - Test  (30%)  : 9K\n",
        "        Batch Size   : 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9239efb6-f567-468b-d805-e8bb046a035a",
        "id": "JB-iYoZOhh0t",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "os.chdir(r'/content/drive/My Drive/EVA4/S15/scripts/pythonFiles')\n",
        "!python train_mask_depth.py -z '/content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_2.zip' -e 5  -bs 50"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are executing model on : cuda\n",
            "Dataset using : /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_2.zip\n",
            "Train Dataset : 21000\n",
            "Test Dataset : 9000\n",
            "\t In batch size of : 50\n",
            "cuda\n",
            "Loading model : batch_best.ckp.pt\n",
            "Model is loaded\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]          18,816\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "   ConvTranspose2d-5        [-1, 128, 111, 111]           8,192\n",
            "            Conv2d-6          [-1, 128, 28, 28]          73,728\n",
            "            Conv2d-7          [-1, 128, 28, 28]          16,384\n",
            "       BatchNorm2d-8          [-1, 128, 28, 28]             256\n",
            "              ReLU-9          [-1, 128, 28, 28]               0\n",
            "           Conv2d-10          [-1, 128, 14, 14]         147,456\n",
            "           Conv2d-11          [-1, 128, 14, 14]          16,384\n",
            "      BatchNorm2d-12          [-1, 128, 14, 14]             256\n",
            "             ReLU-13          [-1, 128, 14, 14]               0\n",
            "         Downsize-14          [-1, 128, 14, 14]               0\n",
            "  ConvTranspose2d-15          [-1, 256, 27, 27]          32,768\n",
            "           Conv2d-16            [-1, 256, 7, 7]         294,912\n",
            "           Conv2d-17            [-1, 256, 7, 7]          65,536\n",
            "      BatchNorm2d-18            [-1, 256, 7, 7]             512\n",
            "             ReLU-19            [-1, 256, 7, 7]               0\n",
            "           Conv2d-20            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-21            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-22            [-1, 256, 4, 4]             512\n",
            "             ReLU-23            [-1, 256, 4, 4]               0\n",
            "         Downsize-24            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-25            [-1, 512, 7, 7]         131,072\n",
            "           Conv2d-26            [-1, 512, 2, 2]       1,179,648\n",
            "           Conv2d-27            [-1, 512, 2, 2]         262,144\n",
            "      BatchNorm2d-28            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-29            [-1, 512, 2, 2]               0\n",
            "           Conv2d-30            [-1, 512, 1, 1]       2,359,296\n",
            "           Conv2d-31            [-1, 512, 1, 1]         262,144\n",
            "      BatchNorm2d-32            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-33            [-1, 512, 1, 1]               0\n",
            "         Downsize-34            [-1, 512, 1, 1]               0\n",
            "  ConvTranspose2d-35            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-36            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-37            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-38            [-1, 256, 4, 4]             512\n",
            "             ReLU-39            [-1, 256, 4, 4]               0\n",
            "           Conv2d-40            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-41            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-42            [-1, 256, 4, 4]             512\n",
            "             ReLU-43            [-1, 256, 4, 4]               0\n",
            "           Upsize-44            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-45          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-46          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-47          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-48          [-1, 128, 28, 28]             256\n",
            "             ReLU-49          [-1, 128, 28, 28]               0\n",
            "           Conv2d-50          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-51          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-52          [-1, 128, 28, 28]             256\n",
            "             ReLU-53          [-1, 128, 28, 28]               0\n",
            "           Upsize-54          [-1, 128, 28, 28]               0\n",
            "  ConvTranspose2d-55           [-1, 64, 56, 56]          73,728\n",
            "           Conv2d-56           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-57           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-58           [-1, 64, 56, 56]             128\n",
            "             ReLU-59           [-1, 64, 56, 56]               0\n",
            "           Conv2d-60           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-61           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-62           [-1, 64, 56, 56]             128\n",
            "             ReLU-63           [-1, 64, 56, 56]               0\n",
            "           Upsize-64           [-1, 64, 56, 56]               0\n",
            "  ConvTranspose2d-65         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-66         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-67         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-68         [-1, 64, 112, 112]             128\n",
            "             ReLU-69         [-1, 64, 112, 112]               0\n",
            "           Conv2d-70         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-71         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-72         [-1, 64, 112, 112]             128\n",
            "             ReLU-73         [-1, 64, 112, 112]               0\n",
            "           Upsize-74         [-1, 64, 112, 112]               0\n",
            "  ConvTranspose2d-75         [-1, 32, 224, 224]          18,432\n",
            "           Conv2d-76         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-77         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-78         [-1, 32, 224, 224]              64\n",
            "             ReLU-79         [-1, 32, 224, 224]               0\n",
            "           Conv2d-80         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-81         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-82         [-1, 32, 224, 224]              64\n",
            "             ReLU-83         [-1, 32, 224, 224]               0\n",
            "           Upsize-84         [-1, 32, 224, 224]               0\n",
            "           Conv2d-85          [-1, 1, 224, 224]              32\n",
            "  ConvTranspose2d-86            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-87            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-88            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-89            [-1, 256, 4, 4]             512\n",
            "             ReLU-90            [-1, 256, 4, 4]               0\n",
            "           Conv2d-91            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-92            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-93            [-1, 256, 4, 4]             512\n",
            "             ReLU-94            [-1, 256, 4, 4]               0\n",
            "           Upsize-95            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-96          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-97          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-98          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-99          [-1, 128, 28, 28]             256\n",
            "            ReLU-100          [-1, 128, 28, 28]               0\n",
            "          Conv2d-101          [-1, 128, 28, 28]         147,456\n",
            "          Conv2d-102          [-1, 128, 28, 28]          16,384\n",
            "     BatchNorm2d-103          [-1, 128, 28, 28]             256\n",
            "            ReLU-104          [-1, 128, 28, 28]               0\n",
            "          Upsize-105          [-1, 128, 28, 28]               0\n",
            " ConvTranspose2d-106           [-1, 64, 56, 56]          73,728\n",
            "          Conv2d-107           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-108           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-109           [-1, 64, 56, 56]             128\n",
            "            ReLU-110           [-1, 64, 56, 56]               0\n",
            "          Conv2d-111           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-112           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-113           [-1, 64, 56, 56]             128\n",
            "            ReLU-114           [-1, 64, 56, 56]               0\n",
            "          Upsize-115           [-1, 64, 56, 56]               0\n",
            " ConvTranspose2d-116         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-117         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-118         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-119         [-1, 64, 112, 112]             128\n",
            "            ReLU-120         [-1, 64, 112, 112]               0\n",
            "          Conv2d-121         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-122         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-123         [-1, 64, 112, 112]             128\n",
            "            ReLU-124         [-1, 64, 112, 112]               0\n",
            "          Upsize-125         [-1, 64, 112, 112]               0\n",
            " ConvTranspose2d-126         [-1, 32, 224, 224]          18,432\n",
            "          Conv2d-127         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-128         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-129         [-1, 32, 224, 224]              64\n",
            "            ReLU-130         [-1, 32, 224, 224]               0\n",
            "          Conv2d-131         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-132         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-133         [-1, 32, 224, 224]              64\n",
            "            ReLU-134         [-1, 32, 224, 224]               0\n",
            "          Upsize-135         [-1, 32, 224, 224]               0\n",
            "          Conv2d-136          [-1, 3, 224, 224]              99\n",
            "================================================================\n",
            "Total params: 12,384,643\n",
            "Trainable params: 12,384,643\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.15\n",
            "Forward/backward pass size (MB): 453.79\n",
            "Params size (MB): 47.24\n",
            "Estimated Total Size (MB): 502.18\n",
            "----------------------------------------------------------------\n",
            "You are running /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_2.zip dataset for 5 epochs\n",
            "EPOCH: 1\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.4361 Mask loss=0.02 Depth loss=0.41:   0% 0/140 [01:13<?, ?it/s]batch_idx: 0\n",
            "loss: 0.4361470639705658\n",
            "Train Epoch: 1  [0/7000  (0%)]\tLoss:0.436147\n",
            "Overall Loss=0.3187 Mask loss=0.01 Depth loss=0.29:  36% 50/140 [11:59<03:37,  2.42s/it]batch_idx: 50\n",
            "loss: 0.31871721148490906\n",
            "Train Epoch: 1  [200/7000  (36%)]\tLoss:0.318717\n",
            "Overall Loss=0.3173 Mask loss=0.01 Depth loss=0.29:  71% 100/140 [12:45<00:26,  1.51it/s]batch_idx: 100\n",
            "loss: 0.31726735830307007\n",
            "Train Epoch: 1  [400/7000  (71%)]\tLoss:0.317267\n",
            "Overall Loss=0.3258 Mask loss=0.01 Depth loss=0.30: 100% 140/140 [13:12<00:00,  5.66s/it]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Validation loss decreased (100000.000000 --> 0.325815).  Saving model ...\n",
            "Model saved\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.33769188821315765\n",
            " 83% 50/60 [00:32<00:06,  1.59it/s]batch_idx: 50\n",
            "loss: 0.3487521521747112\n",
            "100% 60/60 [00:38<00:00,  1.56it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3428, Mask Loss: 0.02, Depth Loss: 0.30\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "EPOCH: 2\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3191 Mask loss=0.01 Depth loss=0.29:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.31910523772239685\n",
            "Train Epoch: 2  [0/7000  (0%)]\tLoss:0.319105\n",
            "Overall Loss=0.3193 Mask loss=0.01 Depth loss=0.29:  36% 50/140 [00:34<01:00,  1.48it/s]batch_idx: 50\n",
            "loss: 0.3192967176437378\n",
            "Train Epoch: 2  [200/7000  (36%)]\tLoss:0.319297\n",
            "Overall Loss=0.3187 Mask loss=0.01 Depth loss=0.29:  71% 100/140 [01:08<00:26,  1.52it/s]batch_idx: 100\n",
            "loss: 0.3187190294265747\n",
            "Train Epoch: 2  [400/7000  (71%)]\tLoss:0.318719\n",
            "Overall Loss=0.3257 Mask loss=0.01 Depth loss=0.30: 100% 140/140 [01:35<00:00,  1.47it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Validation loss decreased (0.325815 --> 0.325669).  Saving model ...\n",
            "Model saved\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.337783120572567\n",
            " 83% 50/60 [00:32<00:06,  1.57it/s]batch_idx: 50\n",
            "loss: 0.33281901851296425\n",
            "100% 60/60 [00:38<00:00,  1.56it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3346, Mask Loss: 0.02, Depth Loss: 0.30\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "EPOCH: 3\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3143 Mask loss=0.01 Depth loss=0.29:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3143474757671356\n",
            "Train Epoch: 3  [0/7000  (0%)]\tLoss:0.314347\n",
            "Overall Loss=0.3168 Mask loss=0.01 Depth loss=0.29:  36% 50/140 [00:34<01:01,  1.46it/s]batch_idx: 50\n",
            "loss: 0.31684398651123047\n",
            "Train Epoch: 3  [200/7000  (36%)]\tLoss:0.316844\n",
            "Overall Loss=0.3183 Mask loss=0.01 Depth loss=0.29:  71% 100/140 [01:09<00:27,  1.47it/s]batch_idx: 100\n",
            "loss: 0.31825244426727295\n",
            "Train Epoch: 3  [400/7000  (71%)]\tLoss:0.318252\n",
            "Overall Loss=0.3175 Mask loss=0.01 Depth loss=0.29: 100% 140/140 [01:35<00:00,  1.46it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Validation loss decreased (0.325669 --> 0.317509).  Saving model ...\n",
            "Model saved\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.32813258469104767\n",
            " 83% 50/60 [00:32<00:06,  1.57it/s]batch_idx: 50\n",
            "loss: 0.3316216878592968\n",
            "100% 60/60 [00:38<00:00,  1.56it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3300, Mask Loss: 0.02, Depth Loss: 0.30\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "EPOCH: 4\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3162 Mask loss=0.01 Depth loss=0.29:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.31617972254753113\n",
            "Train Epoch: 4  [0/7000  (0%)]\tLoss:0.316180\n",
            "Overall Loss=0.3134 Mask loss=0.01 Depth loss=0.29:  36% 50/140 [00:34<00:58,  1.53it/s]batch_idx: 50\n",
            "loss: 0.3133516311645508\n",
            "Train Epoch: 4  [200/7000  (36%)]\tLoss:0.313352\n",
            "Overall Loss=0.3176 Mask loss=0.01 Depth loss=0.29:  71% 100/140 [01:08<00:26,  1.51it/s]batch_idx: 100\n",
            "loss: 0.3176009953022003\n",
            "Train Epoch: 4  [400/7000  (71%)]\tLoss:0.317601\n",
            "Overall Loss=0.3144 Mask loss=0.01 Depth loss=0.29: 100% 140/140 [01:34<00:00,  1.48it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Validation loss decreased (0.317509 --> 0.314450).  Saving model ...\n",
            "Model saved\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.33002494648098946\n",
            " 83% 50/60 [00:31<00:06,  1.61it/s]batch_idx: 50\n",
            "loss: 0.32988106831908226\n",
            "100% 60/60 [00:38<00:00,  1.57it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3289, Mask Loss: 0.02, Depth Loss: 0.30\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "EPOCH: 5\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3167 Mask loss=0.01 Depth loss=0.29:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3167457580566406\n",
            "Train Epoch: 5  [0/7000  (0%)]\tLoss:0.316746\n",
            "Overall Loss=0.3180 Mask loss=0.01 Depth loss=0.29:  36% 50/140 [00:34<00:59,  1.51it/s]batch_idx: 50\n",
            "loss: 0.3179555833339691\n",
            "Train Epoch: 5  [200/7000  (36%)]\tLoss:0.317956\n",
            "Overall Loss=0.3154 Mask loss=0.01 Depth loss=0.29:  71% 100/140 [01:08<00:27,  1.47it/s]batch_idx: 100\n",
            "loss: 0.31538406014442444\n",
            "Train Epoch: 5  [400/7000  (71%)]\tLoss:0.315384\n",
            "Overall Loss=0.3262 Mask loss=0.01 Depth loss=0.30: 100% 140/140 [01:34<00:00,  1.48it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.32681865245103836\n",
            " 83% 50/60 [00:31<00:06,  1.55it/s]batch_idx: 50\n",
            "loss: 0.32792099192738533\n",
            "100% 60/60 [00:38<00:00,  1.57it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3290, Mask Loss: 0.02, Depth Loss: 0.30\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "time: 24min 16s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-G072BbKn3QB"
      },
      "source": [
        "# Batch_3 dataset : \n",
        "        Dataset size : 30K\n",
        "            - Train (70%)  : 21K  \n",
        "            - Test  (30%)  : 9K\n",
        "        Batch Size   : 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "7223996b-8834-421b-c119-1dab2ef3830b",
        "id": "eYA8CFg-n3QE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "os.chdir(r'/content/drive/My Drive/EVA4/S15/scripts/pythonFiles')\n",
        "!python train_mask_depth.py -z '/content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_3.zip' -e 5  -bs 50"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are executing model on : cuda\n",
            "Dataset using : /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_3.zip\n",
            "Train Dataset : 21000\n",
            "Test Dataset : 9000\n",
            "\t In batch size of : 50\n",
            "cuda\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]          18,816\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "   ConvTranspose2d-5        [-1, 128, 111, 111]           8,192\n",
            "            Conv2d-6          [-1, 128, 28, 28]          73,728\n",
            "            Conv2d-7          [-1, 128, 28, 28]          16,384\n",
            "       BatchNorm2d-8          [-1, 128, 28, 28]             256\n",
            "              ReLU-9          [-1, 128, 28, 28]               0\n",
            "           Conv2d-10          [-1, 128, 14, 14]         147,456\n",
            "           Conv2d-11          [-1, 128, 14, 14]          16,384\n",
            "      BatchNorm2d-12          [-1, 128, 14, 14]             256\n",
            "             ReLU-13          [-1, 128, 14, 14]               0\n",
            "         Downsize-14          [-1, 128, 14, 14]               0\n",
            "  ConvTranspose2d-15          [-1, 256, 27, 27]          32,768\n",
            "           Conv2d-16            [-1, 256, 7, 7]         294,912\n",
            "           Conv2d-17            [-1, 256, 7, 7]          65,536\n",
            "      BatchNorm2d-18            [-1, 256, 7, 7]             512\n",
            "             ReLU-19            [-1, 256, 7, 7]               0\n",
            "           Conv2d-20            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-21            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-22            [-1, 256, 4, 4]             512\n",
            "             ReLU-23            [-1, 256, 4, 4]               0\n",
            "         Downsize-24            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-25            [-1, 512, 7, 7]         131,072\n",
            "           Conv2d-26            [-1, 512, 2, 2]       1,179,648\n",
            "           Conv2d-27            [-1, 512, 2, 2]         262,144\n",
            "      BatchNorm2d-28            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-29            [-1, 512, 2, 2]               0\n",
            "           Conv2d-30            [-1, 512, 1, 1]       2,359,296\n",
            "           Conv2d-31            [-1, 512, 1, 1]         262,144\n",
            "      BatchNorm2d-32            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-33            [-1, 512, 1, 1]               0\n",
            "         Downsize-34            [-1, 512, 1, 1]               0\n",
            "  ConvTranspose2d-35            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-36            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-37            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-38            [-1, 256, 4, 4]             512\n",
            "             ReLU-39            [-1, 256, 4, 4]               0\n",
            "           Conv2d-40            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-41            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-42            [-1, 256, 4, 4]             512\n",
            "             ReLU-43            [-1, 256, 4, 4]               0\n",
            "           Upsize-44            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-45          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-46          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-47          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-48          [-1, 128, 28, 28]             256\n",
            "             ReLU-49          [-1, 128, 28, 28]               0\n",
            "           Conv2d-50          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-51          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-52          [-1, 128, 28, 28]             256\n",
            "             ReLU-53          [-1, 128, 28, 28]               0\n",
            "           Upsize-54          [-1, 128, 28, 28]               0\n",
            "  ConvTranspose2d-55           [-1, 64, 56, 56]          73,728\n",
            "           Conv2d-56           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-57           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-58           [-1, 64, 56, 56]             128\n",
            "             ReLU-59           [-1, 64, 56, 56]               0\n",
            "           Conv2d-60           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-61           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-62           [-1, 64, 56, 56]             128\n",
            "             ReLU-63           [-1, 64, 56, 56]               0\n",
            "           Upsize-64           [-1, 64, 56, 56]               0\n",
            "  ConvTranspose2d-65         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-66         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-67         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-68         [-1, 64, 112, 112]             128\n",
            "             ReLU-69         [-1, 64, 112, 112]               0\n",
            "           Conv2d-70         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-71         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-72         [-1, 64, 112, 112]             128\n",
            "             ReLU-73         [-1, 64, 112, 112]               0\n",
            "           Upsize-74         [-1, 64, 112, 112]               0\n",
            "  ConvTranspose2d-75         [-1, 32, 224, 224]          18,432\n",
            "           Conv2d-76         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-77         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-78         [-1, 32, 224, 224]              64\n",
            "             ReLU-79         [-1, 32, 224, 224]               0\n",
            "           Conv2d-80         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-81         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-82         [-1, 32, 224, 224]              64\n",
            "             ReLU-83         [-1, 32, 224, 224]               0\n",
            "           Upsize-84         [-1, 32, 224, 224]               0\n",
            "           Conv2d-85          [-1, 1, 224, 224]              32\n",
            "  ConvTranspose2d-86            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-87            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-88            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-89            [-1, 256, 4, 4]             512\n",
            "             ReLU-90            [-1, 256, 4, 4]               0\n",
            "           Conv2d-91            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-92            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-93            [-1, 256, 4, 4]             512\n",
            "             ReLU-94            [-1, 256, 4, 4]               0\n",
            "           Upsize-95            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-96          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-97          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-98          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-99          [-1, 128, 28, 28]             256\n",
            "            ReLU-100          [-1, 128, 28, 28]               0\n",
            "          Conv2d-101          [-1, 128, 28, 28]         147,456\n",
            "          Conv2d-102          [-1, 128, 28, 28]          16,384\n",
            "     BatchNorm2d-103          [-1, 128, 28, 28]             256\n",
            "            ReLU-104          [-1, 128, 28, 28]               0\n",
            "          Upsize-105          [-1, 128, 28, 28]               0\n",
            " ConvTranspose2d-106           [-1, 64, 56, 56]          73,728\n",
            "          Conv2d-107           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-108           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-109           [-1, 64, 56, 56]             128\n",
            "            ReLU-110           [-1, 64, 56, 56]               0\n",
            "          Conv2d-111           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-112           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-113           [-1, 64, 56, 56]             128\n",
            "            ReLU-114           [-1, 64, 56, 56]               0\n",
            "          Upsize-115           [-1, 64, 56, 56]               0\n",
            " ConvTranspose2d-116         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-117         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-118         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-119         [-1, 64, 112, 112]             128\n",
            "            ReLU-120         [-1, 64, 112, 112]               0\n",
            "          Conv2d-121         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-122         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-123         [-1, 64, 112, 112]             128\n",
            "            ReLU-124         [-1, 64, 112, 112]               0\n",
            "          Upsize-125         [-1, 64, 112, 112]               0\n",
            " ConvTranspose2d-126         [-1, 32, 224, 224]          18,432\n",
            "          Conv2d-127         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-128         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-129         [-1, 32, 224, 224]              64\n",
            "            ReLU-130         [-1, 32, 224, 224]               0\n",
            "          Conv2d-131         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-132         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-133         [-1, 32, 224, 224]              64\n",
            "            ReLU-134         [-1, 32, 224, 224]               0\n",
            "          Upsize-135         [-1, 32, 224, 224]               0\n",
            "          Conv2d-136          [-1, 3, 224, 224]              99\n",
            "================================================================\n",
            "Total params: 12,384,643\n",
            "Trainable params: 12,384,643\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.15\n",
            "Forward/backward pass size (MB): 453.79\n",
            "Params size (MB): 47.24\n",
            "Estimated Total Size (MB): 502.18\n",
            "----------------------------------------------------------------\n",
            "You are running /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_3.zip dataset for 5 epochs\n",
            "Loading model : batch_best.ckp.pt\n",
            "Model is loaded and valid_loss_min is :0.3254179358482361\n",
            "\n",
            "###########EPOCH:1#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3208 Mask loss=0.01 Depth loss=0.30:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.32079699635505676\n",
            "##### Train Epoch: 1  [0/7000  (0%)]\tLoss:0.320797\n",
            "Overall Loss=0.3166 Mask loss=0.01 Depth loss=0.29:  36% 50/140 [00:36<01:00,  1.49it/s]batch_idx: 50\n",
            "loss: 0.3166210651397705\n",
            "##### Train Epoch: 1  [200/7000  (36%)]\tLoss:0.316621\n",
            "Overall Loss=0.3164 Mask loss=0.01 Depth loss=0.29:  71% 100/140 [01:10<00:27,  1.46it/s]batch_idx: 100\n",
            "loss: 0.3164309859275818\n",
            "##### Train Epoch: 1  [400/7000  (71%)]\tLoss:0.316431\n",
            "Overall Loss=0.3209 Mask loss=0.01 Depth loss=0.30: 100% 140/140 [01:37<00:00,  1.44it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Validation loss decreased (0.325418 --> 0.320900).  Saving model ...\n",
            "Model saved\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3291532173752785\n",
            " 83% 50/60 [00:32<00:06,  1.58it/s]batch_idx: 50\n",
            "loss: 0.32828637585043907\n",
            "100% 60/60 [00:38<00:00,  1.56it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3342, Mask Loss: 0.02, Depth Loss: 0.30\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:2#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3185 Mask loss=0.01 Depth loss=0.29:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3184513449668884\n",
            "##### Train Epoch: 2  [0/7000  (0%)]\tLoss:0.318451\n",
            "Overall Loss=0.3221 Mask loss=0.01 Depth loss=0.30:  36% 50/140 [00:34<01:01,  1.47it/s]batch_idx: 50\n",
            "loss: 0.32214275002479553\n",
            "##### Train Epoch: 2  [200/7000  (36%)]\tLoss:0.322143\n",
            "Overall Loss=0.3206 Mask loss=0.01 Depth loss=0.30:  71% 100/140 [01:08<00:27,  1.46it/s]batch_idx: 100\n",
            "loss: 0.3206027150154114\n",
            "##### Train Epoch: 2  [400/7000  (71%)]\tLoss:0.320603\n",
            "Overall Loss=0.3235 Mask loss=0.01 Depth loss=0.30: 100% 140/140 [01:35<00:00,  1.46it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.34310027956962585\n",
            " 83% 50/60 [00:32<00:06,  1.57it/s]batch_idx: 50\n",
            "loss: 0.33780674636363983\n",
            "100% 60/60 [00:38<00:00,  1.55it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3372, Mask Loss: 0.02, Depth Loss: 0.30\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:3#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3250 Mask loss=0.01 Depth loss=0.30:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.32495149970054626\n",
            "##### Train Epoch: 3  [0/7000  (0%)]\tLoss:0.324951\n",
            "Overall Loss=0.3208 Mask loss=0.01 Depth loss=0.30:  36% 50/140 [00:35<01:01,  1.47it/s]batch_idx: 50\n",
            "loss: 0.32076147198677063\n",
            "##### Train Epoch: 3  [200/7000  (36%)]\tLoss:0.320761\n",
            "Overall Loss=0.3223 Mask loss=0.01 Depth loss=0.30:  71% 100/140 [01:09<00:26,  1.48it/s]batch_idx: 100\n",
            "loss: 0.3223169147968292\n",
            "##### Train Epoch: 3  [400/7000  (71%)]\tLoss:0.322317\n",
            "Overall Loss=0.3234 Mask loss=0.01 Depth loss=0.30: 100% 140/140 [01:36<00:00,  1.46it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.33457842469215393\n",
            " 83% 50/60 [00:31<00:06,  1.58it/s]batch_idx: 50\n",
            "loss: 0.33076174184679985\n",
            "100% 60/60 [00:38<00:00,  1.57it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3339, Mask Loss: 0.02, Depth Loss: 0.30\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:4#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3196 Mask loss=0.01 Depth loss=0.30:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.31956061720848083\n",
            "##### Train Epoch: 4  [0/7000  (0%)]\tLoss:0.319561\n",
            "Overall Loss=0.3261 Mask loss=0.01 Depth loss=0.30:  36% 50/140 [00:34<01:00,  1.49it/s]batch_idx: 50\n",
            "loss: 0.32608839869499207\n",
            "##### Train Epoch: 4  [200/7000  (36%)]\tLoss:0.326088\n",
            "Overall Loss=0.3209 Mask loss=0.01 Depth loss=0.30:  71% 100/140 [01:09<00:26,  1.49it/s]batch_idx: 100\n",
            "loss: 0.32086026668548584\n",
            "##### Train Epoch: 4  [400/7000  (71%)]\tLoss:0.320860\n",
            "Overall Loss=0.3226 Mask loss=0.01 Depth loss=0.30: 100% 140/140 [01:35<00:00,  1.46it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3320316709578037\n",
            " 83% 50/60 [00:32<00:06,  1.57it/s]batch_idx: 50\n",
            "loss: 0.33486654609441757\n",
            "100% 60/60 [00:38<00:00,  1.55it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3335, Mask Loss: 0.02, Depth Loss: 0.30\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:5#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3240 Mask loss=0.01 Depth loss=0.30:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.32396313548088074\n",
            "##### Train Epoch: 5  [0/7000  (0%)]\tLoss:0.323963\n",
            "Overall Loss=0.3222 Mask loss=0.01 Depth loss=0.30:  36% 50/140 [00:34<01:00,  1.50it/s]batch_idx: 50\n",
            "loss: 0.32224148511886597\n",
            "##### Train Epoch: 5  [200/7000  (36%)]\tLoss:0.322241\n",
            "Overall Loss=0.3201 Mask loss=0.01 Depth loss=0.30:  71% 100/140 [01:08<00:26,  1.49it/s]batch_idx: 100\n",
            "loss: 0.32013702392578125\n",
            "##### Train Epoch: 5  [400/7000  (71%)]\tLoss:0.320137\n",
            "Overall Loss=0.3179 Mask loss=0.01 Depth loss=0.30: 100% 140/140 [01:35<00:00,  1.47it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Validation loss decreased (0.320900 --> 0.317861).  Saving model ...\n",
            "Model saved\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.33302922174334526\n",
            " 83% 50/60 [00:32<00:06,  1.57it/s]batch_idx: 50\n",
            "loss: 0.3355928622186184\n",
            "100% 60/60 [00:38<00:00,  1.55it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3366, Mask Loss: 0.02, Depth Loss: 0.30\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "time: 12min 43s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "cKnD4EuKzY8Q"
      },
      "source": [
        "# Batch_4 dataset : \n",
        "        Dataset size : 30K\n",
        "            - Train (70%)  : 21K  \n",
        "            - Test  (30%)  : 9K\n",
        "        Batch Size   : 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "2f234634-175a-4045-8456-c67f58758037",
        "id": "6Azm1zkIzY8S",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "os.chdir(r'/content/drive/My Drive/EVA4/S15/scripts/pythonFiles')\n",
        "!python train_mask_depth.py -z '/content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_4.zip' -e 5  -bs 50"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are executing model on : cuda\n",
            "Dataset using : /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_4.zip\n",
            "Train Dataset : 21000\n",
            "Test Dataset : 9000\n",
            "\t In batch size of : 50\n",
            "cuda\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]          18,816\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "   ConvTranspose2d-5        [-1, 128, 111, 111]           8,192\n",
            "            Conv2d-6          [-1, 128, 28, 28]          73,728\n",
            "            Conv2d-7          [-1, 128, 28, 28]          16,384\n",
            "       BatchNorm2d-8          [-1, 128, 28, 28]             256\n",
            "              ReLU-9          [-1, 128, 28, 28]               0\n",
            "           Conv2d-10          [-1, 128, 14, 14]         147,456\n",
            "           Conv2d-11          [-1, 128, 14, 14]          16,384\n",
            "      BatchNorm2d-12          [-1, 128, 14, 14]             256\n",
            "             ReLU-13          [-1, 128, 14, 14]               0\n",
            "         Downsize-14          [-1, 128, 14, 14]               0\n",
            "  ConvTranspose2d-15          [-1, 256, 27, 27]          32,768\n",
            "           Conv2d-16            [-1, 256, 7, 7]         294,912\n",
            "           Conv2d-17            [-1, 256, 7, 7]          65,536\n",
            "      BatchNorm2d-18            [-1, 256, 7, 7]             512\n",
            "             ReLU-19            [-1, 256, 7, 7]               0\n",
            "           Conv2d-20            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-21            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-22            [-1, 256, 4, 4]             512\n",
            "             ReLU-23            [-1, 256, 4, 4]               0\n",
            "         Downsize-24            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-25            [-1, 512, 7, 7]         131,072\n",
            "           Conv2d-26            [-1, 512, 2, 2]       1,179,648\n",
            "           Conv2d-27            [-1, 512, 2, 2]         262,144\n",
            "      BatchNorm2d-28            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-29            [-1, 512, 2, 2]               0\n",
            "           Conv2d-30            [-1, 512, 1, 1]       2,359,296\n",
            "           Conv2d-31            [-1, 512, 1, 1]         262,144\n",
            "      BatchNorm2d-32            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-33            [-1, 512, 1, 1]               0\n",
            "         Downsize-34            [-1, 512, 1, 1]               0\n",
            "  ConvTranspose2d-35            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-36            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-37            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-38            [-1, 256, 4, 4]             512\n",
            "             ReLU-39            [-1, 256, 4, 4]               0\n",
            "           Conv2d-40            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-41            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-42            [-1, 256, 4, 4]             512\n",
            "             ReLU-43            [-1, 256, 4, 4]               0\n",
            "           Upsize-44            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-45          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-46          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-47          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-48          [-1, 128, 28, 28]             256\n",
            "             ReLU-49          [-1, 128, 28, 28]               0\n",
            "           Conv2d-50          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-51          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-52          [-1, 128, 28, 28]             256\n",
            "             ReLU-53          [-1, 128, 28, 28]               0\n",
            "           Upsize-54          [-1, 128, 28, 28]               0\n",
            "  ConvTranspose2d-55           [-1, 64, 56, 56]          73,728\n",
            "           Conv2d-56           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-57           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-58           [-1, 64, 56, 56]             128\n",
            "             ReLU-59           [-1, 64, 56, 56]               0\n",
            "           Conv2d-60           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-61           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-62           [-1, 64, 56, 56]             128\n",
            "             ReLU-63           [-1, 64, 56, 56]               0\n",
            "           Upsize-64           [-1, 64, 56, 56]               0\n",
            "  ConvTranspose2d-65         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-66         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-67         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-68         [-1, 64, 112, 112]             128\n",
            "             ReLU-69         [-1, 64, 112, 112]               0\n",
            "           Conv2d-70         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-71         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-72         [-1, 64, 112, 112]             128\n",
            "             ReLU-73         [-1, 64, 112, 112]               0\n",
            "           Upsize-74         [-1, 64, 112, 112]               0\n",
            "  ConvTranspose2d-75         [-1, 32, 224, 224]          18,432\n",
            "           Conv2d-76         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-77         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-78         [-1, 32, 224, 224]              64\n",
            "             ReLU-79         [-1, 32, 224, 224]               0\n",
            "           Conv2d-80         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-81         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-82         [-1, 32, 224, 224]              64\n",
            "             ReLU-83         [-1, 32, 224, 224]               0\n",
            "           Upsize-84         [-1, 32, 224, 224]               0\n",
            "           Conv2d-85          [-1, 1, 224, 224]              32\n",
            "  ConvTranspose2d-86            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-87            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-88            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-89            [-1, 256, 4, 4]             512\n",
            "             ReLU-90            [-1, 256, 4, 4]               0\n",
            "           Conv2d-91            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-92            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-93            [-1, 256, 4, 4]             512\n",
            "             ReLU-94            [-1, 256, 4, 4]               0\n",
            "           Upsize-95            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-96          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-97          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-98          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-99          [-1, 128, 28, 28]             256\n",
            "            ReLU-100          [-1, 128, 28, 28]               0\n",
            "          Conv2d-101          [-1, 128, 28, 28]         147,456\n",
            "          Conv2d-102          [-1, 128, 28, 28]          16,384\n",
            "     BatchNorm2d-103          [-1, 128, 28, 28]             256\n",
            "            ReLU-104          [-1, 128, 28, 28]               0\n",
            "          Upsize-105          [-1, 128, 28, 28]               0\n",
            " ConvTranspose2d-106           [-1, 64, 56, 56]          73,728\n",
            "          Conv2d-107           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-108           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-109           [-1, 64, 56, 56]             128\n",
            "            ReLU-110           [-1, 64, 56, 56]               0\n",
            "          Conv2d-111           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-112           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-113           [-1, 64, 56, 56]             128\n",
            "            ReLU-114           [-1, 64, 56, 56]               0\n",
            "          Upsize-115           [-1, 64, 56, 56]               0\n",
            " ConvTranspose2d-116         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-117         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-118         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-119         [-1, 64, 112, 112]             128\n",
            "            ReLU-120         [-1, 64, 112, 112]               0\n",
            "          Conv2d-121         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-122         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-123         [-1, 64, 112, 112]             128\n",
            "            ReLU-124         [-1, 64, 112, 112]               0\n",
            "          Upsize-125         [-1, 64, 112, 112]               0\n",
            " ConvTranspose2d-126         [-1, 32, 224, 224]          18,432\n",
            "          Conv2d-127         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-128         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-129         [-1, 32, 224, 224]              64\n",
            "            ReLU-130         [-1, 32, 224, 224]               0\n",
            "          Conv2d-131         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-132         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-133         [-1, 32, 224, 224]              64\n",
            "            ReLU-134         [-1, 32, 224, 224]               0\n",
            "          Upsize-135         [-1, 32, 224, 224]               0\n",
            "          Conv2d-136          [-1, 3, 224, 224]              99\n",
            "================================================================\n",
            "Total params: 12,384,643\n",
            "Trainable params: 12,384,643\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.15\n",
            "Forward/backward pass size (MB): 453.79\n",
            "Params size (MB): 47.24\n",
            "Estimated Total Size (MB): 502.18\n",
            "----------------------------------------------------------------\n",
            "You are running /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_4.zip dataset for 5 epochs\n",
            "Loading model : batch_best.ckp.pt\n",
            "Model is loaded and valid_loss_min is :0.31786099076271057\n",
            "\n",
            "###########EPOCH:1#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3804 Mask loss=0.01 Depth loss=0.36:   0% 0/140 [01:37<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3804413378238678\n",
            "##### Train Epoch: 1  [0/7000  (0%)]\tLoss:0.380441\n",
            "Overall Loss=0.3074 Mask loss=0.01 Depth loss=0.28:  36% 50/140 [11:25<03:43,  2.49s/it]batch_idx: 50\n",
            "loss: 0.3073900043964386\n",
            "##### Train Epoch: 1  [200/7000  (36%)]\tLoss:0.307390\n",
            "Overall Loss=0.3023 Mask loss=0.01 Depth loss=0.28:  71% 100/140 [12:14<00:27,  1.47it/s]batch_idx: 100\n",
            "loss: 0.3023187518119812\n",
            "##### Train Epoch: 1  [400/7000  (71%)]\tLoss:0.302319\n",
            "Overall Loss=0.3089 Mask loss=0.01 Depth loss=0.28: 100% 140/140 [12:43<00:00,  5.45s/it]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Validation loss decreased (0.317861 --> 0.308897).  Saving model ...\n",
            "\n",
            "\n",
            "\n",
            "**************Model saved**************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3202842306345701\n",
            " 83% 50/60 [00:31<00:06,  1.61it/s]batch_idx: 50\n",
            "loss: 0.3188727591186762\n",
            "100% 60/60 [00:38<00:00,  1.58it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3202, Mask Loss: 0.02, Depth Loss: 0.29\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:2#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3102 Mask loss=0.01 Depth loss=0.29:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.31015482544898987\n",
            "##### Train Epoch: 2  [0/7000  (0%)]\tLoss:0.310155\n",
            "Overall Loss=0.3094 Mask loss=0.01 Depth loss=0.29:  36% 50/140 [00:34<00:59,  1.51it/s]batch_idx: 50\n",
            "loss: 0.30942416191101074\n",
            "##### Train Epoch: 2  [200/7000  (36%)]\tLoss:0.309424\n",
            "Overall Loss=0.3074 Mask loss=0.01 Depth loss=0.28:  71% 100/140 [01:07<00:26,  1.54it/s]batch_idx: 100\n",
            "loss: 0.3074348568916321\n",
            "##### Train Epoch: 2  [400/7000  (71%)]\tLoss:0.307435\n",
            "Overall Loss=0.3051 Mask loss=0.01 Depth loss=0.28: 100% 140/140 [01:33<00:00,  1.50it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Validation loss decreased (0.308897 --> 0.305107).  Saving model ...\n",
            "\n",
            "\n",
            "\n",
            "**************Model saved**************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.32202303037047386\n",
            " 83% 50/60 [00:31<00:06,  1.59it/s]batch_idx: 50\n",
            "loss: 0.3147504311054945\n",
            "100% 60/60 [00:37<00:00,  1.59it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3195, Mask Loss: 0.02, Depth Loss: 0.29\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:3#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3075 Mask loss=0.01 Depth loss=0.29:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.30748075246810913\n",
            "##### Train Epoch: 3  [0/7000  (0%)]\tLoss:0.307481\n",
            "Overall Loss=0.3036 Mask loss=0.01 Depth loss=0.28:  36% 50/140 [00:34<01:00,  1.48it/s]batch_idx: 50\n",
            "loss: 0.30361971259117126\n",
            "##### Train Epoch: 3  [200/7000  (36%)]\tLoss:0.303620\n",
            "Overall Loss=0.3085 Mask loss=0.01 Depth loss=0.28:  71% 100/140 [01:07<00:26,  1.52it/s]batch_idx: 100\n",
            "loss: 0.3085474967956543\n",
            "##### Train Epoch: 3  [400/7000  (71%)]\tLoss:0.308547\n",
            "Overall Loss=0.3071 Mask loss=0.01 Depth loss=0.28: 100% 140/140 [01:33<00:00,  1.49it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.32219064980745316\n",
            " 83% 50/60 [00:31<00:06,  1.61it/s]batch_idx: 50\n",
            "loss: 0.31259771063923836\n",
            "100% 60/60 [00:37<00:00,  1.60it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3193, Mask Loss: 0.02, Depth Loss: 0.29\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:4#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3060 Mask loss=0.01 Depth loss=0.28:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.30604636669158936\n",
            "##### Train Epoch: 4  [0/7000  (0%)]\tLoss:0.306046\n",
            "Overall Loss=0.3077 Mask loss=0.01 Depth loss=0.28:  36% 50/140 [00:33<00:58,  1.54it/s]batch_idx: 50\n",
            "loss: 0.30773019790649414\n",
            "##### Train Epoch: 4  [200/7000  (36%)]\tLoss:0.307730\n",
            "Overall Loss=0.3086 Mask loss=0.01 Depth loss=0.29:  71% 100/140 [01:06<00:25,  1.54it/s]batch_idx: 100\n",
            "loss: 0.30864256620407104\n",
            "##### Train Epoch: 4  [400/7000  (71%)]\tLoss:0.308643\n",
            "Overall Loss=0.3084 Mask loss=0.01 Depth loss=0.29: 100% 140/140 [01:32<00:00,  1.51it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3184941727668047\n",
            " 83% 50/60 [00:31<00:06,  1.60it/s]batch_idx: 50\n",
            "loss: 0.32083491422235966\n",
            "100% 60/60 [00:37<00:00,  1.60it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3180, Mask Loss: 0.02, Depth Loss: 0.29\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:5#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3017 Mask loss=0.01 Depth loss=0.28:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.30169135332107544\n",
            "##### Train Epoch: 5  [0/7000  (0%)]\tLoss:0.301691\n",
            "Overall Loss=0.3132 Mask loss=0.01 Depth loss=0.29:  36% 50/140 [00:33<00:59,  1.51it/s]batch_idx: 50\n",
            "loss: 0.31317776441574097\n",
            "##### Train Epoch: 5  [200/7000  (36%)]\tLoss:0.313178\n",
            "Overall Loss=0.3009 Mask loss=0.01 Depth loss=0.28:  71% 100/140 [01:07<00:25,  1.54it/s]batch_idx: 100\n",
            "loss: 0.3008561432361603\n",
            "##### Train Epoch: 5  [400/7000  (71%)]\tLoss:0.300856\n",
            "Overall Loss=0.3129 Mask loss=0.01 Depth loss=0.29: 100% 140/140 [01:33<00:00,  1.50it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.31386501155793667\n",
            " 83% 50/60 [00:31<00:06,  1.62it/s]batch_idx: 50\n",
            "loss: 0.31540275178849697\n",
            "100% 60/60 [00:37<00:00,  1.61it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3156, Mask Loss: 0.01, Depth Loss: 0.29\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "time: 23min 33s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "lLzEHUOA9iLC"
      },
      "source": [
        "# Batch_5 dataset : \n",
        "        Dataset size : 30K\n",
        "            - Train (70%)  : 21K  \n",
        "            - Test  (30%)  : 9K\n",
        "        Batch Size   : 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "eef028e8-1ead-45db-e443-b0018af2cca7",
        "id": "1vHtJVtu9iLP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "os.chdir(r'/content/drive/My Drive/EVA4/S15/scripts/pythonFiles')\n",
        "!python train_mask_depth.py -z '/content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_5.zip' -e 5  -bs 50"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are executing model on : cuda\n",
            "Dataset using : /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_5.zip\n",
            "Train Dataset : 21000\n",
            "Test Dataset : 9000\n",
            "\t In batch size of : 50\n",
            "cuda\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]          18,816\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "   ConvTranspose2d-5        [-1, 128, 111, 111]           8,192\n",
            "            Conv2d-6          [-1, 128, 28, 28]          73,728\n",
            "            Conv2d-7          [-1, 128, 28, 28]          16,384\n",
            "       BatchNorm2d-8          [-1, 128, 28, 28]             256\n",
            "              ReLU-9          [-1, 128, 28, 28]               0\n",
            "           Conv2d-10          [-1, 128, 14, 14]         147,456\n",
            "           Conv2d-11          [-1, 128, 14, 14]          16,384\n",
            "      BatchNorm2d-12          [-1, 128, 14, 14]             256\n",
            "             ReLU-13          [-1, 128, 14, 14]               0\n",
            "         Downsize-14          [-1, 128, 14, 14]               0\n",
            "  ConvTranspose2d-15          [-1, 256, 27, 27]          32,768\n",
            "           Conv2d-16            [-1, 256, 7, 7]         294,912\n",
            "           Conv2d-17            [-1, 256, 7, 7]          65,536\n",
            "      BatchNorm2d-18            [-1, 256, 7, 7]             512\n",
            "             ReLU-19            [-1, 256, 7, 7]               0\n",
            "           Conv2d-20            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-21            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-22            [-1, 256, 4, 4]             512\n",
            "             ReLU-23            [-1, 256, 4, 4]               0\n",
            "         Downsize-24            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-25            [-1, 512, 7, 7]         131,072\n",
            "           Conv2d-26            [-1, 512, 2, 2]       1,179,648\n",
            "           Conv2d-27            [-1, 512, 2, 2]         262,144\n",
            "      BatchNorm2d-28            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-29            [-1, 512, 2, 2]               0\n",
            "           Conv2d-30            [-1, 512, 1, 1]       2,359,296\n",
            "           Conv2d-31            [-1, 512, 1, 1]         262,144\n",
            "      BatchNorm2d-32            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-33            [-1, 512, 1, 1]               0\n",
            "         Downsize-34            [-1, 512, 1, 1]               0\n",
            "  ConvTranspose2d-35            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-36            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-37            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-38            [-1, 256, 4, 4]             512\n",
            "             ReLU-39            [-1, 256, 4, 4]               0\n",
            "           Conv2d-40            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-41            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-42            [-1, 256, 4, 4]             512\n",
            "             ReLU-43            [-1, 256, 4, 4]               0\n",
            "           Upsize-44            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-45          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-46          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-47          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-48          [-1, 128, 28, 28]             256\n",
            "             ReLU-49          [-1, 128, 28, 28]               0\n",
            "           Conv2d-50          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-51          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-52          [-1, 128, 28, 28]             256\n",
            "             ReLU-53          [-1, 128, 28, 28]               0\n",
            "           Upsize-54          [-1, 128, 28, 28]               0\n",
            "  ConvTranspose2d-55           [-1, 64, 56, 56]          73,728\n",
            "           Conv2d-56           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-57           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-58           [-1, 64, 56, 56]             128\n",
            "             ReLU-59           [-1, 64, 56, 56]               0\n",
            "           Conv2d-60           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-61           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-62           [-1, 64, 56, 56]             128\n",
            "             ReLU-63           [-1, 64, 56, 56]               0\n",
            "           Upsize-64           [-1, 64, 56, 56]               0\n",
            "  ConvTranspose2d-65         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-66         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-67         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-68         [-1, 64, 112, 112]             128\n",
            "             ReLU-69         [-1, 64, 112, 112]               0\n",
            "           Conv2d-70         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-71         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-72         [-1, 64, 112, 112]             128\n",
            "             ReLU-73         [-1, 64, 112, 112]               0\n",
            "           Upsize-74         [-1, 64, 112, 112]               0\n",
            "  ConvTranspose2d-75         [-1, 32, 224, 224]          18,432\n",
            "           Conv2d-76         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-77         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-78         [-1, 32, 224, 224]              64\n",
            "             ReLU-79         [-1, 32, 224, 224]               0\n",
            "           Conv2d-80         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-81         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-82         [-1, 32, 224, 224]              64\n",
            "             ReLU-83         [-1, 32, 224, 224]               0\n",
            "           Upsize-84         [-1, 32, 224, 224]               0\n",
            "           Conv2d-85          [-1, 1, 224, 224]              32\n",
            "  ConvTranspose2d-86            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-87            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-88            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-89            [-1, 256, 4, 4]             512\n",
            "             ReLU-90            [-1, 256, 4, 4]               0\n",
            "           Conv2d-91            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-92            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-93            [-1, 256, 4, 4]             512\n",
            "             ReLU-94            [-1, 256, 4, 4]               0\n",
            "           Upsize-95            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-96          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-97          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-98          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-99          [-1, 128, 28, 28]             256\n",
            "            ReLU-100          [-1, 128, 28, 28]               0\n",
            "          Conv2d-101          [-1, 128, 28, 28]         147,456\n",
            "          Conv2d-102          [-1, 128, 28, 28]          16,384\n",
            "     BatchNorm2d-103          [-1, 128, 28, 28]             256\n",
            "            ReLU-104          [-1, 128, 28, 28]               0\n",
            "          Upsize-105          [-1, 128, 28, 28]               0\n",
            " ConvTranspose2d-106           [-1, 64, 56, 56]          73,728\n",
            "          Conv2d-107           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-108           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-109           [-1, 64, 56, 56]             128\n",
            "            ReLU-110           [-1, 64, 56, 56]               0\n",
            "          Conv2d-111           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-112           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-113           [-1, 64, 56, 56]             128\n",
            "            ReLU-114           [-1, 64, 56, 56]               0\n",
            "          Upsize-115           [-1, 64, 56, 56]               0\n",
            " ConvTranspose2d-116         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-117         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-118         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-119         [-1, 64, 112, 112]             128\n",
            "            ReLU-120         [-1, 64, 112, 112]               0\n",
            "          Conv2d-121         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-122         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-123         [-1, 64, 112, 112]             128\n",
            "            ReLU-124         [-1, 64, 112, 112]               0\n",
            "          Upsize-125         [-1, 64, 112, 112]               0\n",
            " ConvTranspose2d-126         [-1, 32, 224, 224]          18,432\n",
            "          Conv2d-127         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-128         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-129         [-1, 32, 224, 224]              64\n",
            "            ReLU-130         [-1, 32, 224, 224]               0\n",
            "          Conv2d-131         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-132         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-133         [-1, 32, 224, 224]              64\n",
            "            ReLU-134         [-1, 32, 224, 224]               0\n",
            "          Upsize-135         [-1, 32, 224, 224]               0\n",
            "          Conv2d-136          [-1, 3, 224, 224]              99\n",
            "================================================================\n",
            "Total params: 12,384,643\n",
            "Trainable params: 12,384,643\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.15\n",
            "Forward/backward pass size (MB): 453.79\n",
            "Params size (MB): 47.24\n",
            "Estimated Total Size (MB): 502.18\n",
            "----------------------------------------------------------------\n",
            "You are running /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_5.zip dataset for 5 epochs\n",
            "Loading model : batch_best.ckp.pt\n",
            "Model is loaded and valid_loss_min is :0.30510684847831726\n",
            "\n",
            "###########EPOCH:1#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3585 Mask loss=0.01 Depth loss=0.33:   0% 0/140 [01:03<?, ?it/s]batch_idx: 0\n",
            "loss: 0.35854244232177734\n",
            "##### Train Epoch: 1  [0/7000  (0%)]\tLoss:0.358542\n",
            "Overall Loss=0.3005 Mask loss=0.01 Depth loss=0.28:  36% 50/140 [11:00<02:46,  1.86s/it]batch_idx: 50\n",
            "loss: 0.3004862368106842\n",
            "##### Train Epoch: 1  [200/7000  (36%)]\tLoss:0.300486\n",
            "Overall Loss=0.2991 Mask loss=0.01 Depth loss=0.28:  71% 100/140 [11:47<00:26,  1.54it/s]batch_idx: 100\n",
            "loss: 0.2990552484989166\n",
            "##### Train Epoch: 1  [400/7000  (71%)]\tLoss:0.299055\n",
            "Overall Loss=0.2969 Mask loss=0.01 Depth loss=0.27: 100% 140/140 [12:13<00:00,  5.24s/it]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Validation loss decreased (0.305107 --> 0.296927).  Saving model ...\n",
            "\n",
            "\n",
            "\n",
            "**************Model saved**************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3167460970580578\n",
            " 83% 50/60 [00:31<00:06,  1.60it/s]batch_idx: 50\n",
            "loss: 0.31097614020109177\n",
            "100% 60/60 [00:37<00:00,  1.59it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3137, Mask Loss: 0.02, Depth Loss: 0.28\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:2#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3059 Mask loss=0.01 Depth loss=0.28:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.30587679147720337\n",
            "##### Train Epoch: 2  [0/7000  (0%)]\tLoss:0.305877\n",
            "Overall Loss=0.2975 Mask loss=0.01 Depth loss=0.27:  36% 50/140 [00:33<00:58,  1.53it/s]batch_idx: 50\n",
            "loss: 0.2974676489830017\n",
            "##### Train Epoch: 2  [200/7000  (36%)]\tLoss:0.297468\n",
            "Overall Loss=0.3008 Mask loss=0.01 Depth loss=0.28:  71% 100/140 [01:07<00:26,  1.49it/s]batch_idx: 100\n",
            "loss: 0.300812304019928\n",
            "##### Train Epoch: 2  [400/7000  (71%)]\tLoss:0.300812\n",
            "Overall Loss=0.2969 Mask loss=0.01 Depth loss=0.27: 100% 140/140 [01:33<00:00,  1.50it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Validation loss decreased (0.296927 --> 0.296854).  Saving model ...\n",
            "\n",
            "\n",
            "\n",
            "**************Model saved**************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3150070160627365\n",
            " 83% 50/60 [00:31<00:06,  1.65it/s]batch_idx: 50\n",
            "loss: 0.310001403093338\n",
            "100% 60/60 [00:37<00:00,  1.61it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3130, Mask Loss: 0.02, Depth Loss: 0.28\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:3#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3001 Mask loss=0.01 Depth loss=0.28:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3000560998916626\n",
            "##### Train Epoch: 3  [0/7000  (0%)]\tLoss:0.300056\n",
            "Overall Loss=0.2975 Mask loss=0.01 Depth loss=0.27:  36% 50/140 [00:33<00:58,  1.53it/s]batch_idx: 50\n",
            "loss: 0.2975441813468933\n",
            "##### Train Epoch: 3  [200/7000  (36%)]\tLoss:0.297544\n",
            "Overall Loss=0.2955 Mask loss=0.01 Depth loss=0.27:  71% 100/140 [01:06<00:25,  1.55it/s]batch_idx: 100\n",
            "loss: 0.2955484986305237\n",
            "##### Train Epoch: 3  [400/7000  (71%)]\tLoss:0.295548\n",
            "Overall Loss=0.2967 Mask loss=0.01 Depth loss=0.27: 100% 140/140 [01:32<00:00,  1.52it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Validation loss decreased (0.296854 --> 0.296688).  Saving model ...\n",
            "\n",
            "\n",
            "\n",
            "**************Model saved**************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3110477291047573\n",
            " 83% 50/60 [00:31<00:06,  1.61it/s]batch_idx: 50\n",
            "loss: 0.31228500232100487\n",
            "100% 60/60 [00:37<00:00,  1.60it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3106, Mask Loss: 0.02, Depth Loss: 0.28\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:4#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.2976 Mask loss=0.01 Depth loss=0.27:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.29756540060043335\n",
            "##### Train Epoch: 4  [0/7000  (0%)]\tLoss:0.297565\n",
            "Overall Loss=0.2965 Mask loss=0.01 Depth loss=0.27:  36% 50/140 [00:33<00:58,  1.55it/s]batch_idx: 50\n",
            "loss: 0.29652419686317444\n",
            "##### Train Epoch: 4  [200/7000  (36%)]\tLoss:0.296524\n",
            "Overall Loss=0.2979 Mask loss=0.01 Depth loss=0.27:  71% 100/140 [01:06<00:25,  1.55it/s]batch_idx: 100\n",
            "loss: 0.29788172245025635\n",
            "##### Train Epoch: 4  [400/7000  (71%)]\tLoss:0.297882\n",
            "Overall Loss=0.2956 Mask loss=0.01 Depth loss=0.27: 100% 140/140 [01:32<00:00,  1.51it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Validation loss decreased (0.296688 --> 0.295602).  Saving model ...\n",
            "\n",
            "\n",
            "\n",
            "**************Model saved**************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3125603720545769\n",
            " 83% 50/60 [00:31<00:06,  1.62it/s]batch_idx: 50\n",
            "loss: 0.3107873946428299\n",
            "100% 60/60 [00:37<00:00,  1.61it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3138, Mask Loss: 0.02, Depth Loss: 0.28\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:5#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.2969 Mask loss=0.01 Depth loss=0.27:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.2968956530094147\n",
            "##### Train Epoch: 5  [0/7000  (0%)]\tLoss:0.296896\n",
            "Overall Loss=0.2976 Mask loss=0.01 Depth loss=0.27:  36% 50/140 [00:33<00:58,  1.55it/s]batch_idx: 50\n",
            "loss: 0.2976331412792206\n",
            "##### Train Epoch: 5  [200/7000  (36%)]\tLoss:0.297633\n",
            "Overall Loss=0.2958 Mask loss=0.01 Depth loss=0.27:  71% 100/140 [01:05<00:26,  1.53it/s]batch_idx: 100\n",
            "loss: 0.2957911193370819\n",
            "##### Train Epoch: 5  [400/7000  (71%)]\tLoss:0.295791\n",
            "Overall Loss=0.2968 Mask loss=0.01 Depth loss=0.27: 100% 140/140 [01:31<00:00,  1.53it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.31204328313469887\n",
            " 83% 50/60 [00:30<00:06,  1.64it/s]batch_idx: 50\n",
            "loss: 0.31341636925935745\n",
            "100% 60/60 [00:36<00:00,  1.63it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3118, Mask Loss: 0.02, Depth Loss: 0.28\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "time: 23min 1s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "WIhuE8usDN14"
      },
      "source": [
        "# Batch_6 dataset : \n",
        "        Dataset size : 30K\n",
        "            - Train (70%)  : 21K  \n",
        "            - Test  (30%)  : 9K\n",
        "        Batch Size   : 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "89af5111-b0e4-4ef3-bbb2-43b4022dec34",
        "id": "E52b-HqqDN17",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "os.chdir(r'/content/drive/My Drive/EVA4/S15/scripts/pythonFiles')\n",
        "!python train_mask_depth.py -z '/content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_6.zip' -e 5  -bs 50"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are executing model on : cuda\n",
            "Dataset using : /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_6.zip\n",
            "Train Dataset : 21000\n",
            "Test Dataset : 9000\n",
            "\t In batch size of : 50\n",
            "cuda\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]          18,816\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "   ConvTranspose2d-5        [-1, 128, 111, 111]           8,192\n",
            "            Conv2d-6          [-1, 128, 28, 28]          73,728\n",
            "            Conv2d-7          [-1, 128, 28, 28]          16,384\n",
            "       BatchNorm2d-8          [-1, 128, 28, 28]             256\n",
            "              ReLU-9          [-1, 128, 28, 28]               0\n",
            "           Conv2d-10          [-1, 128, 14, 14]         147,456\n",
            "           Conv2d-11          [-1, 128, 14, 14]          16,384\n",
            "      BatchNorm2d-12          [-1, 128, 14, 14]             256\n",
            "             ReLU-13          [-1, 128, 14, 14]               0\n",
            "         Downsize-14          [-1, 128, 14, 14]               0\n",
            "  ConvTranspose2d-15          [-1, 256, 27, 27]          32,768\n",
            "           Conv2d-16            [-1, 256, 7, 7]         294,912\n",
            "           Conv2d-17            [-1, 256, 7, 7]          65,536\n",
            "      BatchNorm2d-18            [-1, 256, 7, 7]             512\n",
            "             ReLU-19            [-1, 256, 7, 7]               0\n",
            "           Conv2d-20            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-21            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-22            [-1, 256, 4, 4]             512\n",
            "             ReLU-23            [-1, 256, 4, 4]               0\n",
            "         Downsize-24            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-25            [-1, 512, 7, 7]         131,072\n",
            "           Conv2d-26            [-1, 512, 2, 2]       1,179,648\n",
            "           Conv2d-27            [-1, 512, 2, 2]         262,144\n",
            "      BatchNorm2d-28            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-29            [-1, 512, 2, 2]               0\n",
            "           Conv2d-30            [-1, 512, 1, 1]       2,359,296\n",
            "           Conv2d-31            [-1, 512, 1, 1]         262,144\n",
            "      BatchNorm2d-32            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-33            [-1, 512, 1, 1]               0\n",
            "         Downsize-34            [-1, 512, 1, 1]               0\n",
            "  ConvTranspose2d-35            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-36            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-37            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-38            [-1, 256, 4, 4]             512\n",
            "             ReLU-39            [-1, 256, 4, 4]               0\n",
            "           Conv2d-40            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-41            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-42            [-1, 256, 4, 4]             512\n",
            "             ReLU-43            [-1, 256, 4, 4]               0\n",
            "           Upsize-44            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-45          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-46          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-47          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-48          [-1, 128, 28, 28]             256\n",
            "             ReLU-49          [-1, 128, 28, 28]               0\n",
            "           Conv2d-50          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-51          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-52          [-1, 128, 28, 28]             256\n",
            "             ReLU-53          [-1, 128, 28, 28]               0\n",
            "           Upsize-54          [-1, 128, 28, 28]               0\n",
            "  ConvTranspose2d-55           [-1, 64, 56, 56]          73,728\n",
            "           Conv2d-56           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-57           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-58           [-1, 64, 56, 56]             128\n",
            "             ReLU-59           [-1, 64, 56, 56]               0\n",
            "           Conv2d-60           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-61           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-62           [-1, 64, 56, 56]             128\n",
            "             ReLU-63           [-1, 64, 56, 56]               0\n",
            "           Upsize-64           [-1, 64, 56, 56]               0\n",
            "  ConvTranspose2d-65         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-66         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-67         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-68         [-1, 64, 112, 112]             128\n",
            "             ReLU-69         [-1, 64, 112, 112]               0\n",
            "           Conv2d-70         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-71         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-72         [-1, 64, 112, 112]             128\n",
            "             ReLU-73         [-1, 64, 112, 112]               0\n",
            "           Upsize-74         [-1, 64, 112, 112]               0\n",
            "  ConvTranspose2d-75         [-1, 32, 224, 224]          18,432\n",
            "           Conv2d-76         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-77         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-78         [-1, 32, 224, 224]              64\n",
            "             ReLU-79         [-1, 32, 224, 224]               0\n",
            "           Conv2d-80         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-81         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-82         [-1, 32, 224, 224]              64\n",
            "             ReLU-83         [-1, 32, 224, 224]               0\n",
            "           Upsize-84         [-1, 32, 224, 224]               0\n",
            "           Conv2d-85          [-1, 1, 224, 224]              32\n",
            "  ConvTranspose2d-86            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-87            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-88            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-89            [-1, 256, 4, 4]             512\n",
            "             ReLU-90            [-1, 256, 4, 4]               0\n",
            "           Conv2d-91            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-92            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-93            [-1, 256, 4, 4]             512\n",
            "             ReLU-94            [-1, 256, 4, 4]               0\n",
            "           Upsize-95            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-96          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-97          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-98          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-99          [-1, 128, 28, 28]             256\n",
            "            ReLU-100          [-1, 128, 28, 28]               0\n",
            "          Conv2d-101          [-1, 128, 28, 28]         147,456\n",
            "          Conv2d-102          [-1, 128, 28, 28]          16,384\n",
            "     BatchNorm2d-103          [-1, 128, 28, 28]             256\n",
            "            ReLU-104          [-1, 128, 28, 28]               0\n",
            "          Upsize-105          [-1, 128, 28, 28]               0\n",
            " ConvTranspose2d-106           [-1, 64, 56, 56]          73,728\n",
            "          Conv2d-107           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-108           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-109           [-1, 64, 56, 56]             128\n",
            "            ReLU-110           [-1, 64, 56, 56]               0\n",
            "          Conv2d-111           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-112           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-113           [-1, 64, 56, 56]             128\n",
            "            ReLU-114           [-1, 64, 56, 56]               0\n",
            "          Upsize-115           [-1, 64, 56, 56]               0\n",
            " ConvTranspose2d-116         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-117         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-118         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-119         [-1, 64, 112, 112]             128\n",
            "            ReLU-120         [-1, 64, 112, 112]               0\n",
            "          Conv2d-121         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-122         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-123         [-1, 64, 112, 112]             128\n",
            "            ReLU-124         [-1, 64, 112, 112]               0\n",
            "          Upsize-125         [-1, 64, 112, 112]               0\n",
            " ConvTranspose2d-126         [-1, 32, 224, 224]          18,432\n",
            "          Conv2d-127         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-128         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-129         [-1, 32, 224, 224]              64\n",
            "            ReLU-130         [-1, 32, 224, 224]               0\n",
            "          Conv2d-131         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-132         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-133         [-1, 32, 224, 224]              64\n",
            "            ReLU-134         [-1, 32, 224, 224]               0\n",
            "          Upsize-135         [-1, 32, 224, 224]               0\n",
            "          Conv2d-136          [-1, 3, 224, 224]              99\n",
            "================================================================\n",
            "Total params: 12,384,643\n",
            "Trainable params: 12,384,643\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.15\n",
            "Forward/backward pass size (MB): 453.79\n",
            "Params size (MB): 47.24\n",
            "Estimated Total Size (MB): 502.18\n",
            "----------------------------------------------------------------\n",
            "You are running /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_6.zip dataset for 5 epochs\n",
            "Loading model : batch_best.ckp.pt\n",
            "Model is loaded and valid_loss_min is :0.2956017255783081\n",
            "\n",
            "###########EPOCH:1#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3209 Mask loss=0.01 Depth loss=0.30:   0% 0/140 [01:38<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3209450840950012\n",
            "##### Train Epoch: 1  [0/7000  (0%)]\tLoss:0.320945\n",
            "Overall Loss=0.2991 Mask loss=0.01 Depth loss=0.28:  36% 50/140 [16:06<04:31,  3.02s/it]batch_idx: 50\n",
            "loss: 0.29907360672950745\n",
            "##### Train Epoch: 1  [200/7000  (36%)]\tLoss:0.299074\n",
            "Overall Loss=0.2968 Mask loss=0.01 Depth loss=0.27:  71% 100/140 [17:08<00:39,  1.02it/s]batch_idx: 100\n",
            "loss: 0.2968340814113617\n",
            "##### Train Epoch: 1  [400/7000  (71%)]\tLoss:0.296834\n",
            "Overall Loss=0.2983 Mask loss=0.01 Depth loss=0.28: 100% 140/140 [17:36<00:00,  7.55s/it]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.31160347163677216\n",
            " 83% 50/60 [00:32<00:06,  1.58it/s]batch_idx: 50\n",
            "loss: 0.31194039061665535\n",
            "100% 60/60 [00:38<00:00,  1.55it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3113, Mask Loss: 0.02, Depth Loss: 0.28\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:2#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.2964 Mask loss=0.01 Depth loss=0.27:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.2964076101779938\n",
            "##### Train Epoch: 2  [0/7000  (0%)]\tLoss:0.296408\n",
            "Overall Loss=0.3004 Mask loss=0.01 Depth loss=0.28:  36% 50/140 [00:34<01:00,  1.50it/s]batch_idx: 50\n",
            "loss: 0.30038243532180786\n",
            "##### Train Epoch: 2  [200/7000  (36%)]\tLoss:0.300382\n",
            "Overall Loss=0.2947 Mask loss=0.01 Depth loss=0.27:  71% 100/140 [01:08<00:26,  1.49it/s]batch_idx: 100\n",
            "loss: 0.2946823239326477\n",
            "##### Train Epoch: 2  [400/7000  (71%)]\tLoss:0.294682\n",
            "Overall Loss=0.2959 Mask loss=0.01 Depth loss=0.27: 100% 140/140 [01:35<00:00,  1.47it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3124627787619829\n",
            " 83% 50/60 [00:32<00:06,  1.55it/s]batch_idx: 50\n",
            "loss: 0.31009281799197197\n",
            "100% 60/60 [00:38<00:00,  1.54it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3090, Mask Loss: 0.02, Depth Loss: 0.28\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:3#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.2939 Mask loss=0.01 Depth loss=0.27:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.29387763142585754\n",
            "##### Train Epoch: 3  [0/7000  (0%)]\tLoss:0.293878\n",
            "Overall Loss=0.2934 Mask loss=0.01 Depth loss=0.27:  36% 50/140 [00:34<01:00,  1.49it/s]batch_idx: 50\n",
            "loss: 0.29343926906585693\n",
            "##### Train Epoch: 3  [200/7000  (36%)]\tLoss:0.293439\n",
            "Overall Loss=0.2963 Mask loss=0.01 Depth loss=0.27:  71% 100/140 [01:08<00:26,  1.50it/s]batch_idx: 100\n",
            "loss: 0.2963061034679413\n",
            "##### Train Epoch: 3  [400/7000  (71%)]\tLoss:0.296306\n",
            "Overall Loss=0.2954 Mask loss=0.01 Depth loss=0.27: 100% 140/140 [01:35<00:00,  1.46it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Validation loss decreased (0.295602 --> 0.295359).  Saving model ...\n",
            "\n",
            "\n",
            "\n",
            "**************Model saved**************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.30749519541859627\n",
            " 83% 50/60 [00:32<00:06,  1.57it/s]batch_idx: 50\n",
            "loss: 0.310729306191206\n",
            "100% 60/60 [00:38<00:00,  1.55it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3087, Mask Loss: 0.01, Depth Loss: 0.28\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:4#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.2964 Mask loss=0.01 Depth loss=0.27:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.29644203186035156\n",
            "##### Train Epoch: 4  [0/7000  (0%)]\tLoss:0.296442\n",
            "Overall Loss=0.2928 Mask loss=0.01 Depth loss=0.27:  36% 50/140 [00:34<01:01,  1.47it/s]batch_idx: 50\n",
            "loss: 0.2927951216697693\n",
            "##### Train Epoch: 4  [200/7000  (36%)]\tLoss:0.292795\n",
            "Overall Loss=0.2952 Mask loss=0.01 Depth loss=0.27:  71% 100/140 [01:08<00:26,  1.49it/s]batch_idx: 100\n",
            "loss: 0.2951967716217041\n",
            "##### Train Epoch: 4  [400/7000  (71%)]\tLoss:0.295197\n",
            "Overall Loss=0.2935 Mask loss=0.01 Depth loss=0.27: 100% 140/140 [01:35<00:00,  1.47it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Validation loss decreased (0.295359 --> 0.293484).  Saving model ...\n",
            "\n",
            "\n",
            "\n",
            "**************Model saved**************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3095622956752777\n",
            " 83% 50/60 [00:32<00:06,  1.57it/s]batch_idx: 50\n",
            "loss: 0.310451727360487\n",
            "100% 60/60 [00:38<00:00,  1.56it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3106, Mask Loss: 0.02, Depth Loss: 0.28\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:5#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3002 Mask loss=0.01 Depth loss=0.28:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.30023834109306335\n",
            "##### Train Epoch: 5  [0/7000  (0%)]\tLoss:0.300238\n",
            "Overall Loss=0.2977 Mask loss=0.01 Depth loss=0.28:  36% 50/140 [00:35<01:00,  1.48it/s]batch_idx: 50\n",
            "loss: 0.29769477248191833\n",
            "##### Train Epoch: 5  [200/7000  (36%)]\tLoss:0.297695\n",
            "Overall Loss=0.2950 Mask loss=0.01 Depth loss=0.27:  71% 100/140 [01:09<00:26,  1.49it/s]batch_idx: 100\n",
            "loss: 0.29497405886650085\n",
            "##### Train Epoch: 5  [400/7000  (71%)]\tLoss:0.294974\n",
            "Overall Loss=0.2956 Mask loss=0.01 Depth loss=0.27: 100% 140/140 [01:35<00:00,  1.46it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.30802703835070133\n",
            " 83% 50/60 [00:31<00:06,  1.58it/s]batch_idx: 50\n",
            "loss: 0.3086598515510559\n",
            "100% 60/60 [00:38<00:00,  1.57it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3098, Mask Loss: 0.02, Depth Loss: 0.28\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "time: 28min 42s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "sq0RAxyvLh27"
      },
      "source": [
        "# Batch_7 dataset : \n",
        "        Dataset size : 30K\n",
        "            - Train (70%)  : 21K  \n",
        "            - Test  (30%)  : 9K\n",
        "        Batch Size   : 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4a97daec-92b6-4833-cd65-a0ffa3d27f4d",
        "id": "_Di5zDuYLh3D",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "os.chdir(r'/content/drive/My Drive/EVA4/S15/scripts/pythonFiles')\n",
        "!python train_mask_depth.py -z '/content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_7.zip' -e 5  -bs 50"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are executing model on : cuda\n",
            "Dataset using : /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_7.zip\n",
            "Train Dataset : 21000\n",
            "Test Dataset : 9000\n",
            "\t In batch size of : 50\n",
            "cuda\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]          18,816\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "   ConvTranspose2d-5        [-1, 128, 111, 111]           8,192\n",
            "            Conv2d-6          [-1, 128, 28, 28]          73,728\n",
            "            Conv2d-7          [-1, 128, 28, 28]          16,384\n",
            "       BatchNorm2d-8          [-1, 128, 28, 28]             256\n",
            "              ReLU-9          [-1, 128, 28, 28]               0\n",
            "           Conv2d-10          [-1, 128, 14, 14]         147,456\n",
            "           Conv2d-11          [-1, 128, 14, 14]          16,384\n",
            "      BatchNorm2d-12          [-1, 128, 14, 14]             256\n",
            "             ReLU-13          [-1, 128, 14, 14]               0\n",
            "         Downsize-14          [-1, 128, 14, 14]               0\n",
            "  ConvTranspose2d-15          [-1, 256, 27, 27]          32,768\n",
            "           Conv2d-16            [-1, 256, 7, 7]         294,912\n",
            "           Conv2d-17            [-1, 256, 7, 7]          65,536\n",
            "      BatchNorm2d-18            [-1, 256, 7, 7]             512\n",
            "             ReLU-19            [-1, 256, 7, 7]               0\n",
            "           Conv2d-20            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-21            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-22            [-1, 256, 4, 4]             512\n",
            "             ReLU-23            [-1, 256, 4, 4]               0\n",
            "         Downsize-24            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-25            [-1, 512, 7, 7]         131,072\n",
            "           Conv2d-26            [-1, 512, 2, 2]       1,179,648\n",
            "           Conv2d-27            [-1, 512, 2, 2]         262,144\n",
            "      BatchNorm2d-28            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-29            [-1, 512, 2, 2]               0\n",
            "           Conv2d-30            [-1, 512, 1, 1]       2,359,296\n",
            "           Conv2d-31            [-1, 512, 1, 1]         262,144\n",
            "      BatchNorm2d-32            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-33            [-1, 512, 1, 1]               0\n",
            "         Downsize-34            [-1, 512, 1, 1]               0\n",
            "  ConvTranspose2d-35            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-36            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-37            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-38            [-1, 256, 4, 4]             512\n",
            "             ReLU-39            [-1, 256, 4, 4]               0\n",
            "           Conv2d-40            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-41            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-42            [-1, 256, 4, 4]             512\n",
            "             ReLU-43            [-1, 256, 4, 4]               0\n",
            "           Upsize-44            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-45          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-46          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-47          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-48          [-1, 128, 28, 28]             256\n",
            "             ReLU-49          [-1, 128, 28, 28]               0\n",
            "           Conv2d-50          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-51          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-52          [-1, 128, 28, 28]             256\n",
            "             ReLU-53          [-1, 128, 28, 28]               0\n",
            "           Upsize-54          [-1, 128, 28, 28]               0\n",
            "  ConvTranspose2d-55           [-1, 64, 56, 56]          73,728\n",
            "           Conv2d-56           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-57           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-58           [-1, 64, 56, 56]             128\n",
            "             ReLU-59           [-1, 64, 56, 56]               0\n",
            "           Conv2d-60           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-61           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-62           [-1, 64, 56, 56]             128\n",
            "             ReLU-63           [-1, 64, 56, 56]               0\n",
            "           Upsize-64           [-1, 64, 56, 56]               0\n",
            "  ConvTranspose2d-65         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-66         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-67         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-68         [-1, 64, 112, 112]             128\n",
            "             ReLU-69         [-1, 64, 112, 112]               0\n",
            "           Conv2d-70         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-71         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-72         [-1, 64, 112, 112]             128\n",
            "             ReLU-73         [-1, 64, 112, 112]               0\n",
            "           Upsize-74         [-1, 64, 112, 112]               0\n",
            "  ConvTranspose2d-75         [-1, 32, 224, 224]          18,432\n",
            "           Conv2d-76         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-77         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-78         [-1, 32, 224, 224]              64\n",
            "             ReLU-79         [-1, 32, 224, 224]               0\n",
            "           Conv2d-80         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-81         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-82         [-1, 32, 224, 224]              64\n",
            "             ReLU-83         [-1, 32, 224, 224]               0\n",
            "           Upsize-84         [-1, 32, 224, 224]               0\n",
            "           Conv2d-85          [-1, 1, 224, 224]              32\n",
            "  ConvTranspose2d-86            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-87            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-88            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-89            [-1, 256, 4, 4]             512\n",
            "             ReLU-90            [-1, 256, 4, 4]               0\n",
            "           Conv2d-91            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-92            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-93            [-1, 256, 4, 4]             512\n",
            "             ReLU-94            [-1, 256, 4, 4]               0\n",
            "           Upsize-95            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-96          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-97          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-98          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-99          [-1, 128, 28, 28]             256\n",
            "            ReLU-100          [-1, 128, 28, 28]               0\n",
            "          Conv2d-101          [-1, 128, 28, 28]         147,456\n",
            "          Conv2d-102          [-1, 128, 28, 28]          16,384\n",
            "     BatchNorm2d-103          [-1, 128, 28, 28]             256\n",
            "            ReLU-104          [-1, 128, 28, 28]               0\n",
            "          Upsize-105          [-1, 128, 28, 28]               0\n",
            " ConvTranspose2d-106           [-1, 64, 56, 56]          73,728\n",
            "          Conv2d-107           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-108           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-109           [-1, 64, 56, 56]             128\n",
            "            ReLU-110           [-1, 64, 56, 56]               0\n",
            "          Conv2d-111           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-112           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-113           [-1, 64, 56, 56]             128\n",
            "            ReLU-114           [-1, 64, 56, 56]               0\n",
            "          Upsize-115           [-1, 64, 56, 56]               0\n",
            " ConvTranspose2d-116         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-117         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-118         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-119         [-1, 64, 112, 112]             128\n",
            "            ReLU-120         [-1, 64, 112, 112]               0\n",
            "          Conv2d-121         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-122         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-123         [-1, 64, 112, 112]             128\n",
            "            ReLU-124         [-1, 64, 112, 112]               0\n",
            "          Upsize-125         [-1, 64, 112, 112]               0\n",
            " ConvTranspose2d-126         [-1, 32, 224, 224]          18,432\n",
            "          Conv2d-127         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-128         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-129         [-1, 32, 224, 224]              64\n",
            "            ReLU-130         [-1, 32, 224, 224]               0\n",
            "          Conv2d-131         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-132         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-133         [-1, 32, 224, 224]              64\n",
            "            ReLU-134         [-1, 32, 224, 224]               0\n",
            "          Upsize-135         [-1, 32, 224, 224]               0\n",
            "          Conv2d-136          [-1, 3, 224, 224]              99\n",
            "================================================================\n",
            "Total params: 12,384,643\n",
            "Trainable params: 12,384,643\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.15\n",
            "Forward/backward pass size (MB): 453.79\n",
            "Params size (MB): 47.24\n",
            "Estimated Total Size (MB): 502.18\n",
            "----------------------------------------------------------------\n",
            "You are running /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_7.zip dataset for 5 epochs\n",
            "Loading model : batch_best.ckp.pt\n",
            "Model is loaded and valid_loss_min is :0.29348382353782654\n",
            "\n",
            "###########EPOCH:1#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3904 Mask loss=0.01 Depth loss=0.37:   0% 0/140 [01:13<?, ?it/s]batch_idx: 0\n",
            "loss: 0.39041468501091003\n",
            "##### Train Epoch: 1  [0/7000  (0%)]\tLoss:0.390415\n",
            "Overall Loss=0.3236 Mask loss=0.01 Depth loss=0.30:  36% 50/140 [10:29<02:46,  1.85s/it]batch_idx: 50\n",
            "loss: 0.3236168324947357\n",
            "##### Train Epoch: 1  [200/7000  (36%)]\tLoss:0.323617\n",
            "Overall Loss=0.3174 Mask loss=0.01 Depth loss=0.29:  71% 100/140 [11:16<00:29,  1.35it/s]batch_idx: 100\n",
            "loss: 0.3174440264701843\n",
            "##### Train Epoch: 1  [400/7000  (71%)]\tLoss:0.317444\n",
            "Overall Loss=0.3184 Mask loss=0.01 Depth loss=0.29: 100% 140/140 [11:42<00:00,  5.02s/it]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.34065742418169975\n",
            " 83% 50/60 [00:31<00:06,  1.60it/s]batch_idx: 50\n",
            "loss: 0.331196416169405\n",
            "100% 60/60 [00:37<00:00,  1.59it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3329, Mask Loss: 0.02, Depth Loss: 0.30\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:2#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3138 Mask loss=0.01 Depth loss=0.29:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.31378358602523804\n",
            "##### Train Epoch: 2  [0/7000  (0%)]\tLoss:0.313784\n",
            "Overall Loss=0.3141 Mask loss=0.01 Depth loss=0.29:  36% 50/140 [00:34<00:59,  1.51it/s]batch_idx: 50\n",
            "loss: 0.31407514214515686\n",
            "##### Train Epoch: 2  [200/7000  (36%)]\tLoss:0.314075\n",
            "Overall Loss=0.3141 Mask loss=0.01 Depth loss=0.29:  71% 100/140 [01:08<00:26,  1.49it/s]batch_idx: 100\n",
            "loss: 0.3140949606895447\n",
            "##### Train Epoch: 2  [400/7000  (71%)]\tLoss:0.314095\n",
            "Overall Loss=0.3182 Mask loss=0.01 Depth loss=0.30: 100% 140/140 [01:34<00:00,  1.48it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.329082440584898\n",
            " 83% 50/60 [00:32<00:06,  1.51it/s]batch_idx: 50\n",
            "loss: 0.3262364063411951\n",
            "100% 60/60 [00:38<00:00,  1.55it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3278, Mask Loss: 0.01, Depth Loss: 0.30\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:3#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3160 Mask loss=0.01 Depth loss=0.29:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.316039502620697\n",
            "##### Train Epoch: 3  [0/7000  (0%)]\tLoss:0.316040\n",
            "Overall Loss=0.3066 Mask loss=0.01 Depth loss=0.28:  36% 50/140 [00:34<00:59,  1.51it/s]batch_idx: 50\n",
            "loss: 0.3065701723098755\n",
            "##### Train Epoch: 3  [200/7000  (36%)]\tLoss:0.306570\n",
            "Overall Loss=0.3133 Mask loss=0.01 Depth loss=0.29:  71% 100/140 [01:07<00:26,  1.50it/s]batch_idx: 100\n",
            "loss: 0.31326887011528015\n",
            "##### Train Epoch: 3  [400/7000  (71%)]\tLoss:0.313269\n",
            "Overall Loss=0.3098 Mask loss=0.01 Depth loss=0.29: 100% 140/140 [01:33<00:00,  1.49it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.32883869484066963\n",
            " 83% 50/60 [00:31<00:06,  1.58it/s]batch_idx: 50\n",
            "loss: 0.3259375225752592\n",
            "100% 60/60 [00:37<00:00,  1.58it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3257, Mask Loss: 0.01, Depth Loss: 0.30\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:4#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3111 Mask loss=0.01 Depth loss=0.29:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3111374080181122\n",
            "##### Train Epoch: 4  [0/7000  (0%)]\tLoss:0.311137\n",
            "Overall Loss=0.3138 Mask loss=0.01 Depth loss=0.29:  36% 50/140 [00:34<00:59,  1.51it/s]batch_idx: 50\n",
            "loss: 0.3138192892074585\n",
            "##### Train Epoch: 4  [200/7000  (36%)]\tLoss:0.313819\n",
            "Overall Loss=0.3129 Mask loss=0.01 Depth loss=0.29:  71% 100/140 [01:07<00:26,  1.51it/s]batch_idx: 100\n",
            "loss: 0.3128858804702759\n",
            "##### Train Epoch: 4  [400/7000  (71%)]\tLoss:0.312886\n",
            "Overall Loss=0.3110 Mask loss=0.01 Depth loss=0.29: 100% 140/140 [01:33<00:00,  1.49it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3186202496290207\n",
            " 83% 50/60 [00:31<00:06,  1.59it/s]batch_idx: 50\n",
            "loss: 0.32929323241114616\n",
            "100% 60/60 [00:38<00:00,  1.57it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3244, Mask Loss: 0.01, Depth Loss: 0.30\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:5#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3146 Mask loss=0.01 Depth loss=0.29:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.31462717056274414\n",
            "##### Train Epoch: 5  [0/7000  (0%)]\tLoss:0.314627\n",
            "Overall Loss=0.3159 Mask loss=0.01 Depth loss=0.29:  36% 50/140 [00:34<01:00,  1.48it/s]batch_idx: 50\n",
            "loss: 0.31590643525123596\n",
            "##### Train Epoch: 5  [200/7000  (36%)]\tLoss:0.315906\n",
            "Overall Loss=0.3097 Mask loss=0.01 Depth loss=0.29:  71% 100/140 [01:07<00:26,  1.53it/s]batch_idx: 100\n",
            "loss: 0.3096974790096283\n",
            "##### Train Epoch: 5  [400/7000  (71%)]\tLoss:0.309697\n",
            "Overall Loss=0.3044 Mask loss=0.01 Depth loss=0.28: 100% 140/140 [01:34<00:00,  1.48it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.32789846509695053\n",
            " 83% 50/60 [00:31<00:06,  1.59it/s]batch_idx: 50\n",
            "loss: 0.31919732876122\n",
            "100% 60/60 [00:37<00:00,  1.58it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3264, Mask Loss: 0.02, Depth Loss: 0.30\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "time: 23min 2s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5s4ofb1_RFld"
      },
      "source": [
        "# Batch_8 dataset : \n",
        "        Dataset size : 30K\n",
        "            - Train (70%)  : 21K  \n",
        "            - Test  (30%)  : 9K\n",
        "        Batch Size   : 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bd0be0d2-613b-4e1e-d036-6aaec596d41f",
        "id": "qrv1SDjLRFlf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "os.chdir(r'/content/drive/My Drive/EVA4/S15/scripts/pythonFiles')\n",
        "!python train_mask_depth.py -z '/content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_8.zip' -e 5  -bs 50"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are executing model on : cuda\n",
            "Dataset using : /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_8.zip\n",
            "Train Dataset : 21000\n",
            "Test Dataset : 9000\n",
            "\t In batch size of : 50\n",
            "cuda\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]          18,816\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "   ConvTranspose2d-5        [-1, 128, 111, 111]           8,192\n",
            "            Conv2d-6          [-1, 128, 28, 28]          73,728\n",
            "            Conv2d-7          [-1, 128, 28, 28]          16,384\n",
            "       BatchNorm2d-8          [-1, 128, 28, 28]             256\n",
            "              ReLU-9          [-1, 128, 28, 28]               0\n",
            "           Conv2d-10          [-1, 128, 14, 14]         147,456\n",
            "           Conv2d-11          [-1, 128, 14, 14]          16,384\n",
            "      BatchNorm2d-12          [-1, 128, 14, 14]             256\n",
            "             ReLU-13          [-1, 128, 14, 14]               0\n",
            "         Downsize-14          [-1, 128, 14, 14]               0\n",
            "  ConvTranspose2d-15          [-1, 256, 27, 27]          32,768\n",
            "           Conv2d-16            [-1, 256, 7, 7]         294,912\n",
            "           Conv2d-17            [-1, 256, 7, 7]          65,536\n",
            "      BatchNorm2d-18            [-1, 256, 7, 7]             512\n",
            "             ReLU-19            [-1, 256, 7, 7]               0\n",
            "           Conv2d-20            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-21            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-22            [-1, 256, 4, 4]             512\n",
            "             ReLU-23            [-1, 256, 4, 4]               0\n",
            "         Downsize-24            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-25            [-1, 512, 7, 7]         131,072\n",
            "           Conv2d-26            [-1, 512, 2, 2]       1,179,648\n",
            "           Conv2d-27            [-1, 512, 2, 2]         262,144\n",
            "      BatchNorm2d-28            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-29            [-1, 512, 2, 2]               0\n",
            "           Conv2d-30            [-1, 512, 1, 1]       2,359,296\n",
            "           Conv2d-31            [-1, 512, 1, 1]         262,144\n",
            "      BatchNorm2d-32            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-33            [-1, 512, 1, 1]               0\n",
            "         Downsize-34            [-1, 512, 1, 1]               0\n",
            "  ConvTranspose2d-35            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-36            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-37            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-38            [-1, 256, 4, 4]             512\n",
            "             ReLU-39            [-1, 256, 4, 4]               0\n",
            "           Conv2d-40            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-41            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-42            [-1, 256, 4, 4]             512\n",
            "             ReLU-43            [-1, 256, 4, 4]               0\n",
            "           Upsize-44            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-45          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-46          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-47          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-48          [-1, 128, 28, 28]             256\n",
            "             ReLU-49          [-1, 128, 28, 28]               0\n",
            "           Conv2d-50          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-51          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-52          [-1, 128, 28, 28]             256\n",
            "             ReLU-53          [-1, 128, 28, 28]               0\n",
            "           Upsize-54          [-1, 128, 28, 28]               0\n",
            "  ConvTranspose2d-55           [-1, 64, 56, 56]          73,728\n",
            "           Conv2d-56           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-57           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-58           [-1, 64, 56, 56]             128\n",
            "             ReLU-59           [-1, 64, 56, 56]               0\n",
            "           Conv2d-60           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-61           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-62           [-1, 64, 56, 56]             128\n",
            "             ReLU-63           [-1, 64, 56, 56]               0\n",
            "           Upsize-64           [-1, 64, 56, 56]               0\n",
            "  ConvTranspose2d-65         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-66         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-67         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-68         [-1, 64, 112, 112]             128\n",
            "             ReLU-69         [-1, 64, 112, 112]               0\n",
            "           Conv2d-70         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-71         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-72         [-1, 64, 112, 112]             128\n",
            "             ReLU-73         [-1, 64, 112, 112]               0\n",
            "           Upsize-74         [-1, 64, 112, 112]               0\n",
            "  ConvTranspose2d-75         [-1, 32, 224, 224]          18,432\n",
            "           Conv2d-76         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-77         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-78         [-1, 32, 224, 224]              64\n",
            "             ReLU-79         [-1, 32, 224, 224]               0\n",
            "           Conv2d-80         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-81         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-82         [-1, 32, 224, 224]              64\n",
            "             ReLU-83         [-1, 32, 224, 224]               0\n",
            "           Upsize-84         [-1, 32, 224, 224]               0\n",
            "           Conv2d-85          [-1, 1, 224, 224]              32\n",
            "  ConvTranspose2d-86            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-87            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-88            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-89            [-1, 256, 4, 4]             512\n",
            "             ReLU-90            [-1, 256, 4, 4]               0\n",
            "           Conv2d-91            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-92            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-93            [-1, 256, 4, 4]             512\n",
            "             ReLU-94            [-1, 256, 4, 4]               0\n",
            "           Upsize-95            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-96          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-97          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-98          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-99          [-1, 128, 28, 28]             256\n",
            "            ReLU-100          [-1, 128, 28, 28]               0\n",
            "          Conv2d-101          [-1, 128, 28, 28]         147,456\n",
            "          Conv2d-102          [-1, 128, 28, 28]          16,384\n",
            "     BatchNorm2d-103          [-1, 128, 28, 28]             256\n",
            "            ReLU-104          [-1, 128, 28, 28]               0\n",
            "          Upsize-105          [-1, 128, 28, 28]               0\n",
            " ConvTranspose2d-106           [-1, 64, 56, 56]          73,728\n",
            "          Conv2d-107           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-108           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-109           [-1, 64, 56, 56]             128\n",
            "            ReLU-110           [-1, 64, 56, 56]               0\n",
            "          Conv2d-111           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-112           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-113           [-1, 64, 56, 56]             128\n",
            "            ReLU-114           [-1, 64, 56, 56]               0\n",
            "          Upsize-115           [-1, 64, 56, 56]               0\n",
            " ConvTranspose2d-116         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-117         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-118         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-119         [-1, 64, 112, 112]             128\n",
            "            ReLU-120         [-1, 64, 112, 112]               0\n",
            "          Conv2d-121         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-122         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-123         [-1, 64, 112, 112]             128\n",
            "            ReLU-124         [-1, 64, 112, 112]               0\n",
            "          Upsize-125         [-1, 64, 112, 112]               0\n",
            " ConvTranspose2d-126         [-1, 32, 224, 224]          18,432\n",
            "          Conv2d-127         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-128         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-129         [-1, 32, 224, 224]              64\n",
            "            ReLU-130         [-1, 32, 224, 224]               0\n",
            "          Conv2d-131         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-132         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-133         [-1, 32, 224, 224]              64\n",
            "            ReLU-134         [-1, 32, 224, 224]               0\n",
            "          Upsize-135         [-1, 32, 224, 224]               0\n",
            "          Conv2d-136          [-1, 3, 224, 224]              99\n",
            "================================================================\n",
            "Total params: 12,384,643\n",
            "Trainable params: 12,384,643\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.15\n",
            "Forward/backward pass size (MB): 453.79\n",
            "Params size (MB): 47.24\n",
            "Estimated Total Size (MB): 502.18\n",
            "----------------------------------------------------------------\n",
            "You are running /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_8.zip dataset for 5 epochs\n",
            "Loading model : batch_best.ckp.pt\n",
            "Model is loaded and valid_loss_min is :0.29348382353782654\n",
            "\n",
            "###########EPOCH:1#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.4186 Mask loss=0.01 Depth loss=0.40:   0% 0/140 [01:06<?, ?it/s]batch_idx: 0\n",
            "loss: 0.4186345040798187\n",
            "##### Train Epoch: 1  [0/7000  (0%)]\tLoss:0.418635\n",
            "Overall Loss=0.3291 Mask loss=0.01 Depth loss=0.31:  36% 50/140 [11:36<02:59,  2.00s/it]batch_idx: 50\n",
            "loss: 0.3290592133998871\n",
            "##### Train Epoch: 1  [200/7000  (36%)]\tLoss:0.329059\n",
            "Overall Loss=0.3179 Mask loss=0.01 Depth loss=0.30:  71% 100/140 [12:25<00:39,  1.01it/s]batch_idx: 100\n",
            "loss: 0.3179311752319336\n",
            "##### Train Epoch: 1  [400/7000  (71%)]\tLoss:0.317931\n",
            "Overall Loss=0.3249 Mask loss=0.01 Depth loss=0.30: 100% 140/140 [12:52<00:00,  5.52s/it]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.34247915633022785\n",
            " 83% 50/60 [00:31<00:06,  1.60it/s]batch_idx: 50\n",
            "loss: 0.3396269306540489\n",
            "100% 60/60 [00:37<00:00,  1.59it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3376, Mask Loss: 0.01, Depth Loss: 0.31\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:2#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3218 Mask loss=0.01 Depth loss=0.30:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3218027949333191\n",
            "##### Train Epoch: 2  [0/7000  (0%)]\tLoss:0.321803\n",
            "Overall Loss=0.3161 Mask loss=0.01 Depth loss=0.29:  36% 50/140 [00:34<00:59,  1.52it/s]batch_idx: 50\n",
            "loss: 0.316079705953598\n",
            "##### Train Epoch: 2  [200/7000  (36%)]\tLoss:0.316080\n",
            "Overall Loss=0.3222 Mask loss=0.01 Depth loss=0.30:  71% 100/140 [01:07<00:26,  1.53it/s]batch_idx: 100\n",
            "loss: 0.3222050070762634\n",
            "##### Train Epoch: 2  [400/7000  (71%)]\tLoss:0.322205\n",
            "Overall Loss=0.3244 Mask loss=0.01 Depth loss=0.30: 100% 140/140 [01:33<00:00,  1.50it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.33951982855796814\n",
            " 83% 50/60 [00:31<00:06,  1.60it/s]batch_idx: 50\n",
            "loss: 0.3399441782385111\n",
            "100% 60/60 [00:37<00:00,  1.59it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3380, Mask Loss: 0.02, Depth Loss: 0.31\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:3#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3238 Mask loss=0.01 Depth loss=0.30:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3238179385662079\n",
            "##### Train Epoch: 3  [0/7000  (0%)]\tLoss:0.323818\n",
            "Overall Loss=0.3296 Mask loss=0.01 Depth loss=0.31:  36% 50/140 [00:34<01:02,  1.45it/s]batch_idx: 50\n",
            "loss: 0.3296240568161011\n",
            "##### Train Epoch: 3  [200/7000  (36%)]\tLoss:0.329624\n",
            "Overall Loss=0.3215 Mask loss=0.01 Depth loss=0.30:  71% 100/140 [01:07<00:26,  1.53it/s]batch_idx: 100\n",
            "loss: 0.32153257727622986\n",
            "##### Train Epoch: 3  [400/7000  (71%)]\tLoss:0.321533\n",
            "Overall Loss=0.3231 Mask loss=0.01 Depth loss=0.30: 100% 140/140 [01:33<00:00,  1.49it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.33600014448165894\n",
            " 83% 50/60 [00:31<00:06,  1.60it/s]batch_idx: 50\n",
            "loss: 0.3307669870555401\n",
            "100% 60/60 [00:37<00:00,  1.60it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3341, Mask Loss: 0.01, Depth Loss: 0.31\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:4#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3271 Mask loss=0.01 Depth loss=0.30:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.32707679271698\n",
            "##### Train Epoch: 4  [0/7000  (0%)]\tLoss:0.327077\n",
            "Overall Loss=0.3255 Mask loss=0.01 Depth loss=0.30:  36% 50/140 [00:33<00:59,  1.51it/s]batch_idx: 50\n",
            "loss: 0.3254895508289337\n",
            "##### Train Epoch: 4  [200/7000  (36%)]\tLoss:0.325490\n",
            "Overall Loss=0.3243 Mask loss=0.01 Depth loss=0.30:  71% 100/140 [01:07<00:26,  1.50it/s]batch_idx: 100\n",
            "loss: 0.3242650032043457\n",
            "##### Train Epoch: 4  [400/7000  (71%)]\tLoss:0.324265\n",
            "Overall Loss=0.3201 Mask loss=0.01 Depth loss=0.30: 100% 140/140 [01:33<00:00,  1.50it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3300316222012043\n",
            " 83% 50/60 [00:31<00:06,  1.60it/s]batch_idx: 50\n",
            "loss: 0.33236235938966274\n",
            "100% 60/60 [00:37<00:00,  1.61it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3317, Mask Loss: 0.01, Depth Loss: 0.30\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:5#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3269 Mask loss=0.01 Depth loss=0.30:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.32692986726760864\n",
            "##### Train Epoch: 5  [0/7000  (0%)]\tLoss:0.326930\n",
            "Overall Loss=0.3221 Mask loss=0.01 Depth loss=0.30:  36% 50/140 [00:34<00:59,  1.51it/s]batch_idx: 50\n",
            "loss: 0.32208359241485596\n",
            "##### Train Epoch: 5  [200/7000  (36%)]\tLoss:0.322084\n",
            "Overall Loss=0.3221 Mask loss=0.01 Depth loss=0.30:  71% 100/140 [01:07<00:26,  1.53it/s]batch_idx: 100\n",
            "loss: 0.3220738470554352\n",
            "##### Train Epoch: 5  [400/7000  (71%)]\tLoss:0.322074\n",
            "Overall Loss=0.3228 Mask loss=0.01 Depth loss=0.30: 100% 140/140 [01:33<00:00,  1.50it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3315324652940035\n",
            " 83% 50/60 [00:31<00:06,  1.61it/s]batch_idx: 50\n",
            "loss: 0.3316361401230097\n",
            "100% 60/60 [00:37<00:00,  1.60it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3340, Mask Loss: 0.01, Depth Loss: 0.31\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "time: 24min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "diVW8gt3WyMy"
      },
      "source": [
        "# Batch_9 dataset : \n",
        "        Dataset size : 30K\n",
        "            - Train (70%)  : 21K  \n",
        "            - Test  (30%)  : 9K\n",
        "        Batch Size   : 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "4779fff7-e2eb-476a-fff7-687236340a35",
        "id": "t0IxbGftWyM2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "os.chdir(r'/content/drive/My Drive/EVA4/S15/scripts/pythonFiles')\n",
        "!python train_mask_depth.py -z '/content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_9.zip' -e 5  -bs 50"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are executing model on : cuda\n",
            "Dataset using : /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_9.zip\n",
            "Train Dataset : 21000\n",
            "Test Dataset : 9000\n",
            "\t In batch size of : 50\n",
            "cuda\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]          18,816\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "   ConvTranspose2d-5        [-1, 128, 111, 111]           8,192\n",
            "            Conv2d-6          [-1, 128, 28, 28]          73,728\n",
            "            Conv2d-7          [-1, 128, 28, 28]          16,384\n",
            "       BatchNorm2d-8          [-1, 128, 28, 28]             256\n",
            "              ReLU-9          [-1, 128, 28, 28]               0\n",
            "           Conv2d-10          [-1, 128, 14, 14]         147,456\n",
            "           Conv2d-11          [-1, 128, 14, 14]          16,384\n",
            "      BatchNorm2d-12          [-1, 128, 14, 14]             256\n",
            "             ReLU-13          [-1, 128, 14, 14]               0\n",
            "         Downsize-14          [-1, 128, 14, 14]               0\n",
            "  ConvTranspose2d-15          [-1, 256, 27, 27]          32,768\n",
            "           Conv2d-16            [-1, 256, 7, 7]         294,912\n",
            "           Conv2d-17            [-1, 256, 7, 7]          65,536\n",
            "      BatchNorm2d-18            [-1, 256, 7, 7]             512\n",
            "             ReLU-19            [-1, 256, 7, 7]               0\n",
            "           Conv2d-20            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-21            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-22            [-1, 256, 4, 4]             512\n",
            "             ReLU-23            [-1, 256, 4, 4]               0\n",
            "         Downsize-24            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-25            [-1, 512, 7, 7]         131,072\n",
            "           Conv2d-26            [-1, 512, 2, 2]       1,179,648\n",
            "           Conv2d-27            [-1, 512, 2, 2]         262,144\n",
            "      BatchNorm2d-28            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-29            [-1, 512, 2, 2]               0\n",
            "           Conv2d-30            [-1, 512, 1, 1]       2,359,296\n",
            "           Conv2d-31            [-1, 512, 1, 1]         262,144\n",
            "      BatchNorm2d-32            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-33            [-1, 512, 1, 1]               0\n",
            "         Downsize-34            [-1, 512, 1, 1]               0\n",
            "  ConvTranspose2d-35            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-36            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-37            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-38            [-1, 256, 4, 4]             512\n",
            "             ReLU-39            [-1, 256, 4, 4]               0\n",
            "           Conv2d-40            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-41            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-42            [-1, 256, 4, 4]             512\n",
            "             ReLU-43            [-1, 256, 4, 4]               0\n",
            "           Upsize-44            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-45          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-46          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-47          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-48          [-1, 128, 28, 28]             256\n",
            "             ReLU-49          [-1, 128, 28, 28]               0\n",
            "           Conv2d-50          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-51          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-52          [-1, 128, 28, 28]             256\n",
            "             ReLU-53          [-1, 128, 28, 28]               0\n",
            "           Upsize-54          [-1, 128, 28, 28]               0\n",
            "  ConvTranspose2d-55           [-1, 64, 56, 56]          73,728\n",
            "           Conv2d-56           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-57           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-58           [-1, 64, 56, 56]             128\n",
            "             ReLU-59           [-1, 64, 56, 56]               0\n",
            "           Conv2d-60           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-61           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-62           [-1, 64, 56, 56]             128\n",
            "             ReLU-63           [-1, 64, 56, 56]               0\n",
            "           Upsize-64           [-1, 64, 56, 56]               0\n",
            "  ConvTranspose2d-65         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-66         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-67         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-68         [-1, 64, 112, 112]             128\n",
            "             ReLU-69         [-1, 64, 112, 112]               0\n",
            "           Conv2d-70         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-71         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-72         [-1, 64, 112, 112]             128\n",
            "             ReLU-73         [-1, 64, 112, 112]               0\n",
            "           Upsize-74         [-1, 64, 112, 112]               0\n",
            "  ConvTranspose2d-75         [-1, 32, 224, 224]          18,432\n",
            "           Conv2d-76         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-77         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-78         [-1, 32, 224, 224]              64\n",
            "             ReLU-79         [-1, 32, 224, 224]               0\n",
            "           Conv2d-80         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-81         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-82         [-1, 32, 224, 224]              64\n",
            "             ReLU-83         [-1, 32, 224, 224]               0\n",
            "           Upsize-84         [-1, 32, 224, 224]               0\n",
            "           Conv2d-85          [-1, 1, 224, 224]              32\n",
            "  ConvTranspose2d-86            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-87            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-88            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-89            [-1, 256, 4, 4]             512\n",
            "             ReLU-90            [-1, 256, 4, 4]               0\n",
            "           Conv2d-91            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-92            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-93            [-1, 256, 4, 4]             512\n",
            "             ReLU-94            [-1, 256, 4, 4]               0\n",
            "           Upsize-95            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-96          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-97          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-98          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-99          [-1, 128, 28, 28]             256\n",
            "            ReLU-100          [-1, 128, 28, 28]               0\n",
            "          Conv2d-101          [-1, 128, 28, 28]         147,456\n",
            "          Conv2d-102          [-1, 128, 28, 28]          16,384\n",
            "     BatchNorm2d-103          [-1, 128, 28, 28]             256\n",
            "            ReLU-104          [-1, 128, 28, 28]               0\n",
            "          Upsize-105          [-1, 128, 28, 28]               0\n",
            " ConvTranspose2d-106           [-1, 64, 56, 56]          73,728\n",
            "          Conv2d-107           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-108           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-109           [-1, 64, 56, 56]             128\n",
            "            ReLU-110           [-1, 64, 56, 56]               0\n",
            "          Conv2d-111           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-112           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-113           [-1, 64, 56, 56]             128\n",
            "            ReLU-114           [-1, 64, 56, 56]               0\n",
            "          Upsize-115           [-1, 64, 56, 56]               0\n",
            " ConvTranspose2d-116         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-117         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-118         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-119         [-1, 64, 112, 112]             128\n",
            "            ReLU-120         [-1, 64, 112, 112]               0\n",
            "          Conv2d-121         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-122         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-123         [-1, 64, 112, 112]             128\n",
            "            ReLU-124         [-1, 64, 112, 112]               0\n",
            "          Upsize-125         [-1, 64, 112, 112]               0\n",
            " ConvTranspose2d-126         [-1, 32, 224, 224]          18,432\n",
            "          Conv2d-127         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-128         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-129         [-1, 32, 224, 224]              64\n",
            "            ReLU-130         [-1, 32, 224, 224]               0\n",
            "          Conv2d-131         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-132         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-133         [-1, 32, 224, 224]              64\n",
            "            ReLU-134         [-1, 32, 224, 224]               0\n",
            "          Upsize-135         [-1, 32, 224, 224]               0\n",
            "          Conv2d-136          [-1, 3, 224, 224]              99\n",
            "================================================================\n",
            "Total params: 12,384,643\n",
            "Trainable params: 12,384,643\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.15\n",
            "Forward/backward pass size (MB): 453.79\n",
            "Params size (MB): 47.24\n",
            "Estimated Total Size (MB): 502.18\n",
            "----------------------------------------------------------------\n",
            "You are running /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_9.zip dataset for 5 epochs\n",
            "Loading model : batch_best.ckp.pt\n",
            "Model is loaded and valid_loss_min is :0.29348382353782654\n",
            "\n",
            "###########EPOCH:1#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3789 Mask loss=0.01 Depth loss=0.36:   0% 0/140 [01:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3788585662841797\n",
            "##### Train Epoch: 1  [0/7000  (0%)]\tLoss:0.378859\n",
            "Overall Loss=0.3182 Mask loss=0.01 Depth loss=0.30:  36% 50/140 [11:44<03:01,  2.02s/it]batch_idx: 50\n",
            "loss: 0.3182086646556854\n",
            "##### Train Epoch: 1  [200/7000  (36%)]\tLoss:0.318209\n",
            "Overall Loss=0.3112 Mask loss=0.01 Depth loss=0.29:  71% 100/140 [12:46<00:32,  1.23it/s]batch_idx: 100\n",
            "loss: 0.31120097637176514\n",
            "##### Train Epoch: 1  [400/7000  (71%)]\tLoss:0.311201\n",
            "Overall Loss=0.3162 Mask loss=0.01 Depth loss=0.30: 100% 140/140 [13:13<00:00,  5.67s/it]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3244837298989296\n",
            " 83% 50/60 [00:31<00:06,  1.57it/s]batch_idx: 50\n",
            "loss: 0.3225953858345747\n",
            "100% 60/60 [00:37<00:00,  1.59it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3243, Mask Loss: 0.01, Depth Loss: 0.30\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:2#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3115 Mask loss=0.01 Depth loss=0.29:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.31148552894592285\n",
            "##### Train Epoch: 2  [0/7000  (0%)]\tLoss:0.311486\n",
            "Overall Loss=0.3152 Mask loss=0.01 Depth loss=0.29:  36% 50/140 [00:34<00:59,  1.51it/s]batch_idx: 50\n",
            "loss: 0.31523674726486206\n",
            "##### Train Epoch: 2  [200/7000  (36%)]\tLoss:0.315237\n",
            "Overall Loss=0.3146 Mask loss=0.01 Depth loss=0.29:  71% 100/140 [01:07<00:26,  1.53it/s]batch_idx: 100\n",
            "loss: 0.3145671486854553\n",
            "##### Train Epoch: 2  [400/7000  (71%)]\tLoss:0.314567\n",
            "Overall Loss=0.3080 Mask loss=0.01 Depth loss=0.29: 100% 140/140 [01:33<00:00,  1.50it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.32728447765111923\n",
            " 83% 50/60 [00:31<00:06,  1.60it/s]batch_idx: 50\n",
            "loss: 0.32253834418952465\n",
            "100% 60/60 [00:37<00:00,  1.60it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3234, Mask Loss: 0.01, Depth Loss: 0.29\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:3#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3055 Mask loss=0.01 Depth loss=0.28:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.30546435713768005\n",
            "##### Train Epoch: 3  [0/7000  (0%)]\tLoss:0.305464\n",
            "Overall Loss=0.3149 Mask loss=0.01 Depth loss=0.29:  36% 50/140 [00:34<01:01,  1.47it/s]batch_idx: 50\n",
            "loss: 0.31491878628730774\n",
            "##### Train Epoch: 3  [200/7000  (36%)]\tLoss:0.314919\n",
            "Overall Loss=0.3083 Mask loss=0.01 Depth loss=0.29:  71% 100/140 [01:07<00:26,  1.50it/s]batch_idx: 100\n",
            "loss: 0.30831706523895264\n",
            "##### Train Epoch: 3  [400/7000  (71%)]\tLoss:0.308317\n",
            "Overall Loss=0.3102 Mask loss=0.01 Depth loss=0.29: 100% 140/140 [01:34<00:00,  1.49it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.31854539550840855\n",
            " 83% 50/60 [00:31<00:06,  1.59it/s]batch_idx: 50\n",
            "loss: 0.32397489808499813\n",
            "100% 60/60 [00:37<00:00,  1.58it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3226, Mask Loss: 0.01, Depth Loss: 0.29\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:4#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3082 Mask loss=0.01 Depth loss=0.29:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3082301914691925\n",
            "##### Train Epoch: 4  [0/7000  (0%)]\tLoss:0.308230\n",
            "Overall Loss=0.3111 Mask loss=0.01 Depth loss=0.29:  36% 50/140 [00:34<00:59,  1.52it/s]batch_idx: 50\n",
            "loss: 0.3110710084438324\n",
            "##### Train Epoch: 4  [200/7000  (36%)]\tLoss:0.311071\n",
            "Overall Loss=0.3061 Mask loss=0.01 Depth loss=0.28:  71% 100/140 [01:08<00:26,  1.51it/s]batch_idx: 100\n",
            "loss: 0.30606722831726074\n",
            "##### Train Epoch: 4  [400/7000  (71%)]\tLoss:0.306067\n",
            "Overall Loss=0.3075 Mask loss=0.01 Depth loss=0.29: 100% 140/140 [01:34<00:00,  1.48it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3267406690865755\n",
            " 83% 50/60 [00:31<00:06,  1.61it/s]batch_idx: 50\n",
            "loss: 0.32747078500688076\n",
            "100% 60/60 [00:37<00:00,  1.60it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3232, Mask Loss: 0.01, Depth Loss: 0.29\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:5#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3114 Mask loss=0.01 Depth loss=0.29:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.31138673424720764\n",
            "##### Train Epoch: 5  [0/7000  (0%)]\tLoss:0.311387\n",
            "Overall Loss=0.3106 Mask loss=0.01 Depth loss=0.29:  36% 50/140 [00:34<00:58,  1.53it/s]batch_idx: 50\n",
            "loss: 0.31059980392456055\n",
            "##### Train Epoch: 5  [200/7000  (36%)]\tLoss:0.310600\n",
            "Overall Loss=0.3070 Mask loss=0.01 Depth loss=0.29:  71% 100/140 [01:07<00:26,  1.50it/s]batch_idx: 100\n",
            "loss: 0.3069611191749573\n",
            "##### Train Epoch: 5  [400/7000  (71%)]\tLoss:0.306961\n",
            "Overall Loss=0.3070 Mask loss=0.01 Depth loss=0.28: 100% 140/140 [01:33<00:00,  1.49it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.32154067419469357\n",
            " 83% 50/60 [00:31<00:06,  1.58it/s]batch_idx: 50\n",
            "loss: 0.3262276165187359\n",
            "100% 60/60 [00:37<00:00,  1.60it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3248, Mask Loss: 0.01, Depth Loss: 0.29\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "time: 24min 25s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "gGSf7GRGceTG"
      },
      "source": [
        "# Batch_10 dataset : \n",
        "        Dataset size : 30K\n",
        "            - Train (70%)  : 21K  \n",
        "            - Test  (30%)  : 9K\n",
        "        Batch Size   : 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d9eb6349-0e00-4a2c-da53-f48582c0a8c1",
        "id": "Dl13zm8HceTn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "os.chdir(r'/content/drive/My Drive/EVA4/S15/scripts/pythonFiles')\n",
        "!python train_mask_depth.py -z '/content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_10.zip' -e 5  -bs 50"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are executing model on : cuda\n",
            "Dataset using : /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_10.zip\n",
            "Train Dataset : 21000\n",
            "Test Dataset : 9000\n",
            "\t In batch size of : 50\n",
            "cuda\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]          18,816\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "   ConvTranspose2d-5        [-1, 128, 111, 111]           8,192\n",
            "            Conv2d-6          [-1, 128, 28, 28]          73,728\n",
            "            Conv2d-7          [-1, 128, 28, 28]          16,384\n",
            "       BatchNorm2d-8          [-1, 128, 28, 28]             256\n",
            "              ReLU-9          [-1, 128, 28, 28]               0\n",
            "           Conv2d-10          [-1, 128, 14, 14]         147,456\n",
            "           Conv2d-11          [-1, 128, 14, 14]          16,384\n",
            "      BatchNorm2d-12          [-1, 128, 14, 14]             256\n",
            "             ReLU-13          [-1, 128, 14, 14]               0\n",
            "         Downsize-14          [-1, 128, 14, 14]               0\n",
            "  ConvTranspose2d-15          [-1, 256, 27, 27]          32,768\n",
            "           Conv2d-16            [-1, 256, 7, 7]         294,912\n",
            "           Conv2d-17            [-1, 256, 7, 7]          65,536\n",
            "      BatchNorm2d-18            [-1, 256, 7, 7]             512\n",
            "             ReLU-19            [-1, 256, 7, 7]               0\n",
            "           Conv2d-20            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-21            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-22            [-1, 256, 4, 4]             512\n",
            "             ReLU-23            [-1, 256, 4, 4]               0\n",
            "         Downsize-24            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-25            [-1, 512, 7, 7]         131,072\n",
            "           Conv2d-26            [-1, 512, 2, 2]       1,179,648\n",
            "           Conv2d-27            [-1, 512, 2, 2]         262,144\n",
            "      BatchNorm2d-28            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-29            [-1, 512, 2, 2]               0\n",
            "           Conv2d-30            [-1, 512, 1, 1]       2,359,296\n",
            "           Conv2d-31            [-1, 512, 1, 1]         262,144\n",
            "      BatchNorm2d-32            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-33            [-1, 512, 1, 1]               0\n",
            "         Downsize-34            [-1, 512, 1, 1]               0\n",
            "  ConvTranspose2d-35            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-36            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-37            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-38            [-1, 256, 4, 4]             512\n",
            "             ReLU-39            [-1, 256, 4, 4]               0\n",
            "           Conv2d-40            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-41            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-42            [-1, 256, 4, 4]             512\n",
            "             ReLU-43            [-1, 256, 4, 4]               0\n",
            "           Upsize-44            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-45          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-46          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-47          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-48          [-1, 128, 28, 28]             256\n",
            "             ReLU-49          [-1, 128, 28, 28]               0\n",
            "           Conv2d-50          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-51          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-52          [-1, 128, 28, 28]             256\n",
            "             ReLU-53          [-1, 128, 28, 28]               0\n",
            "           Upsize-54          [-1, 128, 28, 28]               0\n",
            "  ConvTranspose2d-55           [-1, 64, 56, 56]          73,728\n",
            "           Conv2d-56           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-57           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-58           [-1, 64, 56, 56]             128\n",
            "             ReLU-59           [-1, 64, 56, 56]               0\n",
            "           Conv2d-60           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-61           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-62           [-1, 64, 56, 56]             128\n",
            "             ReLU-63           [-1, 64, 56, 56]               0\n",
            "           Upsize-64           [-1, 64, 56, 56]               0\n",
            "  ConvTranspose2d-65         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-66         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-67         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-68         [-1, 64, 112, 112]             128\n",
            "             ReLU-69         [-1, 64, 112, 112]               0\n",
            "           Conv2d-70         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-71         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-72         [-1, 64, 112, 112]             128\n",
            "             ReLU-73         [-1, 64, 112, 112]               0\n",
            "           Upsize-74         [-1, 64, 112, 112]               0\n",
            "  ConvTranspose2d-75         [-1, 32, 224, 224]          18,432\n",
            "           Conv2d-76         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-77         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-78         [-1, 32, 224, 224]              64\n",
            "             ReLU-79         [-1, 32, 224, 224]               0\n",
            "           Conv2d-80         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-81         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-82         [-1, 32, 224, 224]              64\n",
            "             ReLU-83         [-1, 32, 224, 224]               0\n",
            "           Upsize-84         [-1, 32, 224, 224]               0\n",
            "           Conv2d-85          [-1, 1, 224, 224]              32\n",
            "  ConvTranspose2d-86            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-87            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-88            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-89            [-1, 256, 4, 4]             512\n",
            "             ReLU-90            [-1, 256, 4, 4]               0\n",
            "           Conv2d-91            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-92            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-93            [-1, 256, 4, 4]             512\n",
            "             ReLU-94            [-1, 256, 4, 4]               0\n",
            "           Upsize-95            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-96          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-97          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-98          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-99          [-1, 128, 28, 28]             256\n",
            "            ReLU-100          [-1, 128, 28, 28]               0\n",
            "          Conv2d-101          [-1, 128, 28, 28]         147,456\n",
            "          Conv2d-102          [-1, 128, 28, 28]          16,384\n",
            "     BatchNorm2d-103          [-1, 128, 28, 28]             256\n",
            "            ReLU-104          [-1, 128, 28, 28]               0\n",
            "          Upsize-105          [-1, 128, 28, 28]               0\n",
            " ConvTranspose2d-106           [-1, 64, 56, 56]          73,728\n",
            "          Conv2d-107           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-108           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-109           [-1, 64, 56, 56]             128\n",
            "            ReLU-110           [-1, 64, 56, 56]               0\n",
            "          Conv2d-111           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-112           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-113           [-1, 64, 56, 56]             128\n",
            "            ReLU-114           [-1, 64, 56, 56]               0\n",
            "          Upsize-115           [-1, 64, 56, 56]               0\n",
            " ConvTranspose2d-116         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-117         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-118         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-119         [-1, 64, 112, 112]             128\n",
            "            ReLU-120         [-1, 64, 112, 112]               0\n",
            "          Conv2d-121         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-122         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-123         [-1, 64, 112, 112]             128\n",
            "            ReLU-124         [-1, 64, 112, 112]               0\n",
            "          Upsize-125         [-1, 64, 112, 112]               0\n",
            " ConvTranspose2d-126         [-1, 32, 224, 224]          18,432\n",
            "          Conv2d-127         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-128         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-129         [-1, 32, 224, 224]              64\n",
            "            ReLU-130         [-1, 32, 224, 224]               0\n",
            "          Conv2d-131         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-132         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-133         [-1, 32, 224, 224]              64\n",
            "            ReLU-134         [-1, 32, 224, 224]               0\n",
            "          Upsize-135         [-1, 32, 224, 224]               0\n",
            "          Conv2d-136          [-1, 3, 224, 224]              99\n",
            "================================================================\n",
            "Total params: 12,384,643\n",
            "Trainable params: 12,384,643\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.15\n",
            "Forward/backward pass size (MB): 453.79\n",
            "Params size (MB): 47.24\n",
            "Estimated Total Size (MB): 502.18\n",
            "----------------------------------------------------------------\n",
            "You are running /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_10.zip dataset for 5 epochs\n",
            "Loading model : batch_best.ckp.pt\n",
            "Model is loaded and valid_loss_min is :0.29348382353782654\n",
            "\n",
            "###########EPOCH:1#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3724 Mask loss=0.01 Depth loss=0.35:   0% 0/140 [01:09<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3724055290222168\n",
            "##### Train Epoch: 1  [0/7000  (0%)]\tLoss:0.372406\n",
            "Overall Loss=0.3171 Mask loss=0.01 Depth loss=0.29:  36% 50/140 [09:49<03:11,  2.13s/it]batch_idx: 50\n",
            "loss: 0.3171127438545227\n",
            "##### Train Epoch: 1  [200/7000  (36%)]\tLoss:0.317113\n",
            "Overall Loss=0.3217 Mask loss=0.01 Depth loss=0.30:  71% 100/140 [10:43<00:33,  1.20it/s]batch_idx: 100\n",
            "loss: 0.32166415452957153\n",
            "##### Train Epoch: 1  [400/7000  (71%)]\tLoss:0.321664\n",
            "Overall Loss=0.3172 Mask loss=0.01 Depth loss=0.30: 100% 140/140 [11:09<00:00,  4.78s/it]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.32892562076449394\n",
            " 83% 50/60 [00:30<00:06,  1.62it/s]batch_idx: 50\n",
            "loss: 0.3280865214765072\n",
            "100% 60/60 [00:37<00:00,  1.62it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3270, Mask Loss: 0.01, Depth Loss: 0.30\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:2#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3113 Mask loss=0.01 Depth loss=0.29:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3112556040287018\n",
            "##### Train Epoch: 2  [0/7000  (0%)]\tLoss:0.311256\n",
            "Overall Loss=0.3124 Mask loss=0.01 Depth loss=0.29:  36% 50/140 [00:33<00:58,  1.53it/s]batch_idx: 50\n",
            "loss: 0.31242460012435913\n",
            "##### Train Epoch: 2  [200/7000  (36%)]\tLoss:0.312425\n",
            "Overall Loss=0.3148 Mask loss=0.01 Depth loss=0.29:  71% 100/140 [01:06<00:26,  1.52it/s]batch_idx: 100\n",
            "loss: 0.31479713320732117\n",
            "##### Train Epoch: 2  [400/7000  (71%)]\tLoss:0.314797\n",
            "Overall Loss=0.3167 Mask loss=0.01 Depth loss=0.29: 100% 140/140 [01:32<00:00,  1.51it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3220697734504938\n",
            " 83% 50/60 [00:30<00:06,  1.62it/s]batch_idx: 50\n",
            "loss: 0.3270983975380659\n",
            "100% 60/60 [00:37<00:00,  1.61it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3275, Mask Loss: 0.02, Depth Loss: 0.30\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:3#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3146 Mask loss=0.01 Depth loss=0.29:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.31457051634788513\n",
            "##### Train Epoch: 3  [0/7000  (0%)]\tLoss:0.314571\n",
            "Overall Loss=0.3137 Mask loss=0.01 Depth loss=0.29:  36% 50/140 [00:33<00:58,  1.54it/s]batch_idx: 50\n",
            "loss: 0.3137432634830475\n",
            "##### Train Epoch: 3  [200/7000  (36%)]\tLoss:0.313743\n",
            "Overall Loss=0.3106 Mask loss=0.01 Depth loss=0.29:  71% 100/140 [01:06<00:25,  1.55it/s]batch_idx: 100\n",
            "loss: 0.3106195330619812\n",
            "##### Train Epoch: 3  [400/7000  (71%)]\tLoss:0.310620\n",
            "Overall Loss=0.3130 Mask loss=0.01 Depth loss=0.29: 100% 140/140 [01:32<00:00,  1.51it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3241826109588146\n",
            " 83% 50/60 [00:31<00:06,  1.63it/s]batch_idx: 50\n",
            "loss: 0.32443507574498653\n",
            "100% 60/60 [00:37<00:00,  1.61it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3249, Mask Loss: 0.01, Depth Loss: 0.30\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:4#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3181 Mask loss=0.01 Depth loss=0.30:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.31813696026802063\n",
            "##### Train Epoch: 4  [0/7000  (0%)]\tLoss:0.318137\n",
            "Overall Loss=0.3133 Mask loss=0.01 Depth loss=0.29:  36% 50/140 [00:33<00:57,  1.55it/s]batch_idx: 50\n",
            "loss: 0.3133448362350464\n",
            "##### Train Epoch: 4  [200/7000  (36%)]\tLoss:0.313345\n",
            "Overall Loss=0.3175 Mask loss=0.01 Depth loss=0.30:  71% 100/140 [01:06<00:26,  1.54it/s]batch_idx: 100\n",
            "loss: 0.31748372316360474\n",
            "##### Train Epoch: 4  [400/7000  (71%)]\tLoss:0.317484\n",
            "Overall Loss=0.3128 Mask loss=0.01 Depth loss=0.29: 100% 140/140 [01:32<00:00,  1.52it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3361888639628887\n",
            " 83% 50/60 [00:30<00:06,  1.65it/s]batch_idx: 50\n",
            "loss: 0.34165624901652336\n",
            "100% 60/60 [00:36<00:00,  1.63it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3385, Mask Loss: 0.02, Depth Loss: 0.30\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:5#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3117 Mask loss=0.01 Depth loss=0.29:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.31174546480178833\n",
            "##### Train Epoch: 5  [0/7000  (0%)]\tLoss:0.311745\n",
            "Overall Loss=0.3156 Mask loss=0.01 Depth loss=0.29:  36% 50/140 [00:33<00:57,  1.56it/s]batch_idx: 50\n",
            "loss: 0.3155815899372101\n",
            "##### Train Epoch: 5  [200/7000  (36%)]\tLoss:0.315582\n",
            "Overall Loss=0.3135 Mask loss=0.01 Depth loss=0.29:  71% 100/140 [01:06<00:26,  1.53it/s]batch_idx: 100\n",
            "loss: 0.31354936957359314\n",
            "##### Train Epoch: 5  [400/7000  (71%)]\tLoss:0.313549\n",
            "Overall Loss=0.3132 Mask loss=0.01 Depth loss=0.29: 100% 140/140 [01:31<00:00,  1.52it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3282637968659401\n",
            " 83% 50/60 [00:31<00:06,  1.60it/s]batch_idx: 50\n",
            "loss: 0.32864463701844215\n",
            "100% 60/60 [00:37<00:00,  1.61it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3273, Mask Loss: 0.01, Depth Loss: 0.30\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "time: 22min 8s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "bL_bpL28jphT"
      },
      "source": [
        "# Batch_11 dataset : On Gray Images\n",
        "        Dataset size : 30K\n",
        "            - Train (70%)  : 21K  \n",
        "            - Test  (30%)  : 9K\n",
        "        Batch Size   : 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "1db1177d-0301-4760-b34d-117cb1122c40",
        "id": "nNj8Hz4ojph-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "os.chdir(r'/content/drive/My Drive/EVA4/S15/scripts/pythonFiles')\n",
        "!python train_mask_depth.py -z '/content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_11.zip' -e 10  -bs 50"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are executing model on : cuda\n",
            "Dataset using : /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_11.zip\n",
            "Train Dataset : 21000\n",
            "Test Dataset : 9000\n",
            "\t In batch size of : 50\n",
            "cuda\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]          18,816\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "   ConvTranspose2d-5        [-1, 128, 111, 111]           8,192\n",
            "            Conv2d-6          [-1, 128, 28, 28]          73,728\n",
            "            Conv2d-7          [-1, 128, 28, 28]          16,384\n",
            "       BatchNorm2d-8          [-1, 128, 28, 28]             256\n",
            "              ReLU-9          [-1, 128, 28, 28]               0\n",
            "           Conv2d-10          [-1, 128, 14, 14]         147,456\n",
            "           Conv2d-11          [-1, 128, 14, 14]          16,384\n",
            "      BatchNorm2d-12          [-1, 128, 14, 14]             256\n",
            "             ReLU-13          [-1, 128, 14, 14]               0\n",
            "         Downsize-14          [-1, 128, 14, 14]               0\n",
            "  ConvTranspose2d-15          [-1, 256, 27, 27]          32,768\n",
            "           Conv2d-16            [-1, 256, 7, 7]         294,912\n",
            "           Conv2d-17            [-1, 256, 7, 7]          65,536\n",
            "      BatchNorm2d-18            [-1, 256, 7, 7]             512\n",
            "             ReLU-19            [-1, 256, 7, 7]               0\n",
            "           Conv2d-20            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-21            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-22            [-1, 256, 4, 4]             512\n",
            "             ReLU-23            [-1, 256, 4, 4]               0\n",
            "         Downsize-24            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-25            [-1, 512, 7, 7]         131,072\n",
            "           Conv2d-26            [-1, 512, 2, 2]       1,179,648\n",
            "           Conv2d-27            [-1, 512, 2, 2]         262,144\n",
            "      BatchNorm2d-28            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-29            [-1, 512, 2, 2]               0\n",
            "           Conv2d-30            [-1, 512, 1, 1]       2,359,296\n",
            "           Conv2d-31            [-1, 512, 1, 1]         262,144\n",
            "      BatchNorm2d-32            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-33            [-1, 512, 1, 1]               0\n",
            "         Downsize-34            [-1, 512, 1, 1]               0\n",
            "  ConvTranspose2d-35            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-36            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-37            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-38            [-1, 256, 4, 4]             512\n",
            "             ReLU-39            [-1, 256, 4, 4]               0\n",
            "           Conv2d-40            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-41            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-42            [-1, 256, 4, 4]             512\n",
            "             ReLU-43            [-1, 256, 4, 4]               0\n",
            "           Upsize-44            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-45          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-46          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-47          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-48          [-1, 128, 28, 28]             256\n",
            "             ReLU-49          [-1, 128, 28, 28]               0\n",
            "           Conv2d-50          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-51          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-52          [-1, 128, 28, 28]             256\n",
            "             ReLU-53          [-1, 128, 28, 28]               0\n",
            "           Upsize-54          [-1, 128, 28, 28]               0\n",
            "  ConvTranspose2d-55           [-1, 64, 56, 56]          73,728\n",
            "           Conv2d-56           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-57           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-58           [-1, 64, 56, 56]             128\n",
            "             ReLU-59           [-1, 64, 56, 56]               0\n",
            "           Conv2d-60           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-61           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-62           [-1, 64, 56, 56]             128\n",
            "             ReLU-63           [-1, 64, 56, 56]               0\n",
            "           Upsize-64           [-1, 64, 56, 56]               0\n",
            "  ConvTranspose2d-65         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-66         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-67         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-68         [-1, 64, 112, 112]             128\n",
            "             ReLU-69         [-1, 64, 112, 112]               0\n",
            "           Conv2d-70         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-71         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-72         [-1, 64, 112, 112]             128\n",
            "             ReLU-73         [-1, 64, 112, 112]               0\n",
            "           Upsize-74         [-1, 64, 112, 112]               0\n",
            "  ConvTranspose2d-75         [-1, 32, 224, 224]          18,432\n",
            "           Conv2d-76         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-77         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-78         [-1, 32, 224, 224]              64\n",
            "             ReLU-79         [-1, 32, 224, 224]               0\n",
            "           Conv2d-80         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-81         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-82         [-1, 32, 224, 224]              64\n",
            "             ReLU-83         [-1, 32, 224, 224]               0\n",
            "           Upsize-84         [-1, 32, 224, 224]               0\n",
            "           Conv2d-85          [-1, 1, 224, 224]              32\n",
            "  ConvTranspose2d-86            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-87            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-88            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-89            [-1, 256, 4, 4]             512\n",
            "             ReLU-90            [-1, 256, 4, 4]               0\n",
            "           Conv2d-91            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-92            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-93            [-1, 256, 4, 4]             512\n",
            "             ReLU-94            [-1, 256, 4, 4]               0\n",
            "           Upsize-95            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-96          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-97          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-98          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-99          [-1, 128, 28, 28]             256\n",
            "            ReLU-100          [-1, 128, 28, 28]               0\n",
            "          Conv2d-101          [-1, 128, 28, 28]         147,456\n",
            "          Conv2d-102          [-1, 128, 28, 28]          16,384\n",
            "     BatchNorm2d-103          [-1, 128, 28, 28]             256\n",
            "            ReLU-104          [-1, 128, 28, 28]               0\n",
            "          Upsize-105          [-1, 128, 28, 28]               0\n",
            " ConvTranspose2d-106           [-1, 64, 56, 56]          73,728\n",
            "          Conv2d-107           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-108           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-109           [-1, 64, 56, 56]             128\n",
            "            ReLU-110           [-1, 64, 56, 56]               0\n",
            "          Conv2d-111           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-112           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-113           [-1, 64, 56, 56]             128\n",
            "            ReLU-114           [-1, 64, 56, 56]               0\n",
            "          Upsize-115           [-1, 64, 56, 56]               0\n",
            " ConvTranspose2d-116         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-117         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-118         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-119         [-1, 64, 112, 112]             128\n",
            "            ReLU-120         [-1, 64, 112, 112]               0\n",
            "          Conv2d-121         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-122         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-123         [-1, 64, 112, 112]             128\n",
            "            ReLU-124         [-1, 64, 112, 112]               0\n",
            "          Upsize-125         [-1, 64, 112, 112]               0\n",
            " ConvTranspose2d-126         [-1, 32, 224, 224]          18,432\n",
            "          Conv2d-127         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-128         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-129         [-1, 32, 224, 224]              64\n",
            "            ReLU-130         [-1, 32, 224, 224]               0\n",
            "          Conv2d-131         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-132         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-133         [-1, 32, 224, 224]              64\n",
            "            ReLU-134         [-1, 32, 224, 224]               0\n",
            "          Upsize-135         [-1, 32, 224, 224]               0\n",
            "          Conv2d-136          [-1, 1, 224, 224]              33\n",
            "================================================================\n",
            "Total params: 12,384,577\n",
            "Trainable params: 12,384,577\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.15\n",
            "Forward/backward pass size (MB): 453.02\n",
            "Params size (MB): 47.24\n",
            "Estimated Total Size (MB): 501.41\n",
            "----------------------------------------------------------------\n",
            "You are running /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_11.zip dataset for 10 epochs\n",
            "\n",
            "###########EPOCH:1#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=2.2377 Mask loss=0.71 Depth loss=0.81:   0% 0/140 [00:48<?, ?it/s]batch_idx: 0\n",
            "loss: 2.237684726715088\n",
            "##### Train Epoch: 1  [0/7000  (0%)]\tLoss:2.237685\n",
            "Overall Loss=0.4396 Mask loss=0.04 Depth loss=0.37:  36% 50/140 [08:43<03:09,  2.10s/it]batch_idx: 50\n",
            "loss: 0.4395734369754791\n",
            "##### Train Epoch: 1  [200/7000  (36%)]\tLoss:0.439573\n",
            "Overall Loss=0.4045 Mask loss=0.02 Depth loss=0.35:  71% 100/140 [09:34<00:34,  1.16it/s]batch_idx: 100\n",
            "loss: 0.40453237295150757\n",
            "##### Train Epoch: 1  [400/7000  (71%)]\tLoss:0.404532\n",
            "Overall Loss=0.3997 Mask loss=0.02 Depth loss=0.35: 100% 140/140 [10:01<00:00,  4.29s/it]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Validation loss decreased (10000.000000 --> 0.399683).  Saving model ...\n",
            "\n",
            "\n",
            "\n",
            "**************Model saved**************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.4114297106862068\n",
            " 83% 50/60 [00:31<00:06,  1.55it/s]batch_idx: 50\n",
            "loss: 0.41259292140603065\n",
            "100% 60/60 [00:37<00:00,  1.60it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.4121, Mask Loss: 0.02, Depth Loss: 0.37\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:2#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.4001 Mask loss=0.02 Depth loss=0.36:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.40005800127983093\n",
            "##### Train Epoch: 2  [0/7000  (0%)]\tLoss:0.400058\n",
            "Overall Loss=0.3892 Mask loss=0.02 Depth loss=0.35:  36% 50/140 [00:33<00:57,  1.56it/s]batch_idx: 50\n",
            "loss: 0.3891509771347046\n",
            "##### Train Epoch: 2  [200/7000  (36%)]\tLoss:0.389151\n",
            "Overall Loss=0.3780 Mask loss=0.02 Depth loss=0.34:  71% 100/140 [01:05<00:25,  1.58it/s]batch_idx: 100\n",
            "loss: 0.37801164388656616\n",
            "##### Train Epoch: 2  [400/7000  (71%)]\tLoss:0.378012\n",
            "Overall Loss=0.3822 Mask loss=0.02 Depth loss=0.35: 100% 140/140 [01:30<00:00,  1.54it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Validation loss decreased (0.399683 --> 0.382165).  Saving model ...\n",
            "\n",
            "\n",
            "\n",
            "**************Model saved**************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.39386575296521187\n",
            " 83% 50/60 [00:30<00:05,  1.67it/s]batch_idx: 50\n",
            "loss: 0.390657652169466\n",
            "100% 60/60 [00:36<00:00,  1.66it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3935, Mask Loss: 0.02, Depth Loss: 0.36\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:3#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3821 Mask loss=0.02 Depth loss=0.35:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3821311891078949\n",
            "##### Train Epoch: 3  [0/7000  (0%)]\tLoss:0.382131\n",
            "Overall Loss=0.3815 Mask loss=0.02 Depth loss=0.35:  36% 50/140 [00:33<00:59,  1.52it/s]batch_idx: 50\n",
            "loss: 0.3814584016799927\n",
            "##### Train Epoch: 3  [200/7000  (36%)]\tLoss:0.381458\n",
            "Overall Loss=0.3820 Mask loss=0.02 Depth loss=0.35:  71% 100/140 [01:05<00:25,  1.58it/s]batch_idx: 100\n",
            "loss: 0.3820171356201172\n",
            "##### Train Epoch: 3  [400/7000  (71%)]\tLoss:0.382017\n",
            "Overall Loss=0.3751 Mask loss=0.02 Depth loss=0.34: 100% 140/140 [01:30<00:00,  1.54it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Validation loss decreased (0.382165 --> 0.375150).  Saving model ...\n",
            "\n",
            "\n",
            "\n",
            "**************Model saved**************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.41060758382081985\n",
            " 83% 50/60 [00:30<00:06,  1.65it/s]batch_idx: 50\n",
            "loss: 0.4116758480668068\n",
            "100% 60/60 [00:36<00:00,  1.66it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.4142, Mask Loss: 0.03, Depth Loss: 0.36\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:4#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3743 Mask loss=0.01 Depth loss=0.35:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3742503523826599\n",
            "##### Train Epoch: 4  [0/7000  (0%)]\tLoss:0.374250\n",
            "Overall Loss=0.3724 Mask loss=0.01 Depth loss=0.34:  36% 50/140 [00:32<00:57,  1.57it/s]batch_idx: 50\n",
            "loss: 0.3723639249801636\n",
            "##### Train Epoch: 4  [200/7000  (36%)]\tLoss:0.372364\n",
            "Overall Loss=0.3753 Mask loss=0.01 Depth loss=0.35:  71% 100/140 [01:04<00:25,  1.56it/s]batch_idx: 100\n",
            "loss: 0.3753097951412201\n",
            "##### Train Epoch: 4  [400/7000  (71%)]\tLoss:0.375310\n",
            "Overall Loss=0.3756 Mask loss=0.01 Depth loss=0.35: 100% 140/140 [01:30<00:00,  1.55it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.5483980625867844\n",
            " 83% 50/60 [00:30<00:05,  1.69it/s]batch_idx: 50\n",
            "loss: 0.5647959858179092\n",
            "100% 60/60 [00:36<00:00,  1.66it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.5619, Mask Loss: 0.10, Depth Loss: 0.36\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:5#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3779 Mask loss=0.02 Depth loss=0.35:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.37786269187927246\n",
            "##### Train Epoch: 5  [0/7000  (0%)]\tLoss:0.377863\n",
            "Overall Loss=0.3759 Mask loss=0.01 Depth loss=0.35:  36% 50/140 [00:32<00:56,  1.58it/s]batch_idx: 50\n",
            "loss: 0.37591761350631714\n",
            "##### Train Epoch: 5  [200/7000  (36%)]\tLoss:0.375918\n",
            "Overall Loss=0.3758 Mask loss=0.01 Depth loss=0.35:  71% 100/140 [01:05<00:25,  1.58it/s]batch_idx: 100\n",
            "loss: 0.3757675290107727\n",
            "##### Train Epoch: 5  [400/7000  (71%)]\tLoss:0.375768\n",
            "Overall Loss=0.3768 Mask loss=0.01 Depth loss=0.35: 100% 140/140 [01:31<00:00,  1.54it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.394613865762949\n",
            " 83% 50/60 [00:30<00:05,  1.68it/s]batch_idx: 50\n",
            "loss: 0.39698198810219765\n",
            "100% 60/60 [00:36<00:00,  1.66it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3933, Mask Loss: 0.02, Depth Loss: 0.36\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:6#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3689 Mask loss=0.01 Depth loss=0.34:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.36885249614715576\n",
            "##### Train Epoch: 6  [0/7000  (0%)]\tLoss:0.368852\n",
            "Overall Loss=0.3712 Mask loss=0.01 Depth loss=0.34:  36% 50/140 [00:32<00:57,  1.58it/s]batch_idx: 50\n",
            "loss: 0.37118980288505554\n",
            "##### Train Epoch: 6  [200/7000  (36%)]\tLoss:0.371190\n",
            "Overall Loss=0.3727 Mask loss=0.01 Depth loss=0.34:  71% 100/140 [01:05<00:25,  1.58it/s]batch_idx: 100\n",
            "loss: 0.37270042300224304\n",
            "##### Train Epoch: 6  [400/7000  (71%)]\tLoss:0.372700\n",
            "Overall Loss=0.3667 Mask loss=0.01 Depth loss=0.34: 100% 140/140 [01:30<00:00,  1.55it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Validation loss decreased (0.375150 --> 0.366716).  Saving model ...\n",
            "\n",
            "\n",
            "\n",
            "**************Model saved**************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3892221376299858\n",
            " 83% 50/60 [00:30<00:05,  1.68it/s]batch_idx: 50\n",
            "loss: 0.3924296498298645\n",
            "100% 60/60 [00:36<00:00,  1.65it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3920, Mask Loss: 0.02, Depth Loss: 0.36\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:7#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3706 Mask loss=0.01 Depth loss=0.34:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3705996870994568\n",
            "##### Train Epoch: 7  [0/7000  (0%)]\tLoss:0.370600\n",
            "Overall Loss=0.3692 Mask loss=0.01 Depth loss=0.34:  36% 50/140 [00:33<00:58,  1.55it/s]batch_idx: 50\n",
            "loss: 0.3691951036453247\n",
            "##### Train Epoch: 7  [200/7000  (36%)]\tLoss:0.369195\n",
            "Overall Loss=0.3744 Mask loss=0.01 Depth loss=0.35:  71% 100/140 [01:05<00:26,  1.51it/s]batch_idx: 100\n",
            "loss: 0.37437161803245544\n",
            "##### Train Epoch: 7  [400/7000  (71%)]\tLoss:0.374372\n",
            "Overall Loss=0.3705 Mask loss=0.01 Depth loss=0.34: 100% 140/140 [01:31<00:00,  1.54it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3938722126185894\n",
            " 83% 50/60 [00:30<00:06,  1.63it/s]batch_idx: 50\n",
            "loss: 0.3938399776816368\n",
            "100% 60/60 [00:36<00:00,  1.66it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3939, Mask Loss: 0.02, Depth Loss: 0.35\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:8#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3700 Mask loss=0.01 Depth loss=0.34:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.37003403902053833\n",
            "##### Train Epoch: 8  [0/7000  (0%)]\tLoss:0.370034\n",
            "Overall Loss=0.3659 Mask loss=0.01 Depth loss=0.34:  36% 50/140 [00:33<00:57,  1.58it/s]batch_idx: 50\n",
            "loss: 0.36586135625839233\n",
            "##### Train Epoch: 8  [200/7000  (36%)]\tLoss:0.365861\n",
            "Overall Loss=0.3706 Mask loss=0.01 Depth loss=0.35:  71% 100/140 [01:05<00:25,  1.57it/s]batch_idx: 100\n",
            "loss: 0.3705718219280243\n",
            "##### Train Epoch: 8  [400/7000  (71%)]\tLoss:0.370572\n",
            "Overall Loss=0.3640 Mask loss=0.01 Depth loss=0.34: 100% 140/140 [01:30<00:00,  1.54it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Validation loss decreased (0.366716 --> 0.363993).  Saving model ...\n",
            "\n",
            "\n",
            "\n",
            "**************Model saved**************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.39405376836657524\n",
            " 83% 50/60 [00:30<00:05,  1.68it/s]batch_idx: 50\n",
            "loss: 0.39544009417295456\n",
            "100% 60/60 [00:36<00:00,  1.65it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3936, Mask Loss: 0.02, Depth Loss: 0.36\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:9#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3698 Mask loss=0.01 Depth loss=0.34:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3698427081108093\n",
            "##### Train Epoch: 9  [0/7000  (0%)]\tLoss:0.369843\n",
            "Overall Loss=0.3718 Mask loss=0.01 Depth loss=0.35:  36% 50/140 [00:33<00:57,  1.57it/s]batch_idx: 50\n",
            "loss: 0.37184837460517883\n",
            "##### Train Epoch: 9  [200/7000  (36%)]\tLoss:0.371848\n",
            "Overall Loss=0.3745 Mask loss=0.01 Depth loss=0.35:  71% 100/140 [01:05<00:25,  1.56it/s]batch_idx: 100\n",
            "loss: 0.37454167008399963\n",
            "##### Train Epoch: 9  [400/7000  (71%)]\tLoss:0.374542\n",
            "Overall Loss=0.3694 Mask loss=0.01 Depth loss=0.34: 100% 140/140 [01:31<00:00,  1.54it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.38471102342009544\n",
            " 83% 50/60 [00:30<00:06,  1.65it/s]batch_idx: 50\n",
            "loss: 0.38719100318849087\n",
            "100% 60/60 [00:36<00:00,  1.66it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3878, Mask Loss: 0.02, Depth Loss: 0.36\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:10#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3724 Mask loss=0.01 Depth loss=0.35:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3723539113998413\n",
            "##### Train Epoch: 10  [0/7000  (0%)]\tLoss:0.372354\n",
            "Overall Loss=0.3686 Mask loss=0.01 Depth loss=0.34:  36% 50/140 [00:33<00:57,  1.56it/s]batch_idx: 50\n",
            "loss: 0.3685966730117798\n",
            "##### Train Epoch: 10  [200/7000  (36%)]\tLoss:0.368597\n",
            "Overall Loss=0.3731 Mask loss=0.01 Depth loss=0.35:  71% 100/140 [01:05<00:25,  1.58it/s]batch_idx: 100\n",
            "loss: 0.373074471950531\n",
            "##### Train Epoch: 10  [400/7000  (71%)]\tLoss:0.373074\n",
            "Overall Loss=0.3692 Mask loss=0.01 Depth loss=0.35: 100% 140/140 [01:30<00:00,  1.54it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.38916001841425896\n",
            " 83% 50/60 [00:30<00:06,  1.66it/s]batch_idx: 50\n",
            "loss: 0.38923441246151924\n",
            "100% 60/60 [00:36<00:00,  1.65it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3878, Mask Loss: 0.02, Depth Loss: 0.36\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "time: 33min 9s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "4QErgQU2xg1Z"
      },
      "source": [
        "# Batch_12 dataset : On Gray Images\n",
        "        Dataset size : 30K\n",
        "            - Train (70%)  : 21K  \n",
        "            - Test  (30%)  : 9K\n",
        "        Batch Size   : 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "d0fdbf7c-e7ce-43f3-a087-fd0ce5db215b",
        "id": "sJXpKENyxg1e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "os.chdir(r'/content/drive/My Drive/EVA4/S15/scripts/pythonFiles')\n",
        "!python train_mask_depth.py -z '/content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_12.zip' -e 10  -bs 50"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are executing model on : cuda\n",
            "Dataset using : /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_12.zip\n",
            "Train Dataset : 21000\n",
            "Test Dataset : 9000\n",
            "\t In batch size of : 50\n",
            "cuda\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]          18,816\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "   ConvTranspose2d-5        [-1, 128, 111, 111]           8,192\n",
            "            Conv2d-6          [-1, 128, 28, 28]          73,728\n",
            "            Conv2d-7          [-1, 128, 28, 28]          16,384\n",
            "       BatchNorm2d-8          [-1, 128, 28, 28]             256\n",
            "              ReLU-9          [-1, 128, 28, 28]               0\n",
            "           Conv2d-10          [-1, 128, 14, 14]         147,456\n",
            "           Conv2d-11          [-1, 128, 14, 14]          16,384\n",
            "      BatchNorm2d-12          [-1, 128, 14, 14]             256\n",
            "             ReLU-13          [-1, 128, 14, 14]               0\n",
            "         Downsize-14          [-1, 128, 14, 14]               0\n",
            "  ConvTranspose2d-15          [-1, 256, 27, 27]          32,768\n",
            "           Conv2d-16            [-1, 256, 7, 7]         294,912\n",
            "           Conv2d-17            [-1, 256, 7, 7]          65,536\n",
            "      BatchNorm2d-18            [-1, 256, 7, 7]             512\n",
            "             ReLU-19            [-1, 256, 7, 7]               0\n",
            "           Conv2d-20            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-21            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-22            [-1, 256, 4, 4]             512\n",
            "             ReLU-23            [-1, 256, 4, 4]               0\n",
            "         Downsize-24            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-25            [-1, 512, 7, 7]         131,072\n",
            "           Conv2d-26            [-1, 512, 2, 2]       1,179,648\n",
            "           Conv2d-27            [-1, 512, 2, 2]         262,144\n",
            "      BatchNorm2d-28            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-29            [-1, 512, 2, 2]               0\n",
            "           Conv2d-30            [-1, 512, 1, 1]       2,359,296\n",
            "           Conv2d-31            [-1, 512, 1, 1]         262,144\n",
            "      BatchNorm2d-32            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-33            [-1, 512, 1, 1]               0\n",
            "         Downsize-34            [-1, 512, 1, 1]               0\n",
            "  ConvTranspose2d-35            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-36            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-37            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-38            [-1, 256, 4, 4]             512\n",
            "             ReLU-39            [-1, 256, 4, 4]               0\n",
            "           Conv2d-40            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-41            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-42            [-1, 256, 4, 4]             512\n",
            "             ReLU-43            [-1, 256, 4, 4]               0\n",
            "           Upsize-44            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-45          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-46          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-47          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-48          [-1, 128, 28, 28]             256\n",
            "             ReLU-49          [-1, 128, 28, 28]               0\n",
            "           Conv2d-50          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-51          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-52          [-1, 128, 28, 28]             256\n",
            "             ReLU-53          [-1, 128, 28, 28]               0\n",
            "           Upsize-54          [-1, 128, 28, 28]               0\n",
            "  ConvTranspose2d-55           [-1, 64, 56, 56]          73,728\n",
            "           Conv2d-56           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-57           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-58           [-1, 64, 56, 56]             128\n",
            "             ReLU-59           [-1, 64, 56, 56]               0\n",
            "           Conv2d-60           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-61           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-62           [-1, 64, 56, 56]             128\n",
            "             ReLU-63           [-1, 64, 56, 56]               0\n",
            "           Upsize-64           [-1, 64, 56, 56]               0\n",
            "  ConvTranspose2d-65         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-66         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-67         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-68         [-1, 64, 112, 112]             128\n",
            "             ReLU-69         [-1, 64, 112, 112]               0\n",
            "           Conv2d-70         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-71         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-72         [-1, 64, 112, 112]             128\n",
            "             ReLU-73         [-1, 64, 112, 112]               0\n",
            "           Upsize-74         [-1, 64, 112, 112]               0\n",
            "  ConvTranspose2d-75         [-1, 32, 224, 224]          18,432\n",
            "           Conv2d-76         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-77         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-78         [-1, 32, 224, 224]              64\n",
            "             ReLU-79         [-1, 32, 224, 224]               0\n",
            "           Conv2d-80         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-81         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-82         [-1, 32, 224, 224]              64\n",
            "             ReLU-83         [-1, 32, 224, 224]               0\n",
            "           Upsize-84         [-1, 32, 224, 224]               0\n",
            "           Conv2d-85          [-1, 1, 224, 224]              32\n",
            "  ConvTranspose2d-86            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-87            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-88            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-89            [-1, 256, 4, 4]             512\n",
            "             ReLU-90            [-1, 256, 4, 4]               0\n",
            "           Conv2d-91            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-92            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-93            [-1, 256, 4, 4]             512\n",
            "             ReLU-94            [-1, 256, 4, 4]               0\n",
            "           Upsize-95            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-96          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-97          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-98          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-99          [-1, 128, 28, 28]             256\n",
            "            ReLU-100          [-1, 128, 28, 28]               0\n",
            "          Conv2d-101          [-1, 128, 28, 28]         147,456\n",
            "          Conv2d-102          [-1, 128, 28, 28]          16,384\n",
            "     BatchNorm2d-103          [-1, 128, 28, 28]             256\n",
            "            ReLU-104          [-1, 128, 28, 28]               0\n",
            "          Upsize-105          [-1, 128, 28, 28]               0\n",
            " ConvTranspose2d-106           [-1, 64, 56, 56]          73,728\n",
            "          Conv2d-107           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-108           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-109           [-1, 64, 56, 56]             128\n",
            "            ReLU-110           [-1, 64, 56, 56]               0\n",
            "          Conv2d-111           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-112           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-113           [-1, 64, 56, 56]             128\n",
            "            ReLU-114           [-1, 64, 56, 56]               0\n",
            "          Upsize-115           [-1, 64, 56, 56]               0\n",
            " ConvTranspose2d-116         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-117         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-118         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-119         [-1, 64, 112, 112]             128\n",
            "            ReLU-120         [-1, 64, 112, 112]               0\n",
            "          Conv2d-121         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-122         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-123         [-1, 64, 112, 112]             128\n",
            "            ReLU-124         [-1, 64, 112, 112]               0\n",
            "          Upsize-125         [-1, 64, 112, 112]               0\n",
            " ConvTranspose2d-126         [-1, 32, 224, 224]          18,432\n",
            "          Conv2d-127         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-128         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-129         [-1, 32, 224, 224]              64\n",
            "            ReLU-130         [-1, 32, 224, 224]               0\n",
            "          Conv2d-131         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-132         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-133         [-1, 32, 224, 224]              64\n",
            "            ReLU-134         [-1, 32, 224, 224]               0\n",
            "          Upsize-135         [-1, 32, 224, 224]               0\n",
            "          Conv2d-136          [-1, 1, 224, 224]              33\n",
            "================================================================\n",
            "Total params: 12,384,577\n",
            "Trainable params: 12,384,577\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.15\n",
            "Forward/backward pass size (MB): 453.02\n",
            "Params size (MB): 47.24\n",
            "Estimated Total Size (MB): 501.41\n",
            "----------------------------------------------------------------\n",
            "You are running /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_12.zip dataset for 10 epochs\n",
            "Loading model : batch_best.ckp.pt\n",
            "Model is loaded and valid_loss_min is :0.363992840051651\n",
            "\n",
            "###########EPOCH:1#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.4334 Mask loss=0.01 Depth loss=0.41:   0% 0/140 [01:03<?, ?it/s]batch_idx: 0\n",
            "loss: 0.4334222078323364\n",
            "##### Train Epoch: 1  [0/7000  (0%)]\tLoss:0.433422\n",
            "Overall Loss=0.3652 Mask loss=0.01 Depth loss=0.34:  36% 50/140 [10:38<02:56,  1.96s/it]batch_idx: 50\n",
            "loss: 0.3651835024356842\n",
            "##### Train Epoch: 1  [200/7000  (36%)]\tLoss:0.365184\n",
            "Overall Loss=0.3634 Mask loss=0.01 Depth loss=0.34:  71% 100/140 [11:23<00:25,  1.58it/s]batch_idx: 100\n",
            "loss: 0.36342889070510864\n",
            "##### Train Epoch: 1  [400/7000  (71%)]\tLoss:0.363429\n",
            "Overall Loss=0.3615 Mask loss=0.01 Depth loss=0.34: 100% 140/140 [11:48<00:00,  5.06s/it]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Validation loss decreased (10000.000000 --> 0.361459).  Saving model ...\n",
            "\n",
            "\n",
            "\n",
            "**************Model saved**************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3873518593609333\n",
            " 83% 50/60 [00:30<00:05,  1.68it/s]batch_idx: 50\n",
            "loss: 0.3822286147624254\n",
            "100% 60/60 [00:36<00:00,  1.65it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3806, Mask Loss: 0.01, Depth Loss: 0.35\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:2#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3646 Mask loss=0.01 Depth loss=0.34:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.36455073952674866\n",
            "##### Train Epoch: 2  [0/7000  (0%)]\tLoss:0.364551\n",
            "Overall Loss=0.3577 Mask loss=0.01 Depth loss=0.33:  36% 50/140 [00:32<00:57,  1.56it/s]batch_idx: 50\n",
            "loss: 0.3577290177345276\n",
            "##### Train Epoch: 2  [200/7000  (36%)]\tLoss:0.357729\n",
            "Overall Loss=0.3623 Mask loss=0.01 Depth loss=0.34:  71% 100/140 [01:05<00:25,  1.57it/s]batch_idx: 100\n",
            "loss: 0.3623449504375458\n",
            "##### Train Epoch: 2  [400/7000  (71%)]\tLoss:0.362345\n",
            "Overall Loss=0.3580 Mask loss=0.01 Depth loss=0.33: 100% 140/140 [01:30<00:00,  1.54it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Validation loss decreased (0.361459 --> 0.357998).  Saving model ...\n",
            "\n",
            "\n",
            "\n",
            "**************Model saved**************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.39231864735484123\n",
            " 83% 50/60 [00:31<00:06,  1.67it/s]batch_idx: 50\n",
            "loss: 0.39166663959622383\n",
            "100% 60/60 [00:37<00:00,  1.62it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3914, Mask Loss: 0.02, Depth Loss: 0.35\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:3#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3646 Mask loss=0.01 Depth loss=0.34:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3645933270454407\n",
            "##### Train Epoch: 3  [0/7000  (0%)]\tLoss:0.364593\n",
            "Overall Loss=0.3607 Mask loss=0.01 Depth loss=0.34:  36% 50/140 [00:33<00:58,  1.53it/s]batch_idx: 50\n",
            "loss: 0.3606671094894409\n",
            "##### Train Epoch: 3  [200/7000  (36%)]\tLoss:0.360667\n",
            "Overall Loss=0.3571 Mask loss=0.01 Depth loss=0.33:  71% 100/140 [01:05<00:25,  1.56it/s]batch_idx: 100\n",
            "loss: 0.35706278681755066\n",
            "##### Train Epoch: 3  [400/7000  (71%)]\tLoss:0.357063\n",
            "Overall Loss=0.3585 Mask loss=0.01 Depth loss=0.33: 100% 140/140 [01:31<00:00,  1.54it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.37841514497995377\n",
            " 83% 50/60 [00:30<00:06,  1.64it/s]batch_idx: 50\n",
            "loss: 0.3858886957168579\n",
            "100% 60/60 [00:36<00:00,  1.64it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3847, Mask Loss: 0.02, Depth Loss: 0.35\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:4#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3587 Mask loss=0.01 Depth loss=0.33:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.35874345898628235\n",
            "##### Train Epoch: 4  [0/7000  (0%)]\tLoss:0.358743\n",
            "Overall Loss=0.3637 Mask loss=0.01 Depth loss=0.34:  36% 50/140 [00:32<00:57,  1.57it/s]batch_idx: 50\n",
            "loss: 0.36368662118911743\n",
            "##### Train Epoch: 4  [200/7000  (36%)]\tLoss:0.363687\n",
            "Overall Loss=0.3588 Mask loss=0.01 Depth loss=0.33:  71% 100/140 [01:05<00:25,  1.57it/s]batch_idx: 100\n",
            "loss: 0.3588002324104309\n",
            "##### Train Epoch: 4  [400/7000  (71%)]\tLoss:0.358800\n",
            "Overall Loss=0.3624 Mask loss=0.01 Depth loss=0.34: 100% 140/140 [01:30<00:00,  1.55it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.37513376399874687\n",
            " 83% 50/60 [00:30<00:06,  1.57it/s]batch_idx: 50\n",
            "loss: 0.3674393631517887\n",
            "100% 60/60 [00:36<00:00,  1.64it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3743, Mask Loss: 0.01, Depth Loss: 0.35\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:5#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3570 Mask loss=0.01 Depth loss=0.33:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.35702335834503174\n",
            "##### Train Epoch: 5  [0/7000  (0%)]\tLoss:0.357023\n",
            "Overall Loss=0.3568 Mask loss=0.01 Depth loss=0.33:  36% 50/140 [00:32<00:57,  1.57it/s]batch_idx: 50\n",
            "loss: 0.35683760046958923\n",
            "##### Train Epoch: 5  [200/7000  (36%)]\tLoss:0.356838\n",
            "Overall Loss=0.3590 Mask loss=0.01 Depth loss=0.34:  71% 100/140 [01:05<00:25,  1.57it/s]batch_idx: 100\n",
            "loss: 0.3590187430381775\n",
            "##### Train Epoch: 5  [400/7000  (71%)]\tLoss:0.359019\n",
            "Overall Loss=0.3549 Mask loss=0.01 Depth loss=0.33: 100% 140/140 [01:30<00:00,  1.54it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Validation loss decreased (0.357998 --> 0.354949).  Saving model ...\n",
            "\n",
            "\n",
            "\n",
            "**************Model saved**************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.37525385059416294\n",
            " 83% 50/60 [00:30<00:05,  1.67it/s]batch_idx: 50\n",
            "loss: 0.3765821922570467\n",
            "100% 60/60 [00:36<00:00,  1.65it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3758, Mask Loss: 0.01, Depth Loss: 0.35\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:6#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3566 Mask loss=0.01 Depth loss=0.33:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.35660919547080994\n",
            "##### Train Epoch: 6  [0/7000  (0%)]\tLoss:0.356609\n",
            "Overall Loss=0.3557 Mask loss=0.01 Depth loss=0.33:  36% 50/140 [00:32<00:57,  1.56it/s]batch_idx: 50\n",
            "loss: 0.35568907856941223\n",
            "##### Train Epoch: 6  [200/7000  (36%)]\tLoss:0.355689\n",
            "Overall Loss=0.3529 Mask loss=0.01 Depth loss=0.33:  71% 100/140 [01:05<00:25,  1.57it/s]batch_idx: 100\n",
            "loss: 0.3528692424297333\n",
            "##### Train Epoch: 6  [400/7000  (71%)]\tLoss:0.352869\n",
            "Overall Loss=0.3590 Mask loss=0.01 Depth loss=0.33: 100% 140/140 [01:30<00:00,  1.55it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3761722482740879\n",
            " 83% 50/60 [00:30<00:05,  1.67it/s]batch_idx: 50\n",
            "loss: 0.3780742771923542\n",
            "100% 60/60 [00:36<00:00,  1.66it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3775, Mask Loss: 0.02, Depth Loss: 0.35\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:7#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3640 Mask loss=0.01 Depth loss=0.34:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.36395129561424255\n",
            "##### Train Epoch: 7  [0/7000  (0%)]\tLoss:0.363951\n",
            "Overall Loss=0.3629 Mask loss=0.01 Depth loss=0.34:  36% 50/140 [00:33<00:56,  1.58it/s]batch_idx: 50\n",
            "loss: 0.3629347085952759\n",
            "##### Train Epoch: 7  [200/7000  (36%)]\tLoss:0.362935\n",
            "Overall Loss=0.3581 Mask loss=0.01 Depth loss=0.34:  71% 100/140 [01:05<00:25,  1.56it/s]batch_idx: 100\n",
            "loss: 0.35806024074554443\n",
            "##### Train Epoch: 7  [400/7000  (71%)]\tLoss:0.358060\n",
            "Overall Loss=0.3534 Mask loss=0.01 Depth loss=0.33: 100% 140/140 [01:30<00:00,  1.54it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Validation loss decreased (0.354949 --> 0.353422).  Saving model ...\n",
            "\n",
            "\n",
            "\n",
            "**************Model saved**************\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.37882111221551895\n",
            " 83% 50/60 [00:30<00:06,  1.66it/s]batch_idx: 50\n",
            "loss: 0.3817251995205879\n",
            "100% 60/60 [00:36<00:00,  1.64it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3791, Mask Loss: 0.02, Depth Loss: 0.35\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:8#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3561 Mask loss=0.01 Depth loss=0.33:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.35612478852272034\n",
            "##### Train Epoch: 8  [0/7000  (0%)]\tLoss:0.356125\n",
            "Overall Loss=0.3574 Mask loss=0.01 Depth loss=0.33:  36% 50/140 [00:32<00:57,  1.57it/s]batch_idx: 50\n",
            "loss: 0.35741913318634033\n",
            "##### Train Epoch: 8  [200/7000  (36%)]\tLoss:0.357419\n",
            "Overall Loss=0.3620 Mask loss=0.01 Depth loss=0.34:  71% 100/140 [01:05<00:25,  1.55it/s]batch_idx: 100\n",
            "loss: 0.3619978427886963\n",
            "##### Train Epoch: 8  [400/7000  (71%)]\tLoss:0.361998\n",
            "Overall Loss=0.3557 Mask loss=0.01 Depth loss=0.33: 100% 140/140 [01:30<00:00,  1.54it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.390923622995615\n",
            " 83% 50/60 [00:30<00:05,  1.67it/s]batch_idx: 50\n",
            "loss: 0.3888107165694237\n",
            "100% 60/60 [00:36<00:00,  1.65it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3914, Mask Loss: 0.02, Depth Loss: 0.34\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:9#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3591 Mask loss=0.01 Depth loss=0.34:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.35907813906669617\n",
            "##### Train Epoch: 9  [0/7000  (0%)]\tLoss:0.359078\n",
            "Overall Loss=0.3616 Mask loss=0.01 Depth loss=0.34:  36% 50/140 [00:33<00:57,  1.58it/s]batch_idx: 50\n",
            "loss: 0.3616444766521454\n",
            "##### Train Epoch: 9  [200/7000  (36%)]\tLoss:0.361644\n",
            "Overall Loss=0.3532 Mask loss=0.01 Depth loss=0.33:  71% 100/140 [01:05<00:25,  1.58it/s]batch_idx: 100\n",
            "loss: 0.35316985845565796\n",
            "##### Train Epoch: 9  [400/7000  (71%)]\tLoss:0.353170\n",
            "Overall Loss=0.3573 Mask loss=0.01 Depth loss=0.33: 100% 140/140 [01:31<00:00,  1.53it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3792813643813133\n",
            " 83% 50/60 [00:30<00:06,  1.65it/s]batch_idx: 50\n",
            "loss: 0.3771523591130972\n",
            "100% 60/60 [00:36<00:00,  1.65it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3763, Mask Loss: 0.01, Depth Loss: 0.35\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:10#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3534 Mask loss=0.01 Depth loss=0.33:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3534354567527771\n",
            "##### Train Epoch: 10  [0/7000  (0%)]\tLoss:0.353435\n",
            "Overall Loss=0.3598 Mask loss=0.01 Depth loss=0.34:  36% 50/140 [00:32<00:57,  1.57it/s]batch_idx: 50\n",
            "loss: 0.35978952050209045\n",
            "##### Train Epoch: 10  [200/7000  (36%)]\tLoss:0.359790\n",
            "Overall Loss=0.3588 Mask loss=0.01 Depth loss=0.33:  71% 100/140 [01:05<00:25,  1.56it/s]batch_idx: 100\n",
            "loss: 0.35875624418258667\n",
            "##### Train Epoch: 10  [400/7000  (71%)]\tLoss:0.358756\n",
            "Overall Loss=0.3567 Mask loss=0.01 Depth loss=0.33: 100% 140/140 [01:30<00:00,  1.54it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.38290634006261826\n",
            " 83% 50/60 [00:30<00:06,  1.66it/s]batch_idx: 50\n",
            "loss: 0.38626646995544434\n",
            "100% 60/60 [00:36<00:00,  1.65it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3841, Mask Loss: 0.02, Depth Loss: 0.35\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "time: 35min 4s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Wn1H5XGg6OcY"
      },
      "source": [
        "# Batch_13 dataset : On Gray Images\n",
        "        Dataset size : 30K\n",
        "            - Train (70%)  : 21K  \n",
        "            - Test  (30%)  : 9K\n",
        "        Batch Size   : 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "9a74ae0a-26df-48a5-808d-a2bce826ae38",
        "id": "ZmCCkaBY6Ocb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "os.chdir(r'/content/drive/My Drive/EVA4/S15/scripts/pythonFiles')\n",
        "!python train_mask_depth.py -z '/content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_12.zip' -e 5  -bs 50"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are executing model on : cuda\n",
            "Dataset using : /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_12.zip\n",
            "Train Dataset : 21000\n",
            "Test Dataset : 9000\n",
            "\t In batch size of : 50\n",
            "cuda\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]          18,816\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "   ConvTranspose2d-5        [-1, 128, 111, 111]           8,192\n",
            "            Conv2d-6          [-1, 128, 28, 28]          73,728\n",
            "            Conv2d-7          [-1, 128, 28, 28]          16,384\n",
            "       BatchNorm2d-8          [-1, 128, 28, 28]             256\n",
            "              ReLU-9          [-1, 128, 28, 28]               0\n",
            "           Conv2d-10          [-1, 128, 14, 14]         147,456\n",
            "           Conv2d-11          [-1, 128, 14, 14]          16,384\n",
            "      BatchNorm2d-12          [-1, 128, 14, 14]             256\n",
            "             ReLU-13          [-1, 128, 14, 14]               0\n",
            "         Downsize-14          [-1, 128, 14, 14]               0\n",
            "  ConvTranspose2d-15          [-1, 256, 27, 27]          32,768\n",
            "           Conv2d-16            [-1, 256, 7, 7]         294,912\n",
            "           Conv2d-17            [-1, 256, 7, 7]          65,536\n",
            "      BatchNorm2d-18            [-1, 256, 7, 7]             512\n",
            "             ReLU-19            [-1, 256, 7, 7]               0\n",
            "           Conv2d-20            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-21            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-22            [-1, 256, 4, 4]             512\n",
            "             ReLU-23            [-1, 256, 4, 4]               0\n",
            "         Downsize-24            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-25            [-1, 512, 7, 7]         131,072\n",
            "           Conv2d-26            [-1, 512, 2, 2]       1,179,648\n",
            "           Conv2d-27            [-1, 512, 2, 2]         262,144\n",
            "      BatchNorm2d-28            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-29            [-1, 512, 2, 2]               0\n",
            "           Conv2d-30            [-1, 512, 1, 1]       2,359,296\n",
            "           Conv2d-31            [-1, 512, 1, 1]         262,144\n",
            "      BatchNorm2d-32            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-33            [-1, 512, 1, 1]               0\n",
            "         Downsize-34            [-1, 512, 1, 1]               0\n",
            "  ConvTranspose2d-35            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-36            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-37            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-38            [-1, 256, 4, 4]             512\n",
            "             ReLU-39            [-1, 256, 4, 4]               0\n",
            "           Conv2d-40            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-41            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-42            [-1, 256, 4, 4]             512\n",
            "             ReLU-43            [-1, 256, 4, 4]               0\n",
            "           Upsize-44            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-45          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-46          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-47          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-48          [-1, 128, 28, 28]             256\n",
            "             ReLU-49          [-1, 128, 28, 28]               0\n",
            "           Conv2d-50          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-51          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-52          [-1, 128, 28, 28]             256\n",
            "             ReLU-53          [-1, 128, 28, 28]               0\n",
            "           Upsize-54          [-1, 128, 28, 28]               0\n",
            "  ConvTranspose2d-55           [-1, 64, 56, 56]          73,728\n",
            "           Conv2d-56           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-57           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-58           [-1, 64, 56, 56]             128\n",
            "             ReLU-59           [-1, 64, 56, 56]               0\n",
            "           Conv2d-60           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-61           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-62           [-1, 64, 56, 56]             128\n",
            "             ReLU-63           [-1, 64, 56, 56]               0\n",
            "           Upsize-64           [-1, 64, 56, 56]               0\n",
            "  ConvTranspose2d-65         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-66         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-67         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-68         [-1, 64, 112, 112]             128\n",
            "             ReLU-69         [-1, 64, 112, 112]               0\n",
            "           Conv2d-70         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-71         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-72         [-1, 64, 112, 112]             128\n",
            "             ReLU-73         [-1, 64, 112, 112]               0\n",
            "           Upsize-74         [-1, 64, 112, 112]               0\n",
            "  ConvTranspose2d-75         [-1, 32, 224, 224]          18,432\n",
            "           Conv2d-76         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-77         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-78         [-1, 32, 224, 224]              64\n",
            "             ReLU-79         [-1, 32, 224, 224]               0\n",
            "           Conv2d-80         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-81         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-82         [-1, 32, 224, 224]              64\n",
            "             ReLU-83         [-1, 32, 224, 224]               0\n",
            "           Upsize-84         [-1, 32, 224, 224]               0\n",
            "           Conv2d-85          [-1, 1, 224, 224]              32\n",
            "  ConvTranspose2d-86            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-87            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-88            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-89            [-1, 256, 4, 4]             512\n",
            "             ReLU-90            [-1, 256, 4, 4]               0\n",
            "           Conv2d-91            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-92            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-93            [-1, 256, 4, 4]             512\n",
            "             ReLU-94            [-1, 256, 4, 4]               0\n",
            "           Upsize-95            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-96          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-97          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-98          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-99          [-1, 128, 28, 28]             256\n",
            "            ReLU-100          [-1, 128, 28, 28]               0\n",
            "          Conv2d-101          [-1, 128, 28, 28]         147,456\n",
            "          Conv2d-102          [-1, 128, 28, 28]          16,384\n",
            "     BatchNorm2d-103          [-1, 128, 28, 28]             256\n",
            "            ReLU-104          [-1, 128, 28, 28]               0\n",
            "          Upsize-105          [-1, 128, 28, 28]               0\n",
            " ConvTranspose2d-106           [-1, 64, 56, 56]          73,728\n",
            "          Conv2d-107           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-108           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-109           [-1, 64, 56, 56]             128\n",
            "            ReLU-110           [-1, 64, 56, 56]               0\n",
            "          Conv2d-111           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-112           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-113           [-1, 64, 56, 56]             128\n",
            "            ReLU-114           [-1, 64, 56, 56]               0\n",
            "          Upsize-115           [-1, 64, 56, 56]               0\n",
            " ConvTranspose2d-116         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-117         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-118         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-119         [-1, 64, 112, 112]             128\n",
            "            ReLU-120         [-1, 64, 112, 112]               0\n",
            "          Conv2d-121         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-122         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-123         [-1, 64, 112, 112]             128\n",
            "            ReLU-124         [-1, 64, 112, 112]               0\n",
            "          Upsize-125         [-1, 64, 112, 112]               0\n",
            " ConvTranspose2d-126         [-1, 32, 224, 224]          18,432\n",
            "          Conv2d-127         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-128         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-129         [-1, 32, 224, 224]              64\n",
            "            ReLU-130         [-1, 32, 224, 224]               0\n",
            "          Conv2d-131         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-132         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-133         [-1, 32, 224, 224]              64\n",
            "            ReLU-134         [-1, 32, 224, 224]               0\n",
            "          Upsize-135         [-1, 32, 224, 224]               0\n",
            "          Conv2d-136          [-1, 1, 224, 224]              33\n",
            "================================================================\n",
            "Total params: 12,384,577\n",
            "Trainable params: 12,384,577\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.15\n",
            "Forward/backward pass size (MB): 453.02\n",
            "Params size (MB): 47.24\n",
            "Estimated Total Size (MB): 501.41\n",
            "----------------------------------------------------------------\n",
            "You are running /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_12.zip dataset for 5 epochs\n",
            "Loading model : batch_best.ckp.pt\n",
            "Model is loaded and valid_loss_min is :0.3534224331378937\n",
            "\n",
            "###########EPOCH:1#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3605 Mask loss=0.01 Depth loss=0.34:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.36053329706192017\n",
            "##### Train Epoch: 1  [0/7000  (0%)]\tLoss:0.360533\n",
            "Overall Loss=0.3590 Mask loss=0.01 Depth loss=0.34:  36% 50/140 [00:33<00:58,  1.53it/s]batch_idx: 50\n",
            "loss: 0.3589952290058136\n",
            "##### Train Epoch: 1  [200/7000  (36%)]\tLoss:0.358995\n",
            "Overall Loss=0.3558 Mask loss=0.01 Depth loss=0.33:  71% 100/140 [01:06<00:25,  1.57it/s]batch_idx: 100\n",
            "loss: 0.35579827427864075\n",
            "##### Train Epoch: 1  [400/7000  (71%)]\tLoss:0.355798\n",
            "Overall Loss=0.3665 Mask loss=0.01 Depth loss=0.34: 100% 140/140 [01:31<00:00,  1.53it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3782793805003166\n",
            " 83% 50/60 [00:30<00:06,  1.65it/s]batch_idx: 50\n",
            "loss: 0.3764803670346737\n",
            "100% 60/60 [00:36<00:00,  1.65it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3772, Mask Loss: 0.02, Depth Loss: 0.35\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:2#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3507 Mask loss=0.01 Depth loss=0.33:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.35069239139556885\n",
            "##### Train Epoch: 2  [0/7000  (0%)]\tLoss:0.350692\n",
            "Overall Loss=0.3665 Mask loss=0.01 Depth loss=0.34:  36% 50/140 [00:33<00:57,  1.56it/s]batch_idx: 50\n",
            "loss: 0.36647936701774597\n",
            "##### Train Epoch: 2  [200/7000  (36%)]\tLoss:0.366479\n",
            "Overall Loss=0.3572 Mask loss=0.01 Depth loss=0.33:  71% 100/140 [01:06<00:25,  1.55it/s]batch_idx: 100\n",
            "loss: 0.3572408854961395\n",
            "##### Train Epoch: 2  [400/7000  (71%)]\tLoss:0.357241\n",
            "Overall Loss=0.3547 Mask loss=0.01 Depth loss=0.33: 100% 140/140 [01:31<00:00,  1.52it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3909416124224663\n",
            " 83% 50/60 [00:30<00:06,  1.65it/s]batch_idx: 50\n",
            "loss: 0.3841576911509037\n",
            "100% 60/60 [00:36<00:00,  1.65it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3837, Mask Loss: 0.02, Depth Loss: 0.34\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:3#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3528 Mask loss=0.01 Depth loss=0.33:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3527827262878418\n",
            "##### Train Epoch: 3  [0/7000  (0%)]\tLoss:0.352783\n",
            "Overall Loss=0.3596 Mask loss=0.01 Depth loss=0.33:  36% 50/140 [00:33<00:57,  1.57it/s]batch_idx: 50\n",
            "loss: 0.35964086651802063\n",
            "##### Train Epoch: 3  [200/7000  (36%)]\tLoss:0.359641\n",
            "Overall Loss=0.3595 Mask loss=0.01 Depth loss=0.34:  71% 100/140 [01:05<00:25,  1.56it/s]batch_idx: 100\n",
            "loss: 0.3594870865345001\n",
            "##### Train Epoch: 3  [400/7000  (71%)]\tLoss:0.359487\n",
            "Overall Loss=0.3581 Mask loss=0.01 Depth loss=0.33: 100% 140/140 [01:31<00:00,  1.54it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3763623982667923\n",
            " 83% 50/60 [00:30<00:06,  1.66it/s]batch_idx: 50\n",
            "loss: 0.3753530438989401\n",
            "100% 60/60 [00:36<00:00,  1.65it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3742, Mask Loss: 0.01, Depth Loss: 0.34\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:4#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3575 Mask loss=0.01 Depth loss=0.33:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3574647009372711\n",
            "##### Train Epoch: 4  [0/7000  (0%)]\tLoss:0.357465\n",
            "Overall Loss=0.3580 Mask loss=0.01 Depth loss=0.33:  36% 50/140 [00:33<00:58,  1.53it/s]batch_idx: 50\n",
            "loss: 0.35803064703941345\n",
            "##### Train Epoch: 4  [200/7000  (36%)]\tLoss:0.358031\n",
            "Overall Loss=0.3542 Mask loss=0.01 Depth loss=0.33:  71% 100/140 [01:06<00:26,  1.51it/s]batch_idx: 100\n",
            "loss: 0.35416048765182495\n",
            "##### Train Epoch: 4  [400/7000  (71%)]\tLoss:0.354160\n",
            "Overall Loss=0.3561 Mask loss=0.01 Depth loss=0.33: 100% 140/140 [01:31<00:00,  1.53it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.37764343060553074\n",
            " 83% 50/60 [00:30<00:06,  1.65it/s]batch_idx: 50\n",
            "loss: 0.3757406771183014\n",
            "100% 60/60 [00:36<00:00,  1.65it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3743, Mask Loss: 0.01, Depth Loss: 0.35\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:5#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3571 Mask loss=0.01 Depth loss=0.33:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3570931851863861\n",
            "##### Train Epoch: 5  [0/7000  (0%)]\tLoss:0.357093\n",
            "Overall Loss=0.3560 Mask loss=0.01 Depth loss=0.33:  36% 50/140 [00:33<00:58,  1.55it/s]batch_idx: 50\n",
            "loss: 0.3559930622577667\n",
            "##### Train Epoch: 5  [200/7000  (36%)]\tLoss:0.355993\n",
            "Overall Loss=0.3580 Mask loss=0.01 Depth loss=0.34:  71% 100/140 [01:05<00:25,  1.57it/s]batch_idx: 100\n",
            "loss: 0.35803449153900146\n",
            "##### Train Epoch: 5  [400/7000  (71%)]\tLoss:0.358034\n",
            "Overall Loss=0.3611 Mask loss=0.01 Depth loss=0.34: 100% 140/140 [01:31<00:00,  1.54it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3785407543182373\n",
            " 83% 50/60 [00:30<00:06,  1.62it/s]batch_idx: 50\n",
            "loss: 0.3742973767220974\n",
            "100% 60/60 [00:36<00:00,  1.64it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3746, Mask Loss: 0.02, Depth Loss: 0.34\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "time: 12min 33s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "3dSYKXeLknCC"
      },
      "source": [
        "# Batch_14 dataset : On Gray Images\n",
        "        Dataset size : 30K\n",
        "            - Train (70%)  : 21K  \n",
        "            - Test  (30%)  : 9K\n",
        "        Batch Size   : 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "45296403-c45a-420f-cadf-c0184066dc5f",
        "id": "IWaPjbZOknCL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "os.chdir(r'/content/drive/My Drive/EVA4/S15/scripts/pythonFiles')\n",
        "!python train_mask_depth.py -z '/content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_14.zip' -e 5  -bs 50"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are executing model on : cuda\n",
            "Dataset using : /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_13.zip\n",
            "Train Dataset : 21000\n",
            "Test Dataset : 9000\n",
            "\t In batch size of : 50\n",
            "cuda\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]          18,816\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "   ConvTranspose2d-5        [-1, 128, 111, 111]           8,192\n",
            "            Conv2d-6          [-1, 128, 28, 28]          73,728\n",
            "            Conv2d-7          [-1, 128, 28, 28]          16,384\n",
            "       BatchNorm2d-8          [-1, 128, 28, 28]             256\n",
            "              ReLU-9          [-1, 128, 28, 28]               0\n",
            "           Conv2d-10          [-1, 128, 14, 14]         147,456\n",
            "           Conv2d-11          [-1, 128, 14, 14]          16,384\n",
            "      BatchNorm2d-12          [-1, 128, 14, 14]             256\n",
            "             ReLU-13          [-1, 128, 14, 14]               0\n",
            "         Downsize-14          [-1, 128, 14, 14]               0\n",
            "  ConvTranspose2d-15          [-1, 256, 27, 27]          32,768\n",
            "           Conv2d-16            [-1, 256, 7, 7]         294,912\n",
            "           Conv2d-17            [-1, 256, 7, 7]          65,536\n",
            "      BatchNorm2d-18            [-1, 256, 7, 7]             512\n",
            "             ReLU-19            [-1, 256, 7, 7]               0\n",
            "           Conv2d-20            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-21            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-22            [-1, 256, 4, 4]             512\n",
            "             ReLU-23            [-1, 256, 4, 4]               0\n",
            "         Downsize-24            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-25            [-1, 512, 7, 7]         131,072\n",
            "           Conv2d-26            [-1, 512, 2, 2]       1,179,648\n",
            "           Conv2d-27            [-1, 512, 2, 2]         262,144\n",
            "      BatchNorm2d-28            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-29            [-1, 512, 2, 2]               0\n",
            "           Conv2d-30            [-1, 512, 1, 1]       2,359,296\n",
            "           Conv2d-31            [-1, 512, 1, 1]         262,144\n",
            "      BatchNorm2d-32            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-33            [-1, 512, 1, 1]               0\n",
            "         Downsize-34            [-1, 512, 1, 1]               0\n",
            "  ConvTranspose2d-35            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-36            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-37            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-38            [-1, 256, 4, 4]             512\n",
            "             ReLU-39            [-1, 256, 4, 4]               0\n",
            "           Conv2d-40            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-41            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-42            [-1, 256, 4, 4]             512\n",
            "             ReLU-43            [-1, 256, 4, 4]               0\n",
            "           Upsize-44            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-45          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-46          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-47          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-48          [-1, 128, 28, 28]             256\n",
            "             ReLU-49          [-1, 128, 28, 28]               0\n",
            "           Conv2d-50          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-51          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-52          [-1, 128, 28, 28]             256\n",
            "             ReLU-53          [-1, 128, 28, 28]               0\n",
            "           Upsize-54          [-1, 128, 28, 28]               0\n",
            "  ConvTranspose2d-55           [-1, 64, 56, 56]          73,728\n",
            "           Conv2d-56           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-57           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-58           [-1, 64, 56, 56]             128\n",
            "             ReLU-59           [-1, 64, 56, 56]               0\n",
            "           Conv2d-60           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-61           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-62           [-1, 64, 56, 56]             128\n",
            "             ReLU-63           [-1, 64, 56, 56]               0\n",
            "           Upsize-64           [-1, 64, 56, 56]               0\n",
            "  ConvTranspose2d-65         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-66         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-67         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-68         [-1, 64, 112, 112]             128\n",
            "             ReLU-69         [-1, 64, 112, 112]               0\n",
            "           Conv2d-70         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-71         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-72         [-1, 64, 112, 112]             128\n",
            "             ReLU-73         [-1, 64, 112, 112]               0\n",
            "           Upsize-74         [-1, 64, 112, 112]               0\n",
            "  ConvTranspose2d-75         [-1, 32, 224, 224]          18,432\n",
            "           Conv2d-76         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-77         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-78         [-1, 32, 224, 224]              64\n",
            "             ReLU-79         [-1, 32, 224, 224]               0\n",
            "           Conv2d-80         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-81         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-82         [-1, 32, 224, 224]              64\n",
            "             ReLU-83         [-1, 32, 224, 224]               0\n",
            "           Upsize-84         [-1, 32, 224, 224]               0\n",
            "           Conv2d-85          [-1, 1, 224, 224]              32\n",
            "  ConvTranspose2d-86            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-87            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-88            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-89            [-1, 256, 4, 4]             512\n",
            "             ReLU-90            [-1, 256, 4, 4]               0\n",
            "           Conv2d-91            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-92            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-93            [-1, 256, 4, 4]             512\n",
            "             ReLU-94            [-1, 256, 4, 4]               0\n",
            "           Upsize-95            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-96          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-97          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-98          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-99          [-1, 128, 28, 28]             256\n",
            "            ReLU-100          [-1, 128, 28, 28]               0\n",
            "          Conv2d-101          [-1, 128, 28, 28]         147,456\n",
            "          Conv2d-102          [-1, 128, 28, 28]          16,384\n",
            "     BatchNorm2d-103          [-1, 128, 28, 28]             256\n",
            "            ReLU-104          [-1, 128, 28, 28]               0\n",
            "          Upsize-105          [-1, 128, 28, 28]               0\n",
            " ConvTranspose2d-106           [-1, 64, 56, 56]          73,728\n",
            "          Conv2d-107           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-108           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-109           [-1, 64, 56, 56]             128\n",
            "            ReLU-110           [-1, 64, 56, 56]               0\n",
            "          Conv2d-111           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-112           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-113           [-1, 64, 56, 56]             128\n",
            "            ReLU-114           [-1, 64, 56, 56]               0\n",
            "          Upsize-115           [-1, 64, 56, 56]               0\n",
            " ConvTranspose2d-116         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-117         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-118         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-119         [-1, 64, 112, 112]             128\n",
            "            ReLU-120         [-1, 64, 112, 112]               0\n",
            "          Conv2d-121         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-122         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-123         [-1, 64, 112, 112]             128\n",
            "            ReLU-124         [-1, 64, 112, 112]               0\n",
            "          Upsize-125         [-1, 64, 112, 112]               0\n",
            " ConvTranspose2d-126         [-1, 32, 224, 224]          18,432\n",
            "          Conv2d-127         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-128         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-129         [-1, 32, 224, 224]              64\n",
            "            ReLU-130         [-1, 32, 224, 224]               0\n",
            "          Conv2d-131         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-132         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-133         [-1, 32, 224, 224]              64\n",
            "            ReLU-134         [-1, 32, 224, 224]               0\n",
            "          Upsize-135         [-1, 32, 224, 224]               0\n",
            "          Conv2d-136          [-1, 1, 224, 224]              33\n",
            "================================================================\n",
            "Total params: 12,384,577\n",
            "Trainable params: 12,384,577\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.15\n",
            "Forward/backward pass size (MB): 453.02\n",
            "Params size (MB): 47.24\n",
            "Estimated Total Size (MB): 501.41\n",
            "----------------------------------------------------------------\n",
            "You are running /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_13.zip dataset for 5 epochs\n",
            "Loading model : batch_best.ckp.pt\n",
            "Model is loaded and valid_loss_min is :0.3534224331378937\n",
            "\n",
            "###########EPOCH:1#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.4569 Mask loss=0.01 Depth loss=0.43:   0% 0/140 [01:05<?, ?it/s]batch_idx: 0\n",
            "loss: 0.4569050371646881\n",
            "##### Train Epoch: 1  [0/7000  (0%)]\tLoss:0.456905\n",
            "Overall Loss=0.3858 Mask loss=0.01 Depth loss=0.36:  36% 50/140 [11:09<03:14,  2.16s/it]batch_idx: 50\n",
            "loss: 0.38584235310554504\n",
            "##### Train Epoch: 1  [200/7000  (36%)]\tLoss:0.385842\n",
            "Overall Loss=0.3835 Mask loss=0.01 Depth loss=0.36:  71% 100/140 [12:07<00:33,  1.20it/s]batch_idx: 100\n",
            "loss: 0.383466899394989\n",
            "##### Train Epoch: 1  [400/7000  (71%)]\tLoss:0.383467\n",
            "Overall Loss=0.3806 Mask loss=0.01 Depth loss=0.36: 100% 140/140 [12:32<00:00,  5.38s/it]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.40381746739149094\n",
            " 83% 50/60 [00:29<00:05,  1.70it/s]batch_idx: 50\n",
            "loss: 0.4027148634195328\n",
            "100% 60/60 [00:35<00:00,  1.69it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.4025, Mask Loss: 0.01, Depth Loss: 0.37\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:2#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3854 Mask loss=0.01 Depth loss=0.36:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3854268789291382\n",
            "##### Train Epoch: 2  [0/7000  (0%)]\tLoss:0.385427\n",
            "Overall Loss=0.3813 Mask loss=0.01 Depth loss=0.36:  36% 50/140 [00:32<00:56,  1.58it/s]batch_idx: 50\n",
            "loss: 0.38134247064590454\n",
            "##### Train Epoch: 2  [200/7000  (36%)]\tLoss:0.381342\n",
            "Overall Loss=0.3845 Mask loss=0.01 Depth loss=0.36:  71% 100/140 [01:05<00:25,  1.57it/s]batch_idx: 100\n",
            "loss: 0.3844578266143799\n",
            "##### Train Epoch: 2  [400/7000  (71%)]\tLoss:0.384458\n",
            "Overall Loss=0.3796 Mask loss=0.01 Depth loss=0.36: 100% 140/140 [01:30<00:00,  1.55it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.4355968050658703\n",
            " 83% 50/60 [00:29<00:05,  1.68it/s]batch_idx: 50\n",
            "loss: 0.4316429942846298\n",
            "100% 60/60 [00:35<00:00,  1.70it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.4318, Mask Loss: 0.03, Depth Loss: 0.37\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:3#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3829 Mask loss=0.01 Depth loss=0.36:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3829490542411804\n",
            "##### Train Epoch: 3  [0/7000  (0%)]\tLoss:0.382949\n",
            "Overall Loss=0.3782 Mask loss=0.01 Depth loss=0.36:  36% 50/140 [00:32<00:58,  1.54it/s]batch_idx: 50\n",
            "loss: 0.37817174196243286\n",
            "##### Train Epoch: 3  [200/7000  (36%)]\tLoss:0.378172\n",
            "Overall Loss=0.3826 Mask loss=0.01 Depth loss=0.36:  71% 100/140 [01:04<00:25,  1.58it/s]batch_idx: 100\n",
            "loss: 0.38263648748397827\n",
            "##### Train Epoch: 3  [400/7000  (71%)]\tLoss:0.382636\n",
            "Overall Loss=0.3800 Mask loss=0.01 Depth loss=0.36: 100% 140/140 [01:29<00:00,  1.56it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.40598074346780777\n",
            " 83% 50/60 [00:29<00:05,  1.71it/s]batch_idx: 50\n",
            "loss: 0.4021155871450901\n",
            "100% 60/60 [00:35<00:00,  1.70it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.4068, Mask Loss: 0.01, Depth Loss: 0.38\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:4#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3853 Mask loss=0.01 Depth loss=0.36:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.38531294465065\n",
            "##### Train Epoch: 4  [0/7000  (0%)]\tLoss:0.385313\n",
            "Overall Loss=0.3824 Mask loss=0.01 Depth loss=0.36:  36% 50/140 [00:32<00:56,  1.58it/s]batch_idx: 50\n",
            "loss: 0.38243451714515686\n",
            "##### Train Epoch: 4  [200/7000  (36%)]\tLoss:0.382435\n",
            "Overall Loss=0.3816 Mask loss=0.01 Depth loss=0.36:  71% 100/140 [01:04<00:25,  1.54it/s]batch_idx: 100\n",
            "loss: 0.3816281259059906\n",
            "##### Train Epoch: 4  [400/7000  (71%)]\tLoss:0.381628\n",
            "Overall Loss=0.3810 Mask loss=0.01 Depth loss=0.36: 100% 140/140 [01:30<00:00,  1.55it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.40708852373063564\n",
            " 83% 50/60 [00:29<00:05,  1.70it/s]batch_idx: 50\n",
            "loss: 0.4093775488436222\n",
            "100% 60/60 [00:35<00:00,  1.71it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.4080, Mask Loss: 0.01, Depth Loss: 0.38\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:5#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3809 Mask loss=0.01 Depth loss=0.36:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3809014558792114\n",
            "##### Train Epoch: 5  [0/7000  (0%)]\tLoss:0.380901\n",
            "Overall Loss=0.3825 Mask loss=0.01 Depth loss=0.36:  36% 50/140 [00:32<00:57,  1.57it/s]batch_idx: 50\n",
            "loss: 0.38248303532600403\n",
            "##### Train Epoch: 5  [200/7000  (36%)]\tLoss:0.382483\n",
            "Overall Loss=0.3809 Mask loss=0.01 Depth loss=0.36:  71% 100/140 [01:04<00:25,  1.58it/s]batch_idx: 100\n",
            "loss: 0.38087964057922363\n",
            "##### Train Epoch: 5  [400/7000  (71%)]\tLoss:0.380880\n",
            "Overall Loss=0.3817 Mask loss=0.01 Depth loss=0.36: 100% 140/140 [01:29<00:00,  1.56it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.42001525312662125\n",
            " 83% 50/60 [00:29<00:05,  1.71it/s]batch_idx: 50\n",
            "loss: 0.4178320951759815\n",
            "100% 60/60 [00:35<00:00,  1.70it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.4179, Mask Loss: 0.02, Depth Loss: 0.38\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "time: 23min 51s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "GeeAS0pfwdKu"
      },
      "source": [
        "# Batch_15 dataset : On Gray Images\n",
        "        Dataset size : 30K\n",
        "            - Train (70%)  : 21K  \n",
        "            - Test  (30%)  : 9K\n",
        "        Batch Size   : 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "6ef2d1d9-85c8-4507-8365-5f12ee3a83e1",
        "id": "ftb3MajjwdK7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "os.chdir(r'/content/drive/My Drive/EVA4/S15/scripts/pythonFiles')\n",
        "!python train_mask_depth.py -z '/content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_15.zip' -e 5  -bs 50"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are executing model on : cuda\n",
            "Dataset using : /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_15.zip\n",
            "Train Dataset : 21000\n",
            "Test Dataset : 9000\n",
            "\t In batch size of : 50\n",
            "cuda\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]          18,816\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "   ConvTranspose2d-5        [-1, 128, 111, 111]           8,192\n",
            "            Conv2d-6          [-1, 128, 28, 28]          73,728\n",
            "            Conv2d-7          [-1, 128, 28, 28]          16,384\n",
            "       BatchNorm2d-8          [-1, 128, 28, 28]             256\n",
            "              ReLU-9          [-1, 128, 28, 28]               0\n",
            "           Conv2d-10          [-1, 128, 14, 14]         147,456\n",
            "           Conv2d-11          [-1, 128, 14, 14]          16,384\n",
            "      BatchNorm2d-12          [-1, 128, 14, 14]             256\n",
            "             ReLU-13          [-1, 128, 14, 14]               0\n",
            "         Downsize-14          [-1, 128, 14, 14]               0\n",
            "  ConvTranspose2d-15          [-1, 256, 27, 27]          32,768\n",
            "           Conv2d-16            [-1, 256, 7, 7]         294,912\n",
            "           Conv2d-17            [-1, 256, 7, 7]          65,536\n",
            "      BatchNorm2d-18            [-1, 256, 7, 7]             512\n",
            "             ReLU-19            [-1, 256, 7, 7]               0\n",
            "           Conv2d-20            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-21            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-22            [-1, 256, 4, 4]             512\n",
            "             ReLU-23            [-1, 256, 4, 4]               0\n",
            "         Downsize-24            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-25            [-1, 512, 7, 7]         131,072\n",
            "           Conv2d-26            [-1, 512, 2, 2]       1,179,648\n",
            "           Conv2d-27            [-1, 512, 2, 2]         262,144\n",
            "      BatchNorm2d-28            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-29            [-1, 512, 2, 2]               0\n",
            "           Conv2d-30            [-1, 512, 1, 1]       2,359,296\n",
            "           Conv2d-31            [-1, 512, 1, 1]         262,144\n",
            "      BatchNorm2d-32            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-33            [-1, 512, 1, 1]               0\n",
            "         Downsize-34            [-1, 512, 1, 1]               0\n",
            "  ConvTranspose2d-35            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-36            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-37            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-38            [-1, 256, 4, 4]             512\n",
            "             ReLU-39            [-1, 256, 4, 4]               0\n",
            "           Conv2d-40            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-41            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-42            [-1, 256, 4, 4]             512\n",
            "             ReLU-43            [-1, 256, 4, 4]               0\n",
            "           Upsize-44            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-45          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-46          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-47          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-48          [-1, 128, 28, 28]             256\n",
            "             ReLU-49          [-1, 128, 28, 28]               0\n",
            "           Conv2d-50          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-51          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-52          [-1, 128, 28, 28]             256\n",
            "             ReLU-53          [-1, 128, 28, 28]               0\n",
            "           Upsize-54          [-1, 128, 28, 28]               0\n",
            "  ConvTranspose2d-55           [-1, 64, 56, 56]          73,728\n",
            "           Conv2d-56           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-57           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-58           [-1, 64, 56, 56]             128\n",
            "             ReLU-59           [-1, 64, 56, 56]               0\n",
            "           Conv2d-60           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-61           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-62           [-1, 64, 56, 56]             128\n",
            "             ReLU-63           [-1, 64, 56, 56]               0\n",
            "           Upsize-64           [-1, 64, 56, 56]               0\n",
            "  ConvTranspose2d-65         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-66         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-67         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-68         [-1, 64, 112, 112]             128\n",
            "             ReLU-69         [-1, 64, 112, 112]               0\n",
            "           Conv2d-70         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-71         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-72         [-1, 64, 112, 112]             128\n",
            "             ReLU-73         [-1, 64, 112, 112]               0\n",
            "           Upsize-74         [-1, 64, 112, 112]               0\n",
            "  ConvTranspose2d-75         [-1, 32, 224, 224]          18,432\n",
            "           Conv2d-76         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-77         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-78         [-1, 32, 224, 224]              64\n",
            "             ReLU-79         [-1, 32, 224, 224]               0\n",
            "           Conv2d-80         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-81         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-82         [-1, 32, 224, 224]              64\n",
            "             ReLU-83         [-1, 32, 224, 224]               0\n",
            "           Upsize-84         [-1, 32, 224, 224]               0\n",
            "           Conv2d-85          [-1, 1, 224, 224]              32\n",
            "  ConvTranspose2d-86            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-87            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-88            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-89            [-1, 256, 4, 4]             512\n",
            "             ReLU-90            [-1, 256, 4, 4]               0\n",
            "           Conv2d-91            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-92            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-93            [-1, 256, 4, 4]             512\n",
            "             ReLU-94            [-1, 256, 4, 4]               0\n",
            "           Upsize-95            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-96          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-97          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-98          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-99          [-1, 128, 28, 28]             256\n",
            "            ReLU-100          [-1, 128, 28, 28]               0\n",
            "          Conv2d-101          [-1, 128, 28, 28]         147,456\n",
            "          Conv2d-102          [-1, 128, 28, 28]          16,384\n",
            "     BatchNorm2d-103          [-1, 128, 28, 28]             256\n",
            "            ReLU-104          [-1, 128, 28, 28]               0\n",
            "          Upsize-105          [-1, 128, 28, 28]               0\n",
            " ConvTranspose2d-106           [-1, 64, 56, 56]          73,728\n",
            "          Conv2d-107           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-108           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-109           [-1, 64, 56, 56]             128\n",
            "            ReLU-110           [-1, 64, 56, 56]               0\n",
            "          Conv2d-111           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-112           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-113           [-1, 64, 56, 56]             128\n",
            "            ReLU-114           [-1, 64, 56, 56]               0\n",
            "          Upsize-115           [-1, 64, 56, 56]               0\n",
            " ConvTranspose2d-116         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-117         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-118         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-119         [-1, 64, 112, 112]             128\n",
            "            ReLU-120         [-1, 64, 112, 112]               0\n",
            "          Conv2d-121         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-122         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-123         [-1, 64, 112, 112]             128\n",
            "            ReLU-124         [-1, 64, 112, 112]               0\n",
            "          Upsize-125         [-1, 64, 112, 112]               0\n",
            " ConvTranspose2d-126         [-1, 32, 224, 224]          18,432\n",
            "          Conv2d-127         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-128         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-129         [-1, 32, 224, 224]              64\n",
            "            ReLU-130         [-1, 32, 224, 224]               0\n",
            "          Conv2d-131         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-132         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-133         [-1, 32, 224, 224]              64\n",
            "            ReLU-134         [-1, 32, 224, 224]               0\n",
            "          Upsize-135         [-1, 32, 224, 224]               0\n",
            "          Conv2d-136          [-1, 1, 224, 224]              33\n",
            "================================================================\n",
            "Total params: 12,384,577\n",
            "Trainable params: 12,384,577\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.15\n",
            "Forward/backward pass size (MB): 453.02\n",
            "Params size (MB): 47.24\n",
            "Estimated Total Size (MB): 501.41\n",
            "----------------------------------------------------------------\n",
            "You are running /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_15.zip dataset for 5 epochs\n",
            "Loading model : batch_best.ckp.pt\n",
            "Model is loaded and valid_loss_min is :0.3534224331378937\n",
            "\n",
            "###########EPOCH:1#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.4285 Mask loss=0.01 Depth loss=0.40:   0% 0/140 [00:37<?, ?it/s]batch_idx: 0\n",
            "loss: 0.42846429347991943\n",
            "##### Train Epoch: 1  [0/7000  (0%)]\tLoss:0.428464\n",
            "Overall Loss=0.3700 Mask loss=0.01 Depth loss=0.35:  36% 50/140 [05:35<01:56,  1.29s/it]batch_idx: 50\n",
            "loss: 0.37003853917121887\n",
            "##### Train Epoch: 1  [200/7000  (36%)]\tLoss:0.370039\n",
            "Overall Loss=0.3677 Mask loss=0.01 Depth loss=0.35:  71% 100/140 [06:16<00:26,  1.49it/s]batch_idx: 100\n",
            "loss: 0.3677250146865845\n",
            "##### Train Epoch: 1  [400/7000  (71%)]\tLoss:0.367725\n",
            "Overall Loss=0.3708 Mask loss=0.01 Depth loss=0.35: 100% 140/140 [06:41<00:00,  2.87s/it]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.4049755856394768\n",
            " 83% 50/60 [00:26<00:05,  1.95it/s]batch_idx: 50\n",
            "loss: 0.3964799642562866\n",
            "100% 60/60 [00:31<00:00,  1.91it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3956, Mask Loss: 0.02, Depth Loss: 0.36\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:2#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3640 Mask loss=0.01 Depth loss=0.34:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3640217185020447\n",
            "##### Train Epoch: 2  [0/7000  (0%)]\tLoss:0.364022\n",
            "Overall Loss=0.3691 Mask loss=0.01 Depth loss=0.35:  36% 50/140 [00:32<00:56,  1.59it/s]batch_idx: 50\n",
            "loss: 0.36910712718963623\n",
            "##### Train Epoch: 2  [200/7000  (36%)]\tLoss:0.369107\n",
            "Overall Loss=0.3738 Mask loss=0.01 Depth loss=0.35:  71% 100/140 [01:04<00:25,  1.58it/s]batch_idx: 100\n",
            "loss: 0.37384772300720215\n",
            "##### Train Epoch: 2  [400/7000  (71%)]\tLoss:0.373848\n",
            "Overall Loss=0.3687 Mask loss=0.01 Depth loss=0.34: 100% 140/140 [01:29<00:00,  1.57it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.38370695896446705\n",
            " 83% 50/60 [00:25<00:05,  1.96it/s]batch_idx: 50\n",
            "loss: 0.3845859970897436\n",
            "100% 60/60 [00:30<00:00,  1.95it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3840, Mask Loss: 0.01, Depth Loss: 0.36\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:3#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3655 Mask loss=0.01 Depth loss=0.34:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3655041456222534\n",
            "##### Train Epoch: 3  [0/7000  (0%)]\tLoss:0.365504\n",
            "Overall Loss=0.3678 Mask loss=0.01 Depth loss=0.34:  36% 50/140 [00:32<00:56,  1.58it/s]batch_idx: 50\n",
            "loss: 0.3677610754966736\n",
            "##### Train Epoch: 3  [200/7000  (36%)]\tLoss:0.367761\n",
            "Overall Loss=0.3656 Mask loss=0.01 Depth loss=0.34:  71% 100/140 [01:04<00:25,  1.58it/s]batch_idx: 100\n",
            "loss: 0.36556190252304077\n",
            "##### Train Epoch: 3  [400/7000  (71%)]\tLoss:0.365562\n",
            "Overall Loss=0.3677 Mask loss=0.01 Depth loss=0.34: 100% 140/140 [01:29<00:00,  1.57it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3858644738793373\n",
            " 83% 50/60 [00:25<00:05,  1.94it/s]batch_idx: 50\n",
            "loss: 0.3835375662893057\n",
            "100% 60/60 [00:31<00:00,  1.93it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3842, Mask Loss: 0.01, Depth Loss: 0.36\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:4#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3683 Mask loss=0.01 Depth loss=0.34:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.36831796169281006\n",
            "##### Train Epoch: 4  [0/7000  (0%)]\tLoss:0.368318\n",
            "Overall Loss=0.3639 Mask loss=0.01 Depth loss=0.34:  36% 50/140 [00:32<00:56,  1.58it/s]batch_idx: 50\n",
            "loss: 0.36390405893325806\n",
            "##### Train Epoch: 4  [200/7000  (36%)]\tLoss:0.363904\n",
            "Overall Loss=0.3668 Mask loss=0.01 Depth loss=0.34:  71% 100/140 [01:04<00:25,  1.58it/s]batch_idx: 100\n",
            "loss: 0.3667897880077362\n",
            "##### Train Epoch: 4  [400/7000  (71%)]\tLoss:0.366790\n",
            "Overall Loss=0.3657 Mask loss=0.01 Depth loss=0.34: 100% 140/140 [01:29<00:00,  1.57it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.38740968704223633\n",
            " 83% 50/60 [00:25<00:05,  1.94it/s]batch_idx: 50\n",
            "loss: 0.3893309812992811\n",
            "100% 60/60 [00:31<00:00,  1.93it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3878, Mask Loss: 0.01, Depth Loss: 0.36\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:5#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3664 Mask loss=0.01 Depth loss=0.34:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3664134740829468\n",
            "##### Train Epoch: 5  [0/7000  (0%)]\tLoss:0.366413\n",
            "Overall Loss=0.3644 Mask loss=0.01 Depth loss=0.34:  36% 50/140 [00:32<00:56,  1.58it/s]batch_idx: 50\n",
            "loss: 0.36435237526893616\n",
            "##### Train Epoch: 5  [200/7000  (36%)]\tLoss:0.364352\n",
            "Overall Loss=0.3695 Mask loss=0.01 Depth loss=0.35:  71% 100/140 [01:04<00:25,  1.58it/s]batch_idx: 100\n",
            "loss: 0.36946800351142883\n",
            "##### Train Epoch: 5  [400/7000  (71%)]\tLoss:0.369468\n",
            "Overall Loss=0.3669 Mask loss=0.01 Depth loss=0.35: 100% 140/140 [01:29<00:00,  1.57it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.39153725653886795\n",
            " 83% 50/60 [00:25<00:05,  1.95it/s]batch_idx: 50\n",
            "loss: 0.38831770420074463\n",
            "100% 60/60 [00:30<00:00,  1.94it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3895, Mask Loss: 0.02, Depth Loss: 0.36\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "time: 17min 22s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "5F0dPm3xQ3tf"
      },
      "source": [
        "# Batch_16 dataset : On Gray Images\n",
        "        Dataset size : 30K\n",
        "            - Train (70%)  : 21K  \n",
        "            - Test  (30%)  : 9K\n",
        "        Batch Size   : 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f397181c-4069-4443-cacc-a4e71e19ce87",
        "id": "HQkVHONtQ3ty",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "os.chdir(r'/content/drive/My Drive/EVA4/S15/scripts/pythonFiles')\n",
        "!python train_mask_depth.py -z '/content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_16.zip' -e 5  -bs 50"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are executing model on : cuda\n",
            "Dataset using : /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_16.zip\n",
            "Train Dataset : 21000\n",
            "Test Dataset : 9000\n",
            "\t In batch size of : 50\n",
            "cuda\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]          18,816\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "   ConvTranspose2d-5        [-1, 128, 111, 111]           8,192\n",
            "            Conv2d-6          [-1, 128, 28, 28]          73,728\n",
            "            Conv2d-7          [-1, 128, 28, 28]          16,384\n",
            "       BatchNorm2d-8          [-1, 128, 28, 28]             256\n",
            "              ReLU-9          [-1, 128, 28, 28]               0\n",
            "           Conv2d-10          [-1, 128, 14, 14]         147,456\n",
            "           Conv2d-11          [-1, 128, 14, 14]          16,384\n",
            "      BatchNorm2d-12          [-1, 128, 14, 14]             256\n",
            "             ReLU-13          [-1, 128, 14, 14]               0\n",
            "         Downsize-14          [-1, 128, 14, 14]               0\n",
            "  ConvTranspose2d-15          [-1, 256, 27, 27]          32,768\n",
            "           Conv2d-16            [-1, 256, 7, 7]         294,912\n",
            "           Conv2d-17            [-1, 256, 7, 7]          65,536\n",
            "      BatchNorm2d-18            [-1, 256, 7, 7]             512\n",
            "             ReLU-19            [-1, 256, 7, 7]               0\n",
            "           Conv2d-20            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-21            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-22            [-1, 256, 4, 4]             512\n",
            "             ReLU-23            [-1, 256, 4, 4]               0\n",
            "         Downsize-24            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-25            [-1, 512, 7, 7]         131,072\n",
            "           Conv2d-26            [-1, 512, 2, 2]       1,179,648\n",
            "           Conv2d-27            [-1, 512, 2, 2]         262,144\n",
            "      BatchNorm2d-28            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-29            [-1, 512, 2, 2]               0\n",
            "           Conv2d-30            [-1, 512, 1, 1]       2,359,296\n",
            "           Conv2d-31            [-1, 512, 1, 1]         262,144\n",
            "      BatchNorm2d-32            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-33            [-1, 512, 1, 1]               0\n",
            "         Downsize-34            [-1, 512, 1, 1]               0\n",
            "  ConvTranspose2d-35            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-36            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-37            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-38            [-1, 256, 4, 4]             512\n",
            "             ReLU-39            [-1, 256, 4, 4]               0\n",
            "           Conv2d-40            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-41            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-42            [-1, 256, 4, 4]             512\n",
            "             ReLU-43            [-1, 256, 4, 4]               0\n",
            "           Upsize-44            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-45          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-46          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-47          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-48          [-1, 128, 28, 28]             256\n",
            "             ReLU-49          [-1, 128, 28, 28]               0\n",
            "           Conv2d-50          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-51          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-52          [-1, 128, 28, 28]             256\n",
            "             ReLU-53          [-1, 128, 28, 28]               0\n",
            "           Upsize-54          [-1, 128, 28, 28]               0\n",
            "  ConvTranspose2d-55           [-1, 64, 56, 56]          73,728\n",
            "           Conv2d-56           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-57           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-58           [-1, 64, 56, 56]             128\n",
            "             ReLU-59           [-1, 64, 56, 56]               0\n",
            "           Conv2d-60           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-61           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-62           [-1, 64, 56, 56]             128\n",
            "             ReLU-63           [-1, 64, 56, 56]               0\n",
            "           Upsize-64           [-1, 64, 56, 56]               0\n",
            "  ConvTranspose2d-65         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-66         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-67         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-68         [-1, 64, 112, 112]             128\n",
            "             ReLU-69         [-1, 64, 112, 112]               0\n",
            "           Conv2d-70         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-71         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-72         [-1, 64, 112, 112]             128\n",
            "             ReLU-73         [-1, 64, 112, 112]               0\n",
            "           Upsize-74         [-1, 64, 112, 112]               0\n",
            "  ConvTranspose2d-75         [-1, 32, 224, 224]          18,432\n",
            "           Conv2d-76         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-77         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-78         [-1, 32, 224, 224]              64\n",
            "             ReLU-79         [-1, 32, 224, 224]               0\n",
            "           Conv2d-80         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-81         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-82         [-1, 32, 224, 224]              64\n",
            "             ReLU-83         [-1, 32, 224, 224]               0\n",
            "           Upsize-84         [-1, 32, 224, 224]               0\n",
            "           Conv2d-85          [-1, 1, 224, 224]              32\n",
            "  ConvTranspose2d-86            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-87            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-88            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-89            [-1, 256, 4, 4]             512\n",
            "             ReLU-90            [-1, 256, 4, 4]               0\n",
            "           Conv2d-91            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-92            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-93            [-1, 256, 4, 4]             512\n",
            "             ReLU-94            [-1, 256, 4, 4]               0\n",
            "           Upsize-95            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-96          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-97          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-98          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-99          [-1, 128, 28, 28]             256\n",
            "            ReLU-100          [-1, 128, 28, 28]               0\n",
            "          Conv2d-101          [-1, 128, 28, 28]         147,456\n",
            "          Conv2d-102          [-1, 128, 28, 28]          16,384\n",
            "     BatchNorm2d-103          [-1, 128, 28, 28]             256\n",
            "            ReLU-104          [-1, 128, 28, 28]               0\n",
            "          Upsize-105          [-1, 128, 28, 28]               0\n",
            " ConvTranspose2d-106           [-1, 64, 56, 56]          73,728\n",
            "          Conv2d-107           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-108           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-109           [-1, 64, 56, 56]             128\n",
            "            ReLU-110           [-1, 64, 56, 56]               0\n",
            "          Conv2d-111           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-112           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-113           [-1, 64, 56, 56]             128\n",
            "            ReLU-114           [-1, 64, 56, 56]               0\n",
            "          Upsize-115           [-1, 64, 56, 56]               0\n",
            " ConvTranspose2d-116         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-117         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-118         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-119         [-1, 64, 112, 112]             128\n",
            "            ReLU-120         [-1, 64, 112, 112]               0\n",
            "          Conv2d-121         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-122         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-123         [-1, 64, 112, 112]             128\n",
            "            ReLU-124         [-1, 64, 112, 112]               0\n",
            "          Upsize-125         [-1, 64, 112, 112]               0\n",
            " ConvTranspose2d-126         [-1, 32, 224, 224]          18,432\n",
            "          Conv2d-127         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-128         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-129         [-1, 32, 224, 224]              64\n",
            "            ReLU-130         [-1, 32, 224, 224]               0\n",
            "          Conv2d-131         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-132         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-133         [-1, 32, 224, 224]              64\n",
            "            ReLU-134         [-1, 32, 224, 224]               0\n",
            "          Upsize-135         [-1, 32, 224, 224]               0\n",
            "          Conv2d-136          [-1, 1, 224, 224]              33\n",
            "================================================================\n",
            "Total params: 12,384,577\n",
            "Trainable params: 12,384,577\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.15\n",
            "Forward/backward pass size (MB): 453.02\n",
            "Params size (MB): 47.24\n",
            "Estimated Total Size (MB): 501.41\n",
            "----------------------------------------------------------------\n",
            "You are running /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_16.zip dataset for 5 epochs\n",
            "Loading model : batch_best.ckp.pt\n",
            "Model is loaded and valid_loss_min is :0.3534224331378937\n",
            "\n",
            "###########EPOCH:1#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.4307 Mask loss=0.01 Depth loss=0.41:   0% 0/140 [00:37<?, ?it/s]batch_idx: 0\n",
            "loss: 0.43071529269218445\n",
            "##### Train Epoch: 1  [0/7000  (0%)]\tLoss:0.430715\n",
            "Overall Loss=0.3835 Mask loss=0.01 Depth loss=0.36:  36% 50/140 [06:42<02:29,  1.66s/it]batch_idx: 50\n",
            "loss: 0.38353806734085083\n",
            "##### Train Epoch: 1  [200/7000  (36%)]\tLoss:0.383538\n",
            "Overall Loss=0.3774 Mask loss=0.01 Depth loss=0.35:  71% 100/140 [07:24<00:25,  1.58it/s]batch_idx: 100\n",
            "loss: 0.37737584114074707\n",
            "##### Train Epoch: 1  [400/7000  (71%)]\tLoss:0.377376\n",
            "Overall Loss=0.3794 Mask loss=0.01 Depth loss=0.36: 100% 140/140 [07:49<00:00,  3.36s/it]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.39487823843955994\n",
            " 83% 50/60 [00:25<00:05,  1.96it/s]batch_idx: 50\n",
            "loss: 0.39278713800013065\n",
            "100% 60/60 [00:30<00:00,  1.95it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3935, Mask Loss: 0.01, Depth Loss: 0.37\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:2#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3806 Mask loss=0.01 Depth loss=0.36:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3805941343307495\n",
            "##### Train Epoch: 2  [0/7000  (0%)]\tLoss:0.380594\n",
            "Overall Loss=0.3824 Mask loss=0.01 Depth loss=0.36:  36% 50/140 [00:32<00:56,  1.59it/s]batch_idx: 50\n",
            "loss: 0.3824073374271393\n",
            "##### Train Epoch: 2  [200/7000  (36%)]\tLoss:0.382407\n",
            "Overall Loss=0.3791 Mask loss=0.01 Depth loss=0.36:  71% 100/140 [01:04<00:25,  1.59it/s]batch_idx: 100\n",
            "loss: 0.3790806829929352\n",
            "##### Train Epoch: 2  [400/7000  (71%)]\tLoss:0.379081\n",
            "Overall Loss=0.3744 Mask loss=0.01 Depth loss=0.35: 100% 140/140 [01:29<00:00,  1.57it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.39858507737517357\n",
            " 83% 50/60 [00:25<00:05,  1.95it/s]batch_idx: 50\n",
            "loss: 0.39956382662057877\n",
            "100% 60/60 [00:30<00:00,  1.95it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3994, Mask Loss: 0.02, Depth Loss: 0.37\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:3#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3785 Mask loss=0.01 Depth loss=0.36:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.37851980328559875\n",
            "##### Train Epoch: 3  [0/7000  (0%)]\tLoss:0.378520\n",
            "Overall Loss=0.3738 Mask loss=0.01 Depth loss=0.35:  36% 50/140 [00:32<00:56,  1.59it/s]batch_idx: 50\n",
            "loss: 0.3738471567630768\n",
            "##### Train Epoch: 3  [200/7000  (36%)]\tLoss:0.373847\n",
            "Overall Loss=0.3770 Mask loss=0.01 Depth loss=0.35:  71% 100/140 [01:04<00:25,  1.59it/s]batch_idx: 100\n",
            "loss: 0.37700486183166504\n",
            "##### Train Epoch: 3  [400/7000  (71%)]\tLoss:0.377005\n",
            "Overall Loss=0.3738 Mask loss=0.01 Depth loss=0.35: 100% 140/140 [01:29<00:00,  1.57it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.38898568972945213\n",
            " 83% 50/60 [00:25<00:05,  1.96it/s]batch_idx: 50\n",
            "loss: 0.38910478726029396\n",
            "100% 60/60 [00:30<00:00,  1.95it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3910, Mask Loss: 0.01, Depth Loss: 0.36\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:4#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3754 Mask loss=0.01 Depth loss=0.35:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.37538546323776245\n",
            "##### Train Epoch: 4  [0/7000  (0%)]\tLoss:0.375385\n",
            "Overall Loss=0.3767 Mask loss=0.01 Depth loss=0.35:  36% 50/140 [00:32<00:56,  1.59it/s]batch_idx: 50\n",
            "loss: 0.3766685724258423\n",
            "##### Train Epoch: 4  [200/7000  (36%)]\tLoss:0.376669\n",
            "Overall Loss=0.3753 Mask loss=0.01 Depth loss=0.35:  71% 100/140 [01:04<00:25,  1.59it/s]batch_idx: 100\n",
            "loss: 0.37528154253959656\n",
            "##### Train Epoch: 4  [400/7000  (71%)]\tLoss:0.375282\n",
            "Overall Loss=0.3770 Mask loss=0.01 Depth loss=0.35: 100% 140/140 [01:29<00:00,  1.57it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3954910673201084\n",
            " 83% 50/60 [00:25<00:05,  1.96it/s]batch_idx: 50\n",
            "loss: 0.3996722437441349\n",
            "100% 60/60 [00:30<00:00,  1.97it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3986, Mask Loss: 0.02, Depth Loss: 0.37\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:5#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3756 Mask loss=0.01 Depth loss=0.35:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.37558066844940186\n",
            "##### Train Epoch: 5  [0/7000  (0%)]\tLoss:0.375581\n",
            "Overall Loss=0.3748 Mask loss=0.01 Depth loss=0.35:  36% 50/140 [00:32<00:56,  1.59it/s]batch_idx: 50\n",
            "loss: 0.3747882843017578\n",
            "##### Train Epoch: 5  [200/7000  (36%)]\tLoss:0.374788\n",
            "Overall Loss=0.3770 Mask loss=0.01 Depth loss=0.35:  71% 100/140 [01:04<00:25,  1.59it/s]batch_idx: 100\n",
            "loss: 0.37698015570640564\n",
            "##### Train Epoch: 5  [400/7000  (71%)]\tLoss:0.376980\n",
            "Overall Loss=0.3766 Mask loss=0.01 Depth loss=0.36: 100% 140/140 [01:29<00:00,  1.57it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3971928171813488\n",
            " 83% 50/60 [00:25<00:05,  1.96it/s]batch_idx: 50\n",
            "loss: 0.39763835817575455\n",
            "100% 60/60 [00:30<00:00,  1.94it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3993, Mask Loss: 0.02, Depth Loss: 0.36\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "time: 17min 54s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "OqpYL2E8X77K"
      },
      "source": [
        "# Batch_17 dataset : On Gray Images\n",
        "        Dataset size : 30K\n",
        "            - Train (70%)  : 21K  \n",
        "            - Test  (30%)  : 9K\n",
        "        Batch Size   : 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "f07db494-baa3-40b1-c952-ca568f268af2",
        "id": "4Kls4z6SX77O",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "os.chdir(r'/content/drive/My Drive/EVA4/S15/scripts/pythonFiles')\n",
        "!python train_mask_depth.py -z '/content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_17.zip' -e 5  -bs 50"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are executing model on : cuda\n",
            "Dataset using : /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_17.zip\n",
            "Train Dataset : 21000\n",
            "Test Dataset : 9000\n",
            "\t In batch size of : 50\n",
            "cuda\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]          18,816\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "   ConvTranspose2d-5        [-1, 128, 111, 111]           8,192\n",
            "            Conv2d-6          [-1, 128, 28, 28]          73,728\n",
            "            Conv2d-7          [-1, 128, 28, 28]          16,384\n",
            "       BatchNorm2d-8          [-1, 128, 28, 28]             256\n",
            "              ReLU-9          [-1, 128, 28, 28]               0\n",
            "           Conv2d-10          [-1, 128, 14, 14]         147,456\n",
            "           Conv2d-11          [-1, 128, 14, 14]          16,384\n",
            "      BatchNorm2d-12          [-1, 128, 14, 14]             256\n",
            "             ReLU-13          [-1, 128, 14, 14]               0\n",
            "         Downsize-14          [-1, 128, 14, 14]               0\n",
            "  ConvTranspose2d-15          [-1, 256, 27, 27]          32,768\n",
            "           Conv2d-16            [-1, 256, 7, 7]         294,912\n",
            "           Conv2d-17            [-1, 256, 7, 7]          65,536\n",
            "      BatchNorm2d-18            [-1, 256, 7, 7]             512\n",
            "             ReLU-19            [-1, 256, 7, 7]               0\n",
            "           Conv2d-20            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-21            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-22            [-1, 256, 4, 4]             512\n",
            "             ReLU-23            [-1, 256, 4, 4]               0\n",
            "         Downsize-24            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-25            [-1, 512, 7, 7]         131,072\n",
            "           Conv2d-26            [-1, 512, 2, 2]       1,179,648\n",
            "           Conv2d-27            [-1, 512, 2, 2]         262,144\n",
            "      BatchNorm2d-28            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-29            [-1, 512, 2, 2]               0\n",
            "           Conv2d-30            [-1, 512, 1, 1]       2,359,296\n",
            "           Conv2d-31            [-1, 512, 1, 1]         262,144\n",
            "      BatchNorm2d-32            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-33            [-1, 512, 1, 1]               0\n",
            "         Downsize-34            [-1, 512, 1, 1]               0\n",
            "  ConvTranspose2d-35            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-36            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-37            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-38            [-1, 256, 4, 4]             512\n",
            "             ReLU-39            [-1, 256, 4, 4]               0\n",
            "           Conv2d-40            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-41            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-42            [-1, 256, 4, 4]             512\n",
            "             ReLU-43            [-1, 256, 4, 4]               0\n",
            "           Upsize-44            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-45          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-46          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-47          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-48          [-1, 128, 28, 28]             256\n",
            "             ReLU-49          [-1, 128, 28, 28]               0\n",
            "           Conv2d-50          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-51          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-52          [-1, 128, 28, 28]             256\n",
            "             ReLU-53          [-1, 128, 28, 28]               0\n",
            "           Upsize-54          [-1, 128, 28, 28]               0\n",
            "  ConvTranspose2d-55           [-1, 64, 56, 56]          73,728\n",
            "           Conv2d-56           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-57           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-58           [-1, 64, 56, 56]             128\n",
            "             ReLU-59           [-1, 64, 56, 56]               0\n",
            "           Conv2d-60           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-61           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-62           [-1, 64, 56, 56]             128\n",
            "             ReLU-63           [-1, 64, 56, 56]               0\n",
            "           Upsize-64           [-1, 64, 56, 56]               0\n",
            "  ConvTranspose2d-65         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-66         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-67         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-68         [-1, 64, 112, 112]             128\n",
            "             ReLU-69         [-1, 64, 112, 112]               0\n",
            "           Conv2d-70         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-71         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-72         [-1, 64, 112, 112]             128\n",
            "             ReLU-73         [-1, 64, 112, 112]               0\n",
            "           Upsize-74         [-1, 64, 112, 112]               0\n",
            "  ConvTranspose2d-75         [-1, 32, 224, 224]          18,432\n",
            "           Conv2d-76         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-77         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-78         [-1, 32, 224, 224]              64\n",
            "             ReLU-79         [-1, 32, 224, 224]               0\n",
            "           Conv2d-80         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-81         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-82         [-1, 32, 224, 224]              64\n",
            "             ReLU-83         [-1, 32, 224, 224]               0\n",
            "           Upsize-84         [-1, 32, 224, 224]               0\n",
            "           Conv2d-85          [-1, 1, 224, 224]              32\n",
            "  ConvTranspose2d-86            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-87            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-88            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-89            [-1, 256, 4, 4]             512\n",
            "             ReLU-90            [-1, 256, 4, 4]               0\n",
            "           Conv2d-91            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-92            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-93            [-1, 256, 4, 4]             512\n",
            "             ReLU-94            [-1, 256, 4, 4]               0\n",
            "           Upsize-95            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-96          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-97          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-98          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-99          [-1, 128, 28, 28]             256\n",
            "            ReLU-100          [-1, 128, 28, 28]               0\n",
            "          Conv2d-101          [-1, 128, 28, 28]         147,456\n",
            "          Conv2d-102          [-1, 128, 28, 28]          16,384\n",
            "     BatchNorm2d-103          [-1, 128, 28, 28]             256\n",
            "            ReLU-104          [-1, 128, 28, 28]               0\n",
            "          Upsize-105          [-1, 128, 28, 28]               0\n",
            " ConvTranspose2d-106           [-1, 64, 56, 56]          73,728\n",
            "          Conv2d-107           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-108           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-109           [-1, 64, 56, 56]             128\n",
            "            ReLU-110           [-1, 64, 56, 56]               0\n",
            "          Conv2d-111           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-112           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-113           [-1, 64, 56, 56]             128\n",
            "            ReLU-114           [-1, 64, 56, 56]               0\n",
            "          Upsize-115           [-1, 64, 56, 56]               0\n",
            " ConvTranspose2d-116         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-117         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-118         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-119         [-1, 64, 112, 112]             128\n",
            "            ReLU-120         [-1, 64, 112, 112]               0\n",
            "          Conv2d-121         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-122         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-123         [-1, 64, 112, 112]             128\n",
            "            ReLU-124         [-1, 64, 112, 112]               0\n",
            "          Upsize-125         [-1, 64, 112, 112]               0\n",
            " ConvTranspose2d-126         [-1, 32, 224, 224]          18,432\n",
            "          Conv2d-127         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-128         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-129         [-1, 32, 224, 224]              64\n",
            "            ReLU-130         [-1, 32, 224, 224]               0\n",
            "          Conv2d-131         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-132         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-133         [-1, 32, 224, 224]              64\n",
            "            ReLU-134         [-1, 32, 224, 224]               0\n",
            "          Upsize-135         [-1, 32, 224, 224]               0\n",
            "          Conv2d-136          [-1, 1, 224, 224]              33\n",
            "================================================================\n",
            "Total params: 12,384,577\n",
            "Trainable params: 12,384,577\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.15\n",
            "Forward/backward pass size (MB): 453.02\n",
            "Params size (MB): 47.24\n",
            "Estimated Total Size (MB): 501.41\n",
            "----------------------------------------------------------------\n",
            "You are running /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_17.zip dataset for 5 epochs\n",
            "Loading model : batch_best.ckp.pt\n",
            "Model is loaded and valid_loss_min is :0.3534224331378937\n",
            "\n",
            "###########EPOCH:1#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.4384 Mask loss=0.01 Depth loss=0.41:   0% 0/140 [00:44<?, ?it/s]batch_idx: 0\n",
            "loss: 0.43836086988449097\n",
            "##### Train Epoch: 1  [0/7000  (0%)]\tLoss:0.438361\n",
            "Overall Loss=0.3730 Mask loss=0.01 Depth loss=0.35:  36% 50/140 [07:48<02:15,  1.51s/it]batch_idx: 50\n",
            "loss: 0.37301400303840637\n",
            "##### Train Epoch: 1  [200/7000  (36%)]\tLoss:0.373014\n",
            "Overall Loss=0.3739 Mask loss=0.01 Depth loss=0.35:  71% 100/140 [08:30<00:28,  1.40it/s]batch_idx: 100\n",
            "loss: 0.37388619780540466\n",
            "##### Train Epoch: 1  [400/7000  (71%)]\tLoss:0.373886\n",
            "Overall Loss=0.3761 Mask loss=0.01 Depth loss=0.35: 100% 140/140 [08:55<00:00,  3.82s/it]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.38480119593441486\n",
            " 83% 50/60 [00:25<00:05,  1.94it/s]batch_idx: 50\n",
            "loss: 0.3920455202460289\n",
            "100% 60/60 [00:31<00:00,  1.93it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3893, Mask Loss: 0.01, Depth Loss: 0.36\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:2#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3659 Mask loss=0.01 Depth loss=0.34:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3659328818321228\n",
            "##### Train Epoch: 2  [0/7000  (0%)]\tLoss:0.365933\n",
            "Overall Loss=0.3763 Mask loss=0.01 Depth loss=0.35:  36% 50/140 [00:32<00:56,  1.59it/s]batch_idx: 50\n",
            "loss: 0.37628015875816345\n",
            "##### Train Epoch: 2  [200/7000  (36%)]\tLoss:0.376280\n",
            "Overall Loss=0.3685 Mask loss=0.01 Depth loss=0.35:  71% 100/140 [01:04<00:25,  1.59it/s]batch_idx: 100\n",
            "loss: 0.36846521496772766\n",
            "##### Train Epoch: 2  [400/7000  (71%)]\tLoss:0.368465\n",
            "Overall Loss=0.3724 Mask loss=0.01 Depth loss=0.35: 100% 140/140 [01:29<00:00,  1.57it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.40076280757784843\n",
            " 83% 50/60 [00:25<00:05,  1.93it/s]batch_idx: 50\n",
            "loss: 0.40144602209329605\n",
            "100% 60/60 [00:30<00:00,  1.94it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.4018, Mask Loss: 0.02, Depth Loss: 0.36\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:3#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3729 Mask loss=0.01 Depth loss=0.35:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3729131519794464\n",
            "##### Train Epoch: 3  [0/7000  (0%)]\tLoss:0.372913\n",
            "Overall Loss=0.3649 Mask loss=0.01 Depth loss=0.34:  36% 50/140 [00:32<00:56,  1.59it/s]batch_idx: 50\n",
            "loss: 0.3648746609687805\n",
            "##### Train Epoch: 3  [200/7000  (36%)]\tLoss:0.364875\n",
            "Overall Loss=0.3738 Mask loss=0.01 Depth loss=0.35:  71% 100/140 [01:04<00:25,  1.59it/s]batch_idx: 100\n",
            "loss: 0.3738161623477936\n",
            "##### Train Epoch: 3  [400/7000  (71%)]\tLoss:0.373816\n",
            "Overall Loss=0.3726 Mask loss=0.01 Depth loss=0.35: 100% 140/140 [01:29<00:00,  1.57it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.39129772409796715\n",
            " 83% 50/60 [00:25<00:05,  1.95it/s]batch_idx: 50\n",
            "loss: 0.39229157753288746\n",
            "100% 60/60 [00:31<00:00,  1.93it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3916, Mask Loss: 0.01, Depth Loss: 0.36\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:4#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3730 Mask loss=0.01 Depth loss=0.35:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.37301021814346313\n",
            "##### Train Epoch: 4  [0/7000  (0%)]\tLoss:0.373010\n",
            "Overall Loss=0.3686 Mask loss=0.01 Depth loss=0.35:  36% 50/140 [00:32<00:56,  1.59it/s]batch_idx: 50\n",
            "loss: 0.36856377124786377\n",
            "##### Train Epoch: 4  [200/7000  (36%)]\tLoss:0.368564\n",
            "Overall Loss=0.3731 Mask loss=0.01 Depth loss=0.35:  71% 100/140 [01:04<00:25,  1.59it/s]batch_idx: 100\n",
            "loss: 0.3731324076652527\n",
            "##### Train Epoch: 4  [400/7000  (71%)]\tLoss:0.373132\n",
            "Overall Loss=0.3718 Mask loss=0.01 Depth loss=0.35: 100% 140/140 [01:29<00:00,  1.57it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3966794051229954\n",
            " 83% 50/60 [00:25<00:05,  1.91it/s]batch_idx: 50\n",
            "loss: 0.3918186891824007\n",
            "100% 60/60 [00:31<00:00,  1.93it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3946, Mask Loss: 0.02, Depth Loss: 0.36\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:5#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3679 Mask loss=0.01 Depth loss=0.34:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3678928315639496\n",
            "##### Train Epoch: 5  [0/7000  (0%)]\tLoss:0.367893\n",
            "Overall Loss=0.3683 Mask loss=0.01 Depth loss=0.35:  36% 50/140 [00:32<00:56,  1.59it/s]batch_idx: 50\n",
            "loss: 0.3682560920715332\n",
            "##### Train Epoch: 5  [200/7000  (36%)]\tLoss:0.368256\n",
            "Overall Loss=0.3717 Mask loss=0.01 Depth loss=0.35:  71% 100/140 [01:04<00:25,  1.59it/s]batch_idx: 100\n",
            "loss: 0.3716539144515991\n",
            "##### Train Epoch: 5  [400/7000  (71%)]\tLoss:0.371654\n",
            "Overall Loss=0.3714 Mask loss=0.01 Depth loss=0.35: 100% 140/140 [01:29<00:00,  1.57it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.423100546002388\n",
            " 83% 50/60 [00:25<00:05,  1.93it/s]batch_idx: 50\n",
            "loss: 0.4257868193089962\n",
            "100% 60/60 [00:31<00:00,  1.93it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.4265, Mask Loss: 0.03, Depth Loss: 0.36\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "time: 19min\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "-bh2vVBiYCbH"
      },
      "source": [
        "# Batch_18 dataset : On Gray Images\n",
        "        Dataset size : 30K\n",
        "            - Train (70%)  : 21K  \n",
        "            - Test  (30%)  : 9K\n",
        "        Batch Size   : 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "126593a6-06c5-4ae2-eeae-c7543070bf0f",
        "id": "UxTjTLN_YCbJ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "os.chdir(r'/content/drive/My Drive/EVA4/S15/scripts/pythonFiles')\n",
        "!python train_mask_depth.py -z '/content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_18.zip' -e 5  -bs 50"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are executing model on : cuda\n",
            "Dataset using : /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_18.zip\n",
            "Train Dataset : 21000\n",
            "Test Dataset : 9000\n",
            "\t In batch size of : 50\n",
            "cuda\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]          18,816\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "   ConvTranspose2d-5        [-1, 128, 111, 111]           8,192\n",
            "            Conv2d-6          [-1, 128, 28, 28]          73,728\n",
            "            Conv2d-7          [-1, 128, 28, 28]          16,384\n",
            "       BatchNorm2d-8          [-1, 128, 28, 28]             256\n",
            "              ReLU-9          [-1, 128, 28, 28]               0\n",
            "           Conv2d-10          [-1, 128, 14, 14]         147,456\n",
            "           Conv2d-11          [-1, 128, 14, 14]          16,384\n",
            "      BatchNorm2d-12          [-1, 128, 14, 14]             256\n",
            "             ReLU-13          [-1, 128, 14, 14]               0\n",
            "         Downsize-14          [-1, 128, 14, 14]               0\n",
            "  ConvTranspose2d-15          [-1, 256, 27, 27]          32,768\n",
            "           Conv2d-16            [-1, 256, 7, 7]         294,912\n",
            "           Conv2d-17            [-1, 256, 7, 7]          65,536\n",
            "      BatchNorm2d-18            [-1, 256, 7, 7]             512\n",
            "             ReLU-19            [-1, 256, 7, 7]               0\n",
            "           Conv2d-20            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-21            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-22            [-1, 256, 4, 4]             512\n",
            "             ReLU-23            [-1, 256, 4, 4]               0\n",
            "         Downsize-24            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-25            [-1, 512, 7, 7]         131,072\n",
            "           Conv2d-26            [-1, 512, 2, 2]       1,179,648\n",
            "           Conv2d-27            [-1, 512, 2, 2]         262,144\n",
            "      BatchNorm2d-28            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-29            [-1, 512, 2, 2]               0\n",
            "           Conv2d-30            [-1, 512, 1, 1]       2,359,296\n",
            "           Conv2d-31            [-1, 512, 1, 1]         262,144\n",
            "      BatchNorm2d-32            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-33            [-1, 512, 1, 1]               0\n",
            "         Downsize-34            [-1, 512, 1, 1]               0\n",
            "  ConvTranspose2d-35            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-36            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-37            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-38            [-1, 256, 4, 4]             512\n",
            "             ReLU-39            [-1, 256, 4, 4]               0\n",
            "           Conv2d-40            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-41            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-42            [-1, 256, 4, 4]             512\n",
            "             ReLU-43            [-1, 256, 4, 4]               0\n",
            "           Upsize-44            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-45          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-46          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-47          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-48          [-1, 128, 28, 28]             256\n",
            "             ReLU-49          [-1, 128, 28, 28]               0\n",
            "           Conv2d-50          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-51          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-52          [-1, 128, 28, 28]             256\n",
            "             ReLU-53          [-1, 128, 28, 28]               0\n",
            "           Upsize-54          [-1, 128, 28, 28]               0\n",
            "  ConvTranspose2d-55           [-1, 64, 56, 56]          73,728\n",
            "           Conv2d-56           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-57           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-58           [-1, 64, 56, 56]             128\n",
            "             ReLU-59           [-1, 64, 56, 56]               0\n",
            "           Conv2d-60           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-61           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-62           [-1, 64, 56, 56]             128\n",
            "             ReLU-63           [-1, 64, 56, 56]               0\n",
            "           Upsize-64           [-1, 64, 56, 56]               0\n",
            "  ConvTranspose2d-65         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-66         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-67         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-68         [-1, 64, 112, 112]             128\n",
            "             ReLU-69         [-1, 64, 112, 112]               0\n",
            "           Conv2d-70         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-71         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-72         [-1, 64, 112, 112]             128\n",
            "             ReLU-73         [-1, 64, 112, 112]               0\n",
            "           Upsize-74         [-1, 64, 112, 112]               0\n",
            "  ConvTranspose2d-75         [-1, 32, 224, 224]          18,432\n",
            "           Conv2d-76         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-77         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-78         [-1, 32, 224, 224]              64\n",
            "             ReLU-79         [-1, 32, 224, 224]               0\n",
            "           Conv2d-80         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-81         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-82         [-1, 32, 224, 224]              64\n",
            "             ReLU-83         [-1, 32, 224, 224]               0\n",
            "           Upsize-84         [-1, 32, 224, 224]               0\n",
            "           Conv2d-85          [-1, 1, 224, 224]              32\n",
            "  ConvTranspose2d-86            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-87            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-88            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-89            [-1, 256, 4, 4]             512\n",
            "             ReLU-90            [-1, 256, 4, 4]               0\n",
            "           Conv2d-91            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-92            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-93            [-1, 256, 4, 4]             512\n",
            "             ReLU-94            [-1, 256, 4, 4]               0\n",
            "           Upsize-95            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-96          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-97          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-98          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-99          [-1, 128, 28, 28]             256\n",
            "            ReLU-100          [-1, 128, 28, 28]               0\n",
            "          Conv2d-101          [-1, 128, 28, 28]         147,456\n",
            "          Conv2d-102          [-1, 128, 28, 28]          16,384\n",
            "     BatchNorm2d-103          [-1, 128, 28, 28]             256\n",
            "            ReLU-104          [-1, 128, 28, 28]               0\n",
            "          Upsize-105          [-1, 128, 28, 28]               0\n",
            " ConvTranspose2d-106           [-1, 64, 56, 56]          73,728\n",
            "          Conv2d-107           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-108           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-109           [-1, 64, 56, 56]             128\n",
            "            ReLU-110           [-1, 64, 56, 56]               0\n",
            "          Conv2d-111           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-112           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-113           [-1, 64, 56, 56]             128\n",
            "            ReLU-114           [-1, 64, 56, 56]               0\n",
            "          Upsize-115           [-1, 64, 56, 56]               0\n",
            " ConvTranspose2d-116         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-117         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-118         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-119         [-1, 64, 112, 112]             128\n",
            "            ReLU-120         [-1, 64, 112, 112]               0\n",
            "          Conv2d-121         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-122         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-123         [-1, 64, 112, 112]             128\n",
            "            ReLU-124         [-1, 64, 112, 112]               0\n",
            "          Upsize-125         [-1, 64, 112, 112]               0\n",
            " ConvTranspose2d-126         [-1, 32, 224, 224]          18,432\n",
            "          Conv2d-127         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-128         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-129         [-1, 32, 224, 224]              64\n",
            "            ReLU-130         [-1, 32, 224, 224]               0\n",
            "          Conv2d-131         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-132         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-133         [-1, 32, 224, 224]              64\n",
            "            ReLU-134         [-1, 32, 224, 224]               0\n",
            "          Upsize-135         [-1, 32, 224, 224]               0\n",
            "          Conv2d-136          [-1, 1, 224, 224]              33\n",
            "================================================================\n",
            "Total params: 12,384,577\n",
            "Trainable params: 12,384,577\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.15\n",
            "Forward/backward pass size (MB): 453.02\n",
            "Params size (MB): 47.24\n",
            "Estimated Total Size (MB): 501.41\n",
            "----------------------------------------------------------------\n",
            "You are running /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_18.zip dataset for 5 epochs\n",
            "Loading model : batch_best.ckp.pt\n",
            "Model is loaded and valid_loss_min is :0.3534224331378937\n",
            "\n",
            "###########EPOCH:1#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.4612 Mask loss=0.01 Depth loss=0.44:   0% 0/140 [00:40<?, ?it/s]batch_idx: 0\n",
            "loss: 0.4612160325050354\n",
            "##### Train Epoch: 1  [0/7000  (0%)]\tLoss:0.461216\n",
            "Overall Loss=0.3755 Mask loss=0.01 Depth loss=0.35:  36% 50/140 [06:37<02:20,  1.56s/it]batch_idx: 50\n",
            "loss: 0.3755207657814026\n",
            "##### Train Epoch: 1  [200/7000  (36%)]\tLoss:0.375521\n",
            "Overall Loss=0.3750 Mask loss=0.01 Depth loss=0.35:  71% 100/140 [07:21<00:27,  1.43it/s]batch_idx: 100\n",
            "loss: 0.3750133812427521\n",
            "##### Train Epoch: 1  [400/7000  (71%)]\tLoss:0.375013\n",
            "Overall Loss=0.3751 Mask loss=0.01 Depth loss=0.35: 100% 140/140 [07:47<00:00,  3.34s/it]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.39300115033984184\n",
            " 83% 50/60 [00:25<00:05,  1.92it/s]batch_idx: 50\n",
            "loss: 0.3908765222877264\n",
            "100% 60/60 [00:31<00:00,  1.93it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3908, Mask Loss: 0.01, Depth Loss: 0.36\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:2#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3719 Mask loss=0.01 Depth loss=0.35:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3719373047351837\n",
            "##### Train Epoch: 2  [0/7000  (0%)]\tLoss:0.371937\n",
            "Overall Loss=0.3663 Mask loss=0.01 Depth loss=0.34:  36% 50/140 [00:32<00:56,  1.59it/s]batch_idx: 50\n",
            "loss: 0.36627712845802307\n",
            "##### Train Epoch: 2  [200/7000  (36%)]\tLoss:0.366277\n",
            "Overall Loss=0.3700 Mask loss=0.01 Depth loss=0.35:  71% 100/140 [01:04<00:25,  1.59it/s]batch_idx: 100\n",
            "loss: 0.3699715733528137\n",
            "##### Train Epoch: 2  [400/7000  (71%)]\tLoss:0.369972\n",
            "Overall Loss=0.3713 Mask loss=0.01 Depth loss=0.35: 100% 140/140 [01:29<00:00,  1.57it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.40993373468518257\n",
            " 83% 50/60 [00:25<00:05,  1.96it/s]batch_idx: 50\n",
            "loss: 0.41097645461559296\n",
            "100% 60/60 [00:30<00:00,  1.94it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.4092, Mask Loss: 0.02, Depth Loss: 0.36\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:3#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3754 Mask loss=0.01 Depth loss=0.35:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3754408657550812\n",
            "##### Train Epoch: 3  [0/7000  (0%)]\tLoss:0.375441\n",
            "Overall Loss=0.3731 Mask loss=0.01 Depth loss=0.35:  36% 50/140 [00:32<00:56,  1.58it/s]batch_idx: 50\n",
            "loss: 0.3731003701686859\n",
            "##### Train Epoch: 3  [200/7000  (36%)]\tLoss:0.373100\n",
            "Overall Loss=0.3729 Mask loss=0.01 Depth loss=0.35:  71% 100/140 [01:04<00:25,  1.59it/s]batch_idx: 100\n",
            "loss: 0.3729396164417267\n",
            "##### Train Epoch: 3  [400/7000  (71%)]\tLoss:0.372940\n",
            "Overall Loss=0.3709 Mask loss=0.01 Depth loss=0.35: 100% 140/140 [01:29<00:00,  1.57it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.39628878235816956\n",
            " 83% 50/60 [00:25<00:05,  1.96it/s]batch_idx: 50\n",
            "loss: 0.3934128228574991\n",
            "100% 60/60 [00:30<00:00,  1.94it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3957, Mask Loss: 0.01, Depth Loss: 0.37\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:4#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3739 Mask loss=0.01 Depth loss=0.35:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.37389203906059265\n",
            "##### Train Epoch: 4  [0/7000  (0%)]\tLoss:0.373892\n",
            "Overall Loss=0.3704 Mask loss=0.01 Depth loss=0.35:  36% 50/140 [00:32<00:56,  1.58it/s]batch_idx: 50\n",
            "loss: 0.3703775405883789\n",
            "##### Train Epoch: 4  [200/7000  (36%)]\tLoss:0.370378\n",
            "Overall Loss=0.3722 Mask loss=0.01 Depth loss=0.35:  71% 100/140 [01:04<00:25,  1.59it/s]batch_idx: 100\n",
            "loss: 0.37219852209091187\n",
            "##### Train Epoch: 4  [400/7000  (71%)]\tLoss:0.372199\n",
            "Overall Loss=0.3720 Mask loss=0.01 Depth loss=0.35: 100% 140/140 [01:29<00:00,  1.57it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3907534722238779\n",
            " 83% 50/60 [00:25<00:05,  1.94it/s]batch_idx: 50\n",
            "loss: 0.39412529207766056\n",
            "100% 60/60 [00:30<00:00,  1.94it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3935, Mask Loss: 0.01, Depth Loss: 0.36\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:5#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3720 Mask loss=0.01 Depth loss=0.35:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3719893991947174\n",
            "##### Train Epoch: 5  [0/7000  (0%)]\tLoss:0.371989\n",
            "Overall Loss=0.3718 Mask loss=0.01 Depth loss=0.35:  36% 50/140 [00:32<00:56,  1.59it/s]batch_idx: 50\n",
            "loss: 0.3717777132987976\n",
            "##### Train Epoch: 5  [200/7000  (36%)]\tLoss:0.371778\n",
            "Overall Loss=0.3679 Mask loss=0.01 Depth loss=0.35:  71% 100/140 [01:04<00:25,  1.59it/s]batch_idx: 100\n",
            "loss: 0.36791449785232544\n",
            "##### Train Epoch: 5  [400/7000  (71%)]\tLoss:0.367914\n",
            "Overall Loss=0.3721 Mask loss=0.01 Depth loss=0.35: 100% 140/140 [01:29<00:00,  1.57it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.39225753396749496\n",
            " 83% 50/60 [00:25<00:05,  1.91it/s]batch_idx: 50\n",
            "loss: 0.3924374599009752\n",
            "100% 60/60 [00:31<00:00,  1.93it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3939, Mask Loss: 0.02, Depth Loss: 0.36\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "time: 17min 52s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "noPB5EsxYHdv"
      },
      "source": [
        "# Batch_19 dataset : On Gray Images\n",
        "        Dataset size : 30K\n",
        "            - Train (70%)  : 21K  \n",
        "            - Test  (30%)  : 9K\n",
        "        Batch Size   : 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "ru4La-ztYHdw",
        "outputId": "7e46595c-26fc-4670-9a0b-5dac4c32b88a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "os.chdir(r'/content/drive/My Drive/EVA4/S15/scripts/pythonFiles')\n",
        "!python train_mask_depth.py -z '/content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_19.zip' -e 5  -bs 50"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are executing model on : cuda\n",
            "Dataset using : /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_19.zip\n",
            "Train Dataset : 21000\n",
            "Test Dataset : 9000\n",
            "\t In batch size of : 50\n",
            "cuda\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]          18,816\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "   ConvTranspose2d-5        [-1, 128, 111, 111]           8,192\n",
            "            Conv2d-6          [-1, 128, 28, 28]          73,728\n",
            "            Conv2d-7          [-1, 128, 28, 28]          16,384\n",
            "       BatchNorm2d-8          [-1, 128, 28, 28]             256\n",
            "              ReLU-9          [-1, 128, 28, 28]               0\n",
            "           Conv2d-10          [-1, 128, 14, 14]         147,456\n",
            "           Conv2d-11          [-1, 128, 14, 14]          16,384\n",
            "      BatchNorm2d-12          [-1, 128, 14, 14]             256\n",
            "             ReLU-13          [-1, 128, 14, 14]               0\n",
            "         Downsize-14          [-1, 128, 14, 14]               0\n",
            "  ConvTranspose2d-15          [-1, 256, 27, 27]          32,768\n",
            "           Conv2d-16            [-1, 256, 7, 7]         294,912\n",
            "           Conv2d-17            [-1, 256, 7, 7]          65,536\n",
            "      BatchNorm2d-18            [-1, 256, 7, 7]             512\n",
            "             ReLU-19            [-1, 256, 7, 7]               0\n",
            "           Conv2d-20            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-21            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-22            [-1, 256, 4, 4]             512\n",
            "             ReLU-23            [-1, 256, 4, 4]               0\n",
            "         Downsize-24            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-25            [-1, 512, 7, 7]         131,072\n",
            "           Conv2d-26            [-1, 512, 2, 2]       1,179,648\n",
            "           Conv2d-27            [-1, 512, 2, 2]         262,144\n",
            "      BatchNorm2d-28            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-29            [-1, 512, 2, 2]               0\n",
            "           Conv2d-30            [-1, 512, 1, 1]       2,359,296\n",
            "           Conv2d-31            [-1, 512, 1, 1]         262,144\n",
            "      BatchNorm2d-32            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-33            [-1, 512, 1, 1]               0\n",
            "         Downsize-34            [-1, 512, 1, 1]               0\n",
            "  ConvTranspose2d-35            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-36            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-37            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-38            [-1, 256, 4, 4]             512\n",
            "             ReLU-39            [-1, 256, 4, 4]               0\n",
            "           Conv2d-40            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-41            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-42            [-1, 256, 4, 4]             512\n",
            "             ReLU-43            [-1, 256, 4, 4]               0\n",
            "           Upsize-44            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-45          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-46          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-47          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-48          [-1, 128, 28, 28]             256\n",
            "             ReLU-49          [-1, 128, 28, 28]               0\n",
            "           Conv2d-50          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-51          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-52          [-1, 128, 28, 28]             256\n",
            "             ReLU-53          [-1, 128, 28, 28]               0\n",
            "           Upsize-54          [-1, 128, 28, 28]               0\n",
            "  ConvTranspose2d-55           [-1, 64, 56, 56]          73,728\n",
            "           Conv2d-56           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-57           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-58           [-1, 64, 56, 56]             128\n",
            "             ReLU-59           [-1, 64, 56, 56]               0\n",
            "           Conv2d-60           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-61           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-62           [-1, 64, 56, 56]             128\n",
            "             ReLU-63           [-1, 64, 56, 56]               0\n",
            "           Upsize-64           [-1, 64, 56, 56]               0\n",
            "  ConvTranspose2d-65         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-66         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-67         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-68         [-1, 64, 112, 112]             128\n",
            "             ReLU-69         [-1, 64, 112, 112]               0\n",
            "           Conv2d-70         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-71         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-72         [-1, 64, 112, 112]             128\n",
            "             ReLU-73         [-1, 64, 112, 112]               0\n",
            "           Upsize-74         [-1, 64, 112, 112]               0\n",
            "  ConvTranspose2d-75         [-1, 32, 224, 224]          18,432\n",
            "           Conv2d-76         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-77         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-78         [-1, 32, 224, 224]              64\n",
            "             ReLU-79         [-1, 32, 224, 224]               0\n",
            "           Conv2d-80         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-81         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-82         [-1, 32, 224, 224]              64\n",
            "             ReLU-83         [-1, 32, 224, 224]               0\n",
            "           Upsize-84         [-1, 32, 224, 224]               0\n",
            "           Conv2d-85          [-1, 1, 224, 224]              32\n",
            "  ConvTranspose2d-86            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-87            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-88            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-89            [-1, 256, 4, 4]             512\n",
            "             ReLU-90            [-1, 256, 4, 4]               0\n",
            "           Conv2d-91            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-92            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-93            [-1, 256, 4, 4]             512\n",
            "             ReLU-94            [-1, 256, 4, 4]               0\n",
            "           Upsize-95            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-96          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-97          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-98          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-99          [-1, 128, 28, 28]             256\n",
            "            ReLU-100          [-1, 128, 28, 28]               0\n",
            "          Conv2d-101          [-1, 128, 28, 28]         147,456\n",
            "          Conv2d-102          [-1, 128, 28, 28]          16,384\n",
            "     BatchNorm2d-103          [-1, 128, 28, 28]             256\n",
            "            ReLU-104          [-1, 128, 28, 28]               0\n",
            "          Upsize-105          [-1, 128, 28, 28]               0\n",
            " ConvTranspose2d-106           [-1, 64, 56, 56]          73,728\n",
            "          Conv2d-107           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-108           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-109           [-1, 64, 56, 56]             128\n",
            "            ReLU-110           [-1, 64, 56, 56]               0\n",
            "          Conv2d-111           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-112           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-113           [-1, 64, 56, 56]             128\n",
            "            ReLU-114           [-1, 64, 56, 56]               0\n",
            "          Upsize-115           [-1, 64, 56, 56]               0\n",
            " ConvTranspose2d-116         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-117         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-118         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-119         [-1, 64, 112, 112]             128\n",
            "            ReLU-120         [-1, 64, 112, 112]               0\n",
            "          Conv2d-121         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-122         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-123         [-1, 64, 112, 112]             128\n",
            "            ReLU-124         [-1, 64, 112, 112]               0\n",
            "          Upsize-125         [-1, 64, 112, 112]               0\n",
            " ConvTranspose2d-126         [-1, 32, 224, 224]          18,432\n",
            "          Conv2d-127         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-128         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-129         [-1, 32, 224, 224]              64\n",
            "            ReLU-130         [-1, 32, 224, 224]               0\n",
            "          Conv2d-131         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-132         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-133         [-1, 32, 224, 224]              64\n",
            "            ReLU-134         [-1, 32, 224, 224]               0\n",
            "          Upsize-135         [-1, 32, 224, 224]               0\n",
            "          Conv2d-136          [-1, 1, 224, 224]              33\n",
            "================================================================\n",
            "Total params: 12,384,577\n",
            "Trainable params: 12,384,577\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.15\n",
            "Forward/backward pass size (MB): 453.02\n",
            "Params size (MB): 47.24\n",
            "Estimated Total Size (MB): 501.41\n",
            "----------------------------------------------------------------\n",
            "You are running /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_19.zip dataset for 5 epochs\n",
            "Loading model : batch_best.ckp.pt\n",
            "Model is loaded and valid_loss_min is :0.3534224331378937\n",
            "\n",
            "###########EPOCH:1#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.4441 Mask loss=0.01 Depth loss=0.42:   0% 0/140 [00:31<?, ?it/s]batch_idx: 0\n",
            "loss: 0.44412416219711304\n",
            "##### Train Epoch: 1  [0/7000  (0%)]\tLoss:0.444124\n",
            "Overall Loss=0.3977 Mask loss=0.01 Depth loss=0.37:  36% 50/140 [06:11<02:22,  1.59s/it]batch_idx: 50\n",
            "loss: 0.397714227437973\n",
            "##### Train Epoch: 1  [200/7000  (36%)]\tLoss:0.397714\n",
            "Overall Loss=0.3986 Mask loss=0.01 Depth loss=0.38:  71% 100/140 [06:57<00:25,  1.57it/s]batch_idx: 100\n",
            "loss: 0.3985671401023865\n",
            "##### Train Epoch: 1  [400/7000  (71%)]\tLoss:0.398567\n",
            "Overall Loss=0.3941 Mask loss=0.01 Depth loss=0.37: 100% 140/140 [07:22<00:00,  3.16s/it]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.40527310594916344\n",
            " 83% 50/60 [00:25<00:05,  1.96it/s]batch_idx: 50\n",
            "loss: 0.407713133841753\n",
            "100% 60/60 [00:30<00:00,  1.94it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.4062, Mask Loss: 0.01, Depth Loss: 0.38\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:2#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3912 Mask loss=0.01 Depth loss=0.37:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.39120665192604065\n",
            "##### Train Epoch: 2  [0/7000  (0%)]\tLoss:0.391207\n",
            "Overall Loss=0.3978 Mask loss=0.01 Depth loss=0.37:  36% 50/140 [00:32<00:56,  1.59it/s]batch_idx: 50\n",
            "loss: 0.3978102207183838\n",
            "##### Train Epoch: 2  [200/7000  (36%)]\tLoss:0.397810\n",
            "Overall Loss=0.3902 Mask loss=0.01 Depth loss=0.37:  71% 100/140 [01:04<00:25,  1.59it/s]batch_idx: 100\n",
            "loss: 0.3902023136615753\n",
            "##### Train Epoch: 2  [400/7000  (71%)]\tLoss:0.390202\n",
            "Overall Loss=0.3931 Mask loss=0.01 Depth loss=0.37: 100% 140/140 [01:28<00:00,  1.57it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.40531389974057674\n",
            " 83% 50/60 [00:25<00:05,  1.94it/s]batch_idx: 50\n",
            "loss: 0.40641432069242\n",
            "100% 60/60 [00:30<00:00,  1.95it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.4076, Mask Loss: 0.01, Depth Loss: 0.38\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:3#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3986 Mask loss=0.01 Depth loss=0.38:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3986024856567383\n",
            "##### Train Epoch: 3  [0/7000  (0%)]\tLoss:0.398602\n",
            "Overall Loss=0.3960 Mask loss=0.01 Depth loss=0.37:  36% 50/140 [00:32<00:56,  1.59it/s]batch_idx: 50\n",
            "loss: 0.39601361751556396\n",
            "##### Train Epoch: 3  [200/7000  (36%)]\tLoss:0.396014\n",
            "Overall Loss=0.3964 Mask loss=0.01 Depth loss=0.37:  71% 100/140 [01:04<00:25,  1.59it/s]batch_idx: 100\n",
            "loss: 0.3964126706123352\n",
            "##### Train Epoch: 3  [400/7000  (71%)]\tLoss:0.396413\n",
            "Overall Loss=0.3919 Mask loss=0.01 Depth loss=0.37: 100% 140/140 [01:29<00:00,  1.57it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.41544008255004883\n",
            " 83% 50/60 [00:25<00:05,  1.96it/s]batch_idx: 50\n",
            "loss: 0.4109770804643631\n",
            "100% 60/60 [00:30<00:00,  1.95it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.4136, Mask Loss: 0.01, Depth Loss: 0.38\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:4#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3930 Mask loss=0.01 Depth loss=0.37:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3929762542247772\n",
            "##### Train Epoch: 4  [0/7000  (0%)]\tLoss:0.392976\n",
            "Overall Loss=0.3956 Mask loss=0.01 Depth loss=0.37:  36% 50/140 [00:32<00:56,  1.59it/s]batch_idx: 50\n",
            "loss: 0.39564159512519836\n",
            "##### Train Epoch: 4  [200/7000  (36%)]\tLoss:0.395642\n",
            "Overall Loss=0.3915 Mask loss=0.01 Depth loss=0.37:  71% 100/140 [01:04<00:25,  1.59it/s]batch_idx: 100\n",
            "loss: 0.39145350456237793\n",
            "##### Train Epoch: 4  [400/7000  (71%)]\tLoss:0.391454\n",
            "Overall Loss=0.3908 Mask loss=0.01 Depth loss=0.37: 100% 140/140 [01:29<00:00,  1.57it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.4133815001696348\n",
            " 83% 50/60 [00:25<00:05,  1.94it/s]batch_idx: 50\n",
            "loss: 0.4169137738645077\n",
            "100% 60/60 [00:30<00:00,  1.94it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.4140, Mask Loss: 0.01, Depth Loss: 0.39\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:5#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3944 Mask loss=0.01 Depth loss=0.37:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3944433033466339\n",
            "##### Train Epoch: 5  [0/7000  (0%)]\tLoss:0.394443\n",
            "Overall Loss=0.3995 Mask loss=0.01 Depth loss=0.37:  36% 50/140 [00:32<00:56,  1.59it/s]batch_idx: 50\n",
            "loss: 0.3994840979576111\n",
            "##### Train Epoch: 5  [200/7000  (36%)]\tLoss:0.399484\n",
            "Overall Loss=0.3891 Mask loss=0.01 Depth loss=0.37:  71% 100/140 [01:04<00:25,  1.59it/s]batch_idx: 100\n",
            "loss: 0.38914942741394043\n",
            "##### Train Epoch: 5  [400/7000  (71%)]\tLoss:0.389149\n",
            "Overall Loss=0.3959 Mask loss=0.01 Depth loss=0.37: 100% 140/140 [01:29<00:00,  1.57it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.4066769015043974\n",
            " 83% 50/60 [00:25<00:05,  1.94it/s]batch_idx: 50\n",
            "loss: 0.40500751323997974\n",
            "100% 60/60 [00:31<00:00,  1.93it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.4090, Mask Loss: 0.01, Depth Loss: 0.38\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "time: 17min 30s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "wn7qtH8lYKCr"
      },
      "source": [
        "# Batch_20 dataset : On Gray Images\n",
        "        Dataset size : 30K\n",
        "            - Train (70%)  : 21K  \n",
        "            - Test  (30%)  : 9K\n",
        "        Batch Size   : 50"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Xmb75D4SYKCs",
        "outputId": "99302e5d-f0dc-45a5-8b6b-9dbc6f8eaefa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "os.chdir(r'/content/drive/My Drive/EVA4/S15/scripts/pythonFiles')\n",
        "!python train_mask_depth.py -z '/content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_20.zip' -e 5  -bs 50"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are executing model on : cuda\n",
            "Dataset using : /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_20.zip\n",
            "Train Dataset : 21000\n",
            "Test Dataset : 9000\n",
            "\t In batch size of : 50\n",
            "cuda\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
            "  \"See the documentation of nn.Upsample for details.\".format(mode))\n",
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 112, 112]          18,816\n",
            "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
            "              ReLU-3         [-1, 64, 112, 112]               0\n",
            "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
            "   ConvTranspose2d-5        [-1, 128, 111, 111]           8,192\n",
            "            Conv2d-6          [-1, 128, 28, 28]          73,728\n",
            "            Conv2d-7          [-1, 128, 28, 28]          16,384\n",
            "       BatchNorm2d-8          [-1, 128, 28, 28]             256\n",
            "              ReLU-9          [-1, 128, 28, 28]               0\n",
            "           Conv2d-10          [-1, 128, 14, 14]         147,456\n",
            "           Conv2d-11          [-1, 128, 14, 14]          16,384\n",
            "      BatchNorm2d-12          [-1, 128, 14, 14]             256\n",
            "             ReLU-13          [-1, 128, 14, 14]               0\n",
            "         Downsize-14          [-1, 128, 14, 14]               0\n",
            "  ConvTranspose2d-15          [-1, 256, 27, 27]          32,768\n",
            "           Conv2d-16            [-1, 256, 7, 7]         294,912\n",
            "           Conv2d-17            [-1, 256, 7, 7]          65,536\n",
            "      BatchNorm2d-18            [-1, 256, 7, 7]             512\n",
            "             ReLU-19            [-1, 256, 7, 7]               0\n",
            "           Conv2d-20            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-21            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-22            [-1, 256, 4, 4]             512\n",
            "             ReLU-23            [-1, 256, 4, 4]               0\n",
            "         Downsize-24            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-25            [-1, 512, 7, 7]         131,072\n",
            "           Conv2d-26            [-1, 512, 2, 2]       1,179,648\n",
            "           Conv2d-27            [-1, 512, 2, 2]         262,144\n",
            "      BatchNorm2d-28            [-1, 512, 2, 2]           1,024\n",
            "             ReLU-29            [-1, 512, 2, 2]               0\n",
            "           Conv2d-30            [-1, 512, 1, 1]       2,359,296\n",
            "           Conv2d-31            [-1, 512, 1, 1]         262,144\n",
            "      BatchNorm2d-32            [-1, 512, 1, 1]           1,024\n",
            "             ReLU-33            [-1, 512, 1, 1]               0\n",
            "         Downsize-34            [-1, 512, 1, 1]               0\n",
            "  ConvTranspose2d-35            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-36            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-37            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-38            [-1, 256, 4, 4]             512\n",
            "             ReLU-39            [-1, 256, 4, 4]               0\n",
            "           Conv2d-40            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-41            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-42            [-1, 256, 4, 4]             512\n",
            "             ReLU-43            [-1, 256, 4, 4]               0\n",
            "           Upsize-44            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-45          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-46          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-47          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-48          [-1, 128, 28, 28]             256\n",
            "             ReLU-49          [-1, 128, 28, 28]               0\n",
            "           Conv2d-50          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-51          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-52          [-1, 128, 28, 28]             256\n",
            "             ReLU-53          [-1, 128, 28, 28]               0\n",
            "           Upsize-54          [-1, 128, 28, 28]               0\n",
            "  ConvTranspose2d-55           [-1, 64, 56, 56]          73,728\n",
            "           Conv2d-56           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-57           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-58           [-1, 64, 56, 56]             128\n",
            "             ReLU-59           [-1, 64, 56, 56]               0\n",
            "           Conv2d-60           [-1, 64, 56, 56]          36,864\n",
            "           Conv2d-61           [-1, 64, 56, 56]           4,096\n",
            "      BatchNorm2d-62           [-1, 64, 56, 56]             128\n",
            "             ReLU-63           [-1, 64, 56, 56]               0\n",
            "           Upsize-64           [-1, 64, 56, 56]               0\n",
            "  ConvTranspose2d-65         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-66         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-67         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-68         [-1, 64, 112, 112]             128\n",
            "             ReLU-69         [-1, 64, 112, 112]               0\n",
            "           Conv2d-70         [-1, 64, 112, 112]          36,864\n",
            "           Conv2d-71         [-1, 64, 112, 112]           4,096\n",
            "      BatchNorm2d-72         [-1, 64, 112, 112]             128\n",
            "             ReLU-73         [-1, 64, 112, 112]               0\n",
            "           Upsize-74         [-1, 64, 112, 112]               0\n",
            "  ConvTranspose2d-75         [-1, 32, 224, 224]          18,432\n",
            "           Conv2d-76         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-77         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-78         [-1, 32, 224, 224]              64\n",
            "             ReLU-79         [-1, 32, 224, 224]               0\n",
            "           Conv2d-80         [-1, 32, 224, 224]           9,216\n",
            "           Conv2d-81         [-1, 32, 224, 224]           1,024\n",
            "      BatchNorm2d-82         [-1, 32, 224, 224]              64\n",
            "             ReLU-83         [-1, 32, 224, 224]               0\n",
            "           Upsize-84         [-1, 32, 224, 224]               0\n",
            "           Conv2d-85          [-1, 1, 224, 224]              32\n",
            "  ConvTranspose2d-86            [-1, 256, 4, 4]       1,179,648\n",
            "           Conv2d-87            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-88            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-89            [-1, 256, 4, 4]             512\n",
            "             ReLU-90            [-1, 256, 4, 4]               0\n",
            "           Conv2d-91            [-1, 256, 4, 4]         589,824\n",
            "           Conv2d-92            [-1, 256, 4, 4]          65,536\n",
            "      BatchNorm2d-93            [-1, 256, 4, 4]             512\n",
            "             ReLU-94            [-1, 256, 4, 4]               0\n",
            "           Upsize-95            [-1, 256, 4, 4]               0\n",
            "  ConvTranspose2d-96          [-1, 128, 28, 28]         294,912\n",
            "           Conv2d-97          [-1, 128, 28, 28]         147,456\n",
            "           Conv2d-98          [-1, 128, 28, 28]          16,384\n",
            "      BatchNorm2d-99          [-1, 128, 28, 28]             256\n",
            "            ReLU-100          [-1, 128, 28, 28]               0\n",
            "          Conv2d-101          [-1, 128, 28, 28]         147,456\n",
            "          Conv2d-102          [-1, 128, 28, 28]          16,384\n",
            "     BatchNorm2d-103          [-1, 128, 28, 28]             256\n",
            "            ReLU-104          [-1, 128, 28, 28]               0\n",
            "          Upsize-105          [-1, 128, 28, 28]               0\n",
            " ConvTranspose2d-106           [-1, 64, 56, 56]          73,728\n",
            "          Conv2d-107           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-108           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-109           [-1, 64, 56, 56]             128\n",
            "            ReLU-110           [-1, 64, 56, 56]               0\n",
            "          Conv2d-111           [-1, 64, 56, 56]          36,864\n",
            "          Conv2d-112           [-1, 64, 56, 56]           4,096\n",
            "     BatchNorm2d-113           [-1, 64, 56, 56]             128\n",
            "            ReLU-114           [-1, 64, 56, 56]               0\n",
            "          Upsize-115           [-1, 64, 56, 56]               0\n",
            " ConvTranspose2d-116         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-117         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-118         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-119         [-1, 64, 112, 112]             128\n",
            "            ReLU-120         [-1, 64, 112, 112]               0\n",
            "          Conv2d-121         [-1, 64, 112, 112]          36,864\n",
            "          Conv2d-122         [-1, 64, 112, 112]           4,096\n",
            "     BatchNorm2d-123         [-1, 64, 112, 112]             128\n",
            "            ReLU-124         [-1, 64, 112, 112]               0\n",
            "          Upsize-125         [-1, 64, 112, 112]               0\n",
            " ConvTranspose2d-126         [-1, 32, 224, 224]          18,432\n",
            "          Conv2d-127         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-128         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-129         [-1, 32, 224, 224]              64\n",
            "            ReLU-130         [-1, 32, 224, 224]               0\n",
            "          Conv2d-131         [-1, 32, 224, 224]           9,216\n",
            "          Conv2d-132         [-1, 32, 224, 224]           1,024\n",
            "     BatchNorm2d-133         [-1, 32, 224, 224]              64\n",
            "            ReLU-134         [-1, 32, 224, 224]               0\n",
            "          Upsize-135         [-1, 32, 224, 224]               0\n",
            "          Conv2d-136          [-1, 1, 224, 224]              33\n",
            "================================================================\n",
            "Total params: 12,384,577\n",
            "Trainable params: 12,384,577\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 1.15\n",
            "Forward/backward pass size (MB): 453.02\n",
            "Params size (MB): 47.24\n",
            "Estimated Total Size (MB): 501.41\n",
            "----------------------------------------------------------------\n",
            "You are running /content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_20.zip dataset for 5 epochs\n",
            "Loading model : batch_best.ckp.pt\n",
            "Model is loaded and valid_loss_min is :0.3534224331378937\n",
            "\n",
            "###########EPOCH:1#########\n",
            "\n",
            "\r  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.4099 Mask loss=0.01 Depth loss=0.38:   0% 0/140 [00:33<?, ?it/s]batch_idx: 0\n",
            "loss: 0.4098898470401764\n",
            "##### Train Epoch: 1  [0/7000  (0%)]\tLoss:0.409890\n",
            "Overall Loss=0.3724 Mask loss=0.01 Depth loss=0.35:  36% 50/140 [06:42<03:10,  2.11s/it]batch_idx: 50\n",
            "loss: 0.37239739298820496\n",
            "##### Train Epoch: 1  [200/7000  (36%)]\tLoss:0.372397\n",
            "Overall Loss=0.3710 Mask loss=0.01 Depth loss=0.35:  71% 100/140 [07:29<00:25,  1.56it/s]batch_idx: 100\n",
            "loss: 0.3709692656993866\n",
            "##### Train Epoch: 1  [400/7000  (71%)]\tLoss:0.370969\n",
            "Overall Loss=0.3746 Mask loss=0.01 Depth loss=0.35: 100% 140/140 [07:54<00:00,  3.39s/it]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.38588794507086277\n",
            " 83% 50/60 [00:25<00:05,  1.95it/s]batch_idx: 50\n",
            "loss: 0.38568845577538013\n",
            "100% 60/60 [00:30<00:00,  1.94it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3877, Mask Loss: 0.01, Depth Loss: 0.36\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:2#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3742 Mask loss=0.01 Depth loss=0.35:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.37421154975891113\n",
            "##### Train Epoch: 2  [0/7000  (0%)]\tLoss:0.374212\n",
            "Overall Loss=0.3681 Mask loss=0.01 Depth loss=0.34:  36% 50/140 [00:32<00:56,  1.59it/s]batch_idx: 50\n",
            "loss: 0.36809393763542175\n",
            "##### Train Epoch: 2  [200/7000  (36%)]\tLoss:0.368094\n",
            "Overall Loss=0.3686 Mask loss=0.01 Depth loss=0.35:  71% 100/140 [01:04<00:25,  1.59it/s]batch_idx: 100\n",
            "loss: 0.3686003088951111\n",
            "##### Train Epoch: 2  [400/7000  (71%)]\tLoss:0.368600\n",
            "Overall Loss=0.3709 Mask loss=0.01 Depth loss=0.35: 100% 140/140 [01:29<00:00,  1.57it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3853230457752943\n",
            " 83% 50/60 [00:26<00:05,  1.90it/s]batch_idx: 50\n",
            "loss: 0.38279327377676964\n",
            "100% 60/60 [00:31<00:00,  1.92it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3878, Mask Loss: 0.01, Depth Loss: 0.36\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:3#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3717 Mask loss=0.01 Depth loss=0.35:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3716721832752228\n",
            "##### Train Epoch: 3  [0/7000  (0%)]\tLoss:0.371672\n",
            "Overall Loss=0.3717 Mask loss=0.01 Depth loss=0.35:  36% 50/140 [00:32<00:56,  1.59it/s]batch_idx: 50\n",
            "loss: 0.37166303396224976\n",
            "##### Train Epoch: 3  [200/7000  (36%)]\tLoss:0.371663\n",
            "Overall Loss=0.3683 Mask loss=0.01 Depth loss=0.34:  71% 100/140 [01:04<00:25,  1.59it/s]batch_idx: 100\n",
            "loss: 0.3682682514190674\n",
            "##### Train Epoch: 3  [400/7000  (71%)]\tLoss:0.368268\n",
            "Overall Loss=0.3663 Mask loss=0.01 Depth loss=0.34: 100% 140/140 [01:29<00:00,  1.57it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.38483210653066635\n",
            " 83% 50/60 [00:25<00:05,  1.93it/s]batch_idx: 50\n",
            "loss: 0.3867369331419468\n",
            "100% 60/60 [00:30<00:00,  1.94it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3864, Mask Loss: 0.01, Depth Loss: 0.36\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:4#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3740 Mask loss=0.01 Depth loss=0.35:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.37398913502693176\n",
            "##### Train Epoch: 4  [0/7000  (0%)]\tLoss:0.373989\n",
            "Overall Loss=0.3702 Mask loss=0.01 Depth loss=0.35:  36% 50/140 [00:32<00:56,  1.59it/s]batch_idx: 50\n",
            "loss: 0.3701981008052826\n",
            "##### Train Epoch: 4  [200/7000  (36%)]\tLoss:0.370198\n",
            "Overall Loss=0.3729 Mask loss=0.01 Depth loss=0.35:  71% 100/140 [01:04<00:25,  1.59it/s]batch_idx: 100\n",
            "loss: 0.3728572726249695\n",
            "##### Train Epoch: 4  [400/7000  (71%)]\tLoss:0.372857\n",
            "Overall Loss=0.3663 Mask loss=0.01 Depth loss=0.34: 100% 140/140 [01:29<00:00,  1.57it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.3938264846801758\n",
            " 83% 50/60 [00:25<00:05,  1.93it/s]batch_idx: 50\n",
            "loss: 0.3875546231865883\n",
            "100% 60/60 [00:31<00:00,  1.93it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3893, Mask Loss: 0.01, Depth Loss: 0.36\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "###########EPOCH:5#########\n",
            "\n",
            "  0% 0/140 [00:00<?, ?it/s]\n",
            "\n",
            "######################\n",
            "You are in Train process\n",
            "################################\n",
            "Overall Loss=0.3664 Mask loss=0.01 Depth loss=0.34:   0% 0/140 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.36640796065330505\n",
            "##### Train Epoch: 5  [0/7000  (0%)]\tLoss:0.366408\n",
            "Overall Loss=0.3710 Mask loss=0.01 Depth loss=0.35:  36% 50/140 [00:32<00:56,  1.59it/s]batch_idx: 50\n",
            "loss: 0.37099161744117737\n",
            "##### Train Epoch: 5  [200/7000  (36%)]\tLoss:0.370992\n",
            "Overall Loss=0.3645 Mask loss=0.01 Depth loss=0.34:  71% 100/140 [01:04<00:25,  1.59it/s]batch_idx: 100\n",
            "loss: 0.3645164668560028\n",
            "##### Train Epoch: 5  [400/7000  (71%)]\tLoss:0.364516\n",
            "Overall Loss=0.3751 Mask loss=0.01 Depth loss=0.35: 100% 140/140 [01:29<00:00,  1.57it/s]\n",
            "After compleation of training at epoch :139\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "\n",
            "\n",
            "######################\n",
            "You are in Test process\n",
            "################################\n",
            "  0% 0/60 [00:00<?, ?it/s]batch_idx: 0\n",
            "loss: 0.386623028665781\n",
            " 83% 50/60 [00:25<00:05,  1.96it/s]batch_idx: 50\n",
            "loss: 0.3842735029757023\n",
            "100% 60/60 [00:30<00:00,  1.95it/s]\n",
            "\n",
            "####################\n",
            "Test set: Avg loss: 0.3860, Mask Loss: 0.02, Depth Loss: 0.35\n",
            "############\n",
            "After compleation of Test at epoch :59\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "time: 18min 7s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7x-GdQbf2rGB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}