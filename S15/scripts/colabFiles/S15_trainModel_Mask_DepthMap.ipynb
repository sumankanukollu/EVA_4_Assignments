{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"S15_trainModel_Mask_DepthMap.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true,"mount_file_id":"1RyC3o6eZadFX0yaGKbwuk3tMH4x54r74","authorship_tag":"ABX9TyOeycB68/jvsTQ22j0LXvt+"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"PtWeRI9vSrmq","colab_type":"code","outputId":"1333d856-5a1b-4204-8a94-ca25cbefe8dd","executionInfo":{"status":"ok","timestamp":1590244646758,"user_tz":-330,"elapsed":1533,"user":{"displayName":"Suman Vamsi","photoUrl":"","userId":"17013667235091068730"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import torch\n","from IPython.display import Image, clear_output \n","\n","print('PyTorch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["PyTorch 1.5.0+cu101 _CudaDeviceProperties(name='Tesla P100-PCIE-16GB', major=6, minor=0, total_memory=16280MB, multi_processor_count=56)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2oecG2ydhWcR","colab_type":"code","outputId":"abd39d04-216f-461b-cbbf-8de01c9a7e7d","executionInfo":{"status":"ok","timestamp":1590244651942,"user_tz":-330,"elapsed":6707,"user":{"displayName":"Suman Vamsi","photoUrl":"","userId":"17013667235091068730"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["!pip install ipython-autotime\n","%load_ext autotime"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: ipython-autotime in /usr/local/lib/python3.6/dist-packages (0.1)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"tCvT-6J4zpgS","colab_type":"text"},"source":["# Environment setup"]},{"cell_type":"code","metadata":{"id":"TUvypmIa0Rvc","colab_type":"code","outputId":"9ea3f9c9-d76a-482e-adc6-dd5042e293da","executionInfo":{"status":"ok","timestamp":1590244651945,"user_tz":-330,"elapsed":6705,"user":{"displayName":"Suman Vamsi","photoUrl":"","userId":"17013667235091068730"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torchvision\n","import torchvision.transforms as transforms\n","from IPython.core.debugger import set_trace\n","\n","from torchvision.utils import make_grid\n","from torchsummary import summary\n","from PIL import Image\n","# New \n","from torchvision import models\n","from zipfile import ZipFile"],"execution_count":0,"outputs":[{"output_type":"stream","text":["time: 189 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"5hmtUIY7zYpj","colab_type":"code","outputId":"efd68352-dc0d-4228-f3cb-2e0c5372dd41","executionInfo":{"status":"ok","timestamp":1590244651947,"user_tz":-330,"elapsed":6700,"user":{"displayName":"Suman Vamsi","photoUrl":"","userId":"17013667235091068730"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from pathlib import Path\n","import os ,sys, gc ,tarfile ,zipfile,pickle\n","\n","homepath = Path('/content/drive/My Drive/EVA4/S15')\n","libPath  = Path('/content/drive/My Drive/EVA4/S15/lib') \n","#scripts  = Path('/content/drive/My Drive/EVA4/S15/scripts')\n","#dataset  = Path('/content/drive/My Drive/EVA4/S15/dataset/pklFiles/')\n","dataPath  = Path('/content/drive/My Drive/EVA4/S15/dataset/zipFiles')\n","\n","sys.path.append(libPath)\n","os.chdir(homepath)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["time: 4.65 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"NU_e0fBK0hdh","colab_type":"code","outputId":"c39f015e-b19a-4528-b002-809105eee7cf","executionInfo":{"status":"ok","timestamp":1590244651949,"user_tz":-330,"elapsed":6697,"user":{"displayName":"Suman Vamsi","photoUrl":"","userId":"17013667235091068730"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","print(device)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["cuda\n","time: 1.84 ms\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2VNj12OTVyJk","colab_type":"text"},"source":["# Load dataset"]},{"cell_type":"markdown","metadata":{"id":"7_grXPsza9cW","colab_type":"text"},"source":["## Transformations"]},{"cell_type":"code","metadata":{"id":"agsCBidUy8Vd","colab_type":"code","outputId":"8b4cfa47-5648-45b3-b8e6-f437d2d79a6d","executionInfo":{"status":"ok","timestamp":1590244651950,"user_tz":-330,"elapsed":6693,"user":{"displayName":"Suman Vamsi","photoUrl":"","userId":"17013667235091068730"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import torchvision\n","import torchvision.transforms as transforms\n","\n","def transformations():\n","    transform_train = transforms.Compose([\n","        # transforms.RandomCrop(32, padding=4),\n","        # transforms.RandomHorizontalFlip(),\n","        transforms.ToTensor(),\n","        # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","    ])\n","\n","    transform_test = transforms.Compose([\n","        transforms.ToTensor(),\n","        # transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n","    ])\n","\n","    return (transform_train, transform_test)\n","\n","transform_train, transform_test = transformations()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["time: 4.72 ms\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4VErTFvtzSr1","colab_type":"text"},"source":["# Custom dataset"]},{"cell_type":"code","metadata":{"id":"22evPVDj1rIZ","colab_type":"code","outputId":"8eb7f69c-cde5-4423-a6d3-0bf8a0895309","executionInfo":{"status":"ok","timestamp":1590244651951,"user_tz":-330,"elapsed":6688,"user":{"displayName":"Suman Vamsi","photoUrl":"","userId":"17013667235091068730"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from torch.utils.data import Dataset\n","from torchvision.transforms import transforms\n","from PIL import Image\n","from zipfile import ZipFile\n","\n","class customDataset(Dataset):\n","    def __init__(self, zipFName,transfrm):\n","        self.z_obj      = ZipFile(zipFName)\n","        self.transfrm   = transfrm\n","        # BG Images : dataPath.parent.joinpath('bg')\n","        self.bg         = os.listdir('/content/drive/My Drive/EVA4/S15/dataset/bg')\n","\n","        # bgfg\n","        tmp             = list(filter(lambda x : x.startswith('bg_fg_1/'),self.z_obj.namelist()))\n","        tmp.remove('bg_fg_1/') if 'bg_fg_1/' in tmp else tmp\n","        self.bgfgF      = tmp\n","        del tmp\n","        # masks\n","        tmp             = list(filter(lambda x : x.startswith('bg_fg_mask_1/'),self.z_obj.namelist()))\n","        tmp.remove('bg_fg_mask_1/') if 'bg_fg_mask_1/' in tmp else tmp\n","        self.maskF      = tmp\n","        del tmp\n","        #depth\n","        tmp             =   list(filter(lambda x : x.startswith('depthMap/'),self.z_obj.namelist()))\n","        tmp.remove('depthMap/') if 'depthMap/' in tmp else tmp\n","        self.depthF     = tmp\n","        del tmp\n","\n","    def __len__(self):\n","        return len(self.bgfgF)\n","\n","    def __getitem__(self, idx):\n","        bgname = os.path.basename(self.bgfgF[idx]).split('_bg_')[0]+'_bg.jpg'\n","        bgF    = os.path.join('/content/drive/My Drive/EVA4/S15/dataset/bg',bgname)\n","\n","        bgImg   = self.transfrm(Image.open(bgF))\n","        bgfgImg = self.transfrm(Image.open((self.z_obj.open(self.bgfgF[idx]))))\n","        maskImg = self.transfrm(Image.open((self.z_obj.open(self.maskF[idx]))))\n","        depthImg = self.transfrm(Image.open((self.z_obj.open(self.depthF[idx]))))\n","\n","        return {'bgK' : bgImg,'bgfgK': bgfgImg, 'maskK' : maskImg, 'depthK': depthImg}\n","\n","    def __del__(self):\n","        self.z_obj.close()\n","        del self.bgfgF"],"execution_count":0,"outputs":[{"output_type":"stream","text":["time: 38.7 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"mJI5xGF0VrXg","colab_type":"code","outputId":"3f57129a-1be8-46d7-adbd-63072490d48d","executionInfo":{"status":"ok","timestamp":1590244653122,"user_tz":-330,"elapsed":7853,"user":{"displayName":"Suman Vamsi","photoUrl":"","userId":"17013667235091068730"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from torch.utils.data import DataLoader,random_split\n","\n","trainset = customDataset(zipFName = r'/content/drive/My Drive/EVA4/S15/dataset/zipFiles/batch_1.zip' ,transfrm = transform_train)\n","train_set, test_set  = random_split(trainset,[int(0.7*len(trainset)),int(0.3*len(trainset))])\n","\n","#trainloader = DataLoader(trainset, batch_size = 50, shuffle =True, pin_memory=True,num_workers =1)\n","trainloader = DataLoader(train_set, batch_size = 50, shuffle =True, pin_memory=True,num_workers =0)\n","testloader  = DataLoader(test_set, batch_size = 50, shuffle =True, pin_memory=True,num_workers =0)\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["time: 273 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FASFQaGMz-ht","colab_type":"code","outputId":"e7df99a0-7483-4101-c847-52c76d9efbde","executionInfo":{"status":"ok","timestamp":1590244653126,"user_tz":-330,"elapsed":7852,"user":{"displayName":"Suman Vamsi","photoUrl":"","userId":"17013667235091068730"}},"colab":{"base_uri":"https://localhost:8080/","height":50}},"source":["print(len(train_set),len(test_set))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["7000 3000\n","time: 2.51 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AJfxSgeNpABw","colab_type":"code","outputId":"ceafd4a5-d35e-4e9f-c878-231b5e90fe5c","executionInfo":{"status":"ok","timestamp":1590244653128,"user_tz":-330,"elapsed":7848,"user":{"displayName":"Suman Vamsi","photoUrl":"","userId":"17013667235091068730"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["imgs = train_set.__getitem__(3)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["time: 17.1 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-34_tJNupL5d","colab_type":"code","outputId":"466bed28-9cdd-46c8-b67d-7ab749511eef","executionInfo":{"status":"ok","timestamp":1590244653129,"user_tz":-330,"elapsed":7845,"user":{"displayName":"Suman Vamsi","photoUrl":"","userId":"17013667235091068730"}},"colab":{"base_uri":"https://localhost:8080/","height":101}},"source":["print(type(imgs['bgK']))\n","print(type(imgs['bgfgK']))\n","print(type(imgs['maskK']))\n","print(type(imgs['depthK']))\n","\n","del imgs"],"execution_count":0,"outputs":[{"output_type":"stream","text":["<class 'torch.Tensor'>\n","<class 'torch.Tensor'>\n","<class 'torch.Tensor'>\n","<class 'torch.Tensor'>\n","time: 2.29 ms\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"O1MnaRESWtqe","colab_type":"text"},"source":["## Display few images from the dataset"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"KiXPSMOlObP5","outputId":"7002dd43-afbf-4f50-c341-b96229becb4f","executionInfo":{"status":"ok","timestamp":1590244653131,"user_tz":-330,"elapsed":7843,"user":{"displayName":"Suman Vamsi","photoUrl":"","userId":"17013667235091068730"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["import torchvision\n","\n","def show(tensors, figsize=(100,100), *args, **kwargs):\n","    grid_tensor = torchvision.utils.make_grid(tensors[:8], *args, **kwargs)\n","    grid_image = grid_tensor.permute(1,2,0)\n","    plt.figure(figsize=figsize)\n","    plt.imshow(grid_image)\n","    plt.xticks([])\n","    plt.yticks([])\n","    plt.show()\n","    plt.close()\n","\n","\n","def saveplot(tensors, name, figsize=(100,100), *args, **kwargs):\n","\tgrid_tensor = torchvision.utils.make_grid(tensors[:8], *args, **kwargs)\n","\tgrid_image=grid_tensor.permute(1,2,0)\n","\tplt.figure(figsize=figsize)\n","\tplt.imshow((grid_image))\n","\tplt.xticks([])\n","\tplt.yticks([])\n","\tplt.savefig(name, bbox_inches='tight')\n","\tplt.close()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["time: 13 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zPJ2Vn1Jp6CQ","colab_type":"code","outputId":"bb7d1749-58c6-4eb9-ce80-afacdf1d1bc6","executionInfo":{"status":"ok","timestamp":1590244653132,"user_tz":-330,"elapsed":7839,"user":{"displayName":"Suman Vamsi","photoUrl":"","userId":"17013667235091068730"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#sample = next(iter(trainloader))\n","#sample['maskK'].shape"],"execution_count":0,"outputs":[{"output_type":"stream","text":["time: 798 µs\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"bpfz_YoSeTqT","colab_type":"code","outputId":"77cc44c3-4e9d-4681-eba4-276ae773aea8","executionInfo":{"status":"ok","timestamp":1590244653133,"user_tz":-330,"elapsed":7834,"user":{"displayName":"Suman Vamsi","photoUrl":"","userId":"17013667235091068730"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#show(sample['bgK'])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["time: 480 µs\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VHQ1LQ-e5Q95","colab_type":"code","outputId":"6364a4a1-86f9-4e5f-fd19-47cea1554092","executionInfo":{"status":"ok","timestamp":1590244653134,"user_tz":-330,"elapsed":7830,"user":{"displayName":"Suman Vamsi","photoUrl":"","userId":"17013667235091068730"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#show(sample['bgfgK'])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["time: 791 µs\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8HW_iw9Eq8HI","colab_type":"code","outputId":"21f3046e-ee65-4fd8-944d-25fb67a1ce30","executionInfo":{"status":"ok","timestamp":1590244653135,"user_tz":-330,"elapsed":7827,"user":{"displayName":"Suman Vamsi","photoUrl":"","userId":"17013667235091068730"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#show(sample['maskK'])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["time: 962 µs\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"IUkH4AuPrEdb","colab_type":"code","outputId":"c6b5f3cb-2a12-4443-8a19-04781658edef","executionInfo":{"status":"ok","timestamp":1590244653138,"user_tz":-330,"elapsed":7825,"user":{"displayName":"Suman Vamsi","photoUrl":"","userId":"17013667235091068730"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#show(sample['depthK'])"],"execution_count":0,"outputs":[{"output_type":"stream","text":["time: 597 µs\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"57FZy1lA2Ae8","colab_type":"code","outputId":"e4dbbd36-40d6-4329-f503-582d60ccfea0","executionInfo":{"status":"ok","timestamp":1590244653139,"user_tz":-330,"elapsed":7822,"user":{"displayName":"Suman Vamsi","photoUrl":"","userId":"17013667235091068730"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["#del sample"],"execution_count":0,"outputs":[{"output_type":"stream","text":["time: 451 µs\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uuRtcMtohiCR","colab_type":"text"},"source":["# Model"]},{"cell_type":"markdown","metadata":{"id":"j-WStulzhk5i","colab_type":"text"},"source":["## Downsize"]},{"cell_type":"code","metadata":{"id":"7OrxtxtDrLQQ","colab_type":"code","outputId":"e5b9ca9c-405a-42c3-ebc0-04befe943624","executionInfo":{"status":"ok","timestamp":1590244653140,"user_tz":-330,"elapsed":7819,"user":{"displayName":"Suman Vamsi","photoUrl":"","userId":"17013667235091068730"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["class Downsize (nn.Module):\n","    def __init__(self, inchannels, outchannels):\n","        super (Downsize,self).__init__()\n","        self.c1 = nn.Conv2d(inchannels, outchannels, kernel_size=3, stride=2, padding = 1, bias=False)\n","        self.conv11 = nn.Conv2d(outchannels, outchannels, kernel_size=1, stride=1, bias=False)\n","        self.bn1=nn.BatchNorm2d(outchannels)\n","        self.relu=nn.ReLU()\n","\n","        self.c2= nn.Conv2d(outchannels, outchannels, kernel_size=3, stride=2, padding = 1, bias=False)\n","        self.conv21 = nn.Conv2d(outchannels, outchannels, kernel_size=1, stride=1, bias=False)\n","        self.bn2=nn.BatchNorm2d(outchannels)\n","\n","        self.dconv = nn.ConvTranspose2d(inchannels, outchannels,kernel_size=1, stride=2, bias=False)\n","    def forward(self,x):\n","        idchannel=self.dconv(x)\n","        x1=self.c1(x)\n","        x2=self.conv11(x1)\n","        x3=self.bn1(x2)\n","        x4=self.relu(x3)\n","        x5=self.c2(x4)\n","        x6=self.conv21(x5)\n","        x7=self.bn2(x6)\n","        x8=x7\n","        #x8=x7+idchannel\n","        x9=self.relu(x8)\n","        return x9\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["time: 36.2 ms\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"LeWz_8AVhnH9","colab_type":"text"},"source":["## upsize"]},{"cell_type":"code","metadata":{"id":"FdJKL54XtJlZ","colab_type":"code","outputId":"40401fee-ab12-4714-c6b4-bdf53ec6f4f9","executionInfo":{"status":"ok","timestamp":1590244653141,"user_tz":-330,"elapsed":7816,"user":{"displayName":"Suman Vamsi","photoUrl":"","userId":"17013667235091068730"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["class Upsize(nn.Module):\n","    def __init__(self,inchannels,outchannels):\n","        super(Upsize, self).__init__()\n","        self.c1=nn.Conv2d(outchannels, outchannels, kernel_size=3, padding=1,bias=False)\n","        self.conv11=nn.Conv2d(outchannels, outchannels, kernel_size=1, bias=False)\n","        self.bn1=nn.BatchNorm2d(outchannels)\n","        self.relu=nn.ReLU()\n","        self.c2=nn.Conv2d(outchannels, outchannels, kernel_size=3, padding=1,bias=False)\n","        self.conv21=nn.Conv2d(outchannels, outchannels, kernel_size=1, bias=False)\n","        self.bn2=nn.BatchNorm2d(outchannels)\n","\n","        self.dconv=nn.ConvTranspose2d(inchannels, outchannels,kernel_size=3, padding=1, bias=False)\n","\n","    def forward(self,x):\n","        idchannel=self.dconv(x)\n","        x1=self.c1(idchannel)\n","        x2=self.conv11(x1)\n","        x3=self.bn1(x2)\n","        x4=self.relu(x3)\n","        x5=self.c2(x4)\n","        x6=self.conv21(x5)\n","        x7=self.bn2(x6)\n","        x8=self.relu(x7)\n","        return x8\n","    "],"execution_count":0,"outputs":[{"output_type":"stream","text":["time: 21.6 ms\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"eNFr4u2ChovK","colab_type":"text"},"source":["## Depthmask"]},{"cell_type":"code","metadata":{"id":"SR4n7vtxtOjH","colab_type":"code","outputId":"e4fe1c12-474c-46b1-f6d9-badbc53e7c82","executionInfo":{"status":"ok","timestamp":1590244653142,"user_tz":-330,"elapsed":7813,"user":{"displayName":"Suman Vamsi","photoUrl":"","userId":"17013667235091068730"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["class DepthMask(nn.Module):\n","    def __init__(self):\n","        super(DepthMask, self).__init__()\n","\n","        self.c1=nn.Sequential(\n","            nn.Conv2d(6,64, kernel_size=7, stride=2, padding=3, bias=False),\n","            nn.BatchNorm2d(64),\n","            nn.ReLU()\n","        )\n","        self.maxpool=nn.MaxPool2d(3, stride=2, padding=1)\n","\n","        self.fdm1=Downsize(64,128)\n","        self.fdm2=Downsize(128,256)\n","        self.fdm3=Downsize(256,512)\n","        self.fdm4=Upsize(512,256)\n","        self.fdm5=Upsize(256,128)\n","        self.fdm6=Upsize(128,64)\n","        self.fdm7=Upsize(64,64)\n","        self.fdm8=Upsize(64,32)\n","        self.lasconv=nn.Sequential(\n","            nn.Conv2d(32,1,kernel_size=1, bias=False)\n","        )\n","        self.fdm4v=Upsize(512,256)\n","        self.fdm5v=Upsize(256,128)\n","        self.fdm6v=Upsize(128,64)\n","        self.fdm7v=Upsize(64,64)\n","        self.fdm8v=Upsize(64,32)\n","        self.lastconvd=nn.Sequential(\n","            nn.Conv2d(32,3,kernel_size=1, stride=1)\n","        )\n","\n","    def forward (self, x):\n","   \n","        #z = torch.cat([sample['bg'], sample['bgfg']], dim=1)\n","        #z=torch.cat([x,y], dim=1)\n","        x0=self.c1(x)\n","        x1=self.maxpool(x0)\n","        x2=self.fdm1(x1)\n","        x3=self.fdm2(x2)\n","        x4=self.fdm3(x3)\n","\n","        x4=nn.functional.interpolate(x4, scale_factor=4, mode='bilinear')\n","        x5=self.fdm4(x4)\n","        #print('x3:',x3.shape)\n","        #print('x4:',x4.shape)\n","        x5+=x3\n","        x5=nn.functional.interpolate(x5, scale_factor=7, mode='bilinear')\n","        x6=self.fdm5(x5)\n","        x2=nn.functional.interpolate(x2, scale_factor=2, mode='bilinear')\n","        #print('x6:',x6.shape)\n","        #print('x2:',x2.shape)\n","        \n","        x6+=x2\n","        x6=nn.functional.interpolate(x6, scale_factor=2, mode='bilinear')\n","        x7=self.fdm6(x6)\n","        x7+=x1\n","        x7=nn.functional.interpolate(x7, scale_factor=2, mode='bilinear')\n","        x8=self.fdm7(x7)\n","        x8+=x0\n","        x8=nn.functional.interpolate(x8, scale_factor=2, mode='bilinear')\n","        x9=self.fdm8(x8)\n","        x10=self.lasconv(x9)\n","\n","\n","        x5v=self.fdm4v(x4)\n","        x5v+=x3\n","        x5v=nn.functional.interpolate(x5v, scale_factor=7, mode='bilinear')\n","        x6v=self.fdm5(x5v)\n","        #print('x6v shape:',x6v.shape)\n","        #print('x2 shape:',x2.shape)\n","        x6v+=x2\n","        x6v=nn.functional.interpolate(x6v, scale_factor=2, mode='bilinear')\n","        x7v=self.fdm6(x6v)\n","        x7v=nn.functional.interpolate(x7v, scale_factor=2, mode='bilinear')\n","        x8v=self.fdm7(x7v)\n","        x8v+=x0\n","        x8v=nn.functional.interpolate(x8v, scale_factor=2, mode='bilinear')\n","        x9v=self.fdm8(x8v)\n","        x10Depth=self.lastconvd(x9v)\n","        return (x10, x10Depth)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["time: 69.5 ms\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"q4cvyg1ahsoj","colab_type":"text"},"source":["## Loss nd optimizer"]},{"cell_type":"code","metadata":{"id":"V4eFbkEQtVPc","colab_type":"code","outputId":"922d47ee-e034-43d5-9266-f80a80db70b9","executionInfo":{"status":"ok","timestamp":1590244655966,"user_tz":-330,"elapsed":10633,"user":{"displayName":"Suman Vamsi","photoUrl":"","userId":"17013667235091068730"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["net = DepthMask()\n","\n","use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","print(device)\n","\n","from torchsummary import summary\n","# Display Model Summary\n","model = net.to(device)\n","summary(model, input_size=(6, 224, 224))\n","\n","criterion = nn.BCEWithLogitsLoss() #SSIM( 3, reduction =\"mean\")\n","optimizer = torch.optim.SGD(model.parameters(),lr= 0.01, momentum=0.9, weight_decay=1e-5)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["cuda\n","----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","            Conv2d-1         [-1, 64, 112, 112]          18,816\n","       BatchNorm2d-2         [-1, 64, 112, 112]             128\n","              ReLU-3         [-1, 64, 112, 112]               0\n","         MaxPool2d-4           [-1, 64, 56, 56]               0\n","   ConvTranspose2d-5        [-1, 128, 111, 111]           8,192\n","            Conv2d-6          [-1, 128, 28, 28]          73,728\n","            Conv2d-7          [-1, 128, 28, 28]          16,384\n","       BatchNorm2d-8          [-1, 128, 28, 28]             256\n","              ReLU-9          [-1, 128, 28, 28]               0\n","           Conv2d-10          [-1, 128, 14, 14]         147,456\n","           Conv2d-11          [-1, 128, 14, 14]          16,384\n","      BatchNorm2d-12          [-1, 128, 14, 14]             256\n","             ReLU-13          [-1, 128, 14, 14]               0\n","         Downsize-14          [-1, 128, 14, 14]               0\n","  ConvTranspose2d-15          [-1, 256, 27, 27]          32,768\n","           Conv2d-16            [-1, 256, 7, 7]         294,912\n","           Conv2d-17            [-1, 256, 7, 7]          65,536\n","      BatchNorm2d-18            [-1, 256, 7, 7]             512\n","             ReLU-19            [-1, 256, 7, 7]               0\n","           Conv2d-20            [-1, 256, 4, 4]         589,824\n","           Conv2d-21            [-1, 256, 4, 4]          65,536\n","      BatchNorm2d-22            [-1, 256, 4, 4]             512\n","             ReLU-23            [-1, 256, 4, 4]               0\n","         Downsize-24            [-1, 256, 4, 4]               0\n","  ConvTranspose2d-25            [-1, 512, 7, 7]         131,072\n","           Conv2d-26            [-1, 512, 2, 2]       1,179,648\n","           Conv2d-27            [-1, 512, 2, 2]         262,144\n","      BatchNorm2d-28            [-1, 512, 2, 2]           1,024\n","             ReLU-29            [-1, 512, 2, 2]               0\n","           Conv2d-30            [-1, 512, 1, 1]       2,359,296\n","           Conv2d-31            [-1, 512, 1, 1]         262,144\n","      BatchNorm2d-32            [-1, 512, 1, 1]           1,024\n","             ReLU-33            [-1, 512, 1, 1]               0\n","         Downsize-34            [-1, 512, 1, 1]               0\n","  ConvTranspose2d-35            [-1, 256, 4, 4]       1,179,648\n","           Conv2d-36            [-1, 256, 4, 4]         589,824\n","           Conv2d-37            [-1, 256, 4, 4]          65,536\n","      BatchNorm2d-38            [-1, 256, 4, 4]             512\n","             ReLU-39            [-1, 256, 4, 4]               0\n","           Conv2d-40            [-1, 256, 4, 4]         589,824\n","           Conv2d-41            [-1, 256, 4, 4]          65,536\n","      BatchNorm2d-42            [-1, 256, 4, 4]             512\n","             ReLU-43            [-1, 256, 4, 4]               0\n","           Upsize-44            [-1, 256, 4, 4]               0\n","  ConvTranspose2d-45          [-1, 128, 28, 28]         294,912\n","           Conv2d-46          [-1, 128, 28, 28]         147,456\n","           Conv2d-47          [-1, 128, 28, 28]          16,384\n","      BatchNorm2d-48          [-1, 128, 28, 28]             256\n","             ReLU-49          [-1, 128, 28, 28]               0\n","           Conv2d-50          [-1, 128, 28, 28]         147,456\n","           Conv2d-51          [-1, 128, 28, 28]          16,384\n","      BatchNorm2d-52          [-1, 128, 28, 28]             256\n","             ReLU-53          [-1, 128, 28, 28]               0\n","           Upsize-54          [-1, 128, 28, 28]               0\n","  ConvTranspose2d-55           [-1, 64, 56, 56]          73,728\n","           Conv2d-56           [-1, 64, 56, 56]          36,864\n","           Conv2d-57           [-1, 64, 56, 56]           4,096\n","      BatchNorm2d-58           [-1, 64, 56, 56]             128\n","             ReLU-59           [-1, 64, 56, 56]               0\n","           Conv2d-60           [-1, 64, 56, 56]          36,864\n","           Conv2d-61           [-1, 64, 56, 56]           4,096\n","      BatchNorm2d-62           [-1, 64, 56, 56]             128\n","             ReLU-63           [-1, 64, 56, 56]               0\n","           Upsize-64           [-1, 64, 56, 56]               0\n","  ConvTranspose2d-65         [-1, 64, 112, 112]          36,864\n","           Conv2d-66         [-1, 64, 112, 112]          36,864\n","           Conv2d-67         [-1, 64, 112, 112]           4,096\n","      BatchNorm2d-68         [-1, 64, 112, 112]             128\n","             ReLU-69         [-1, 64, 112, 112]               0\n","           Conv2d-70         [-1, 64, 112, 112]          36,864\n","           Conv2d-71         [-1, 64, 112, 112]           4,096\n","      BatchNorm2d-72         [-1, 64, 112, 112]             128\n","             ReLU-73         [-1, 64, 112, 112]               0\n","           Upsize-74         [-1, 64, 112, 112]               0\n","  ConvTranspose2d-75         [-1, 32, 224, 224]          18,432\n","           Conv2d-76         [-1, 32, 224, 224]           9,216\n","           Conv2d-77         [-1, 32, 224, 224]           1,024\n","      BatchNorm2d-78         [-1, 32, 224, 224]              64\n","             ReLU-79         [-1, 32, 224, 224]               0\n","           Conv2d-80         [-1, 32, 224, 224]           9,216\n","           Conv2d-81         [-1, 32, 224, 224]           1,024\n","      BatchNorm2d-82         [-1, 32, 224, 224]              64\n","             ReLU-83         [-1, 32, 224, 224]               0\n","           Upsize-84         [-1, 32, 224, 224]               0\n","           Conv2d-85          [-1, 1, 224, 224]              32\n","  ConvTranspose2d-86            [-1, 256, 4, 4]       1,179,648\n","           Conv2d-87            [-1, 256, 4, 4]         589,824\n","           Conv2d-88            [-1, 256, 4, 4]          65,536\n","      BatchNorm2d-89            [-1, 256, 4, 4]             512\n","             ReLU-90            [-1, 256, 4, 4]               0\n","           Conv2d-91            [-1, 256, 4, 4]         589,824\n","           Conv2d-92            [-1, 256, 4, 4]          65,536\n","      BatchNorm2d-93            [-1, 256, 4, 4]             512\n","             ReLU-94            [-1, 256, 4, 4]               0\n","           Upsize-95            [-1, 256, 4, 4]               0\n","  ConvTranspose2d-96          [-1, 128, 28, 28]         294,912\n","           Conv2d-97          [-1, 128, 28, 28]         147,456\n","           Conv2d-98          [-1, 128, 28, 28]          16,384\n","      BatchNorm2d-99          [-1, 128, 28, 28]             256\n","            ReLU-100          [-1, 128, 28, 28]               0\n","          Conv2d-101          [-1, 128, 28, 28]         147,456\n","          Conv2d-102          [-1, 128, 28, 28]          16,384\n","     BatchNorm2d-103          [-1, 128, 28, 28]             256\n","            ReLU-104          [-1, 128, 28, 28]               0\n","          Upsize-105          [-1, 128, 28, 28]               0\n"," ConvTranspose2d-106           [-1, 64, 56, 56]          73,728\n","          Conv2d-107           [-1, 64, 56, 56]          36,864\n","          Conv2d-108           [-1, 64, 56, 56]           4,096\n","     BatchNorm2d-109           [-1, 64, 56, 56]             128\n","            ReLU-110           [-1, 64, 56, 56]               0\n","          Conv2d-111           [-1, 64, 56, 56]          36,864\n","          Conv2d-112           [-1, 64, 56, 56]           4,096\n","     BatchNorm2d-113           [-1, 64, 56, 56]             128\n","            ReLU-114           [-1, 64, 56, 56]               0\n","          Upsize-115           [-1, 64, 56, 56]               0\n"," ConvTranspose2d-116         [-1, 64, 112, 112]          36,864\n","          Conv2d-117         [-1, 64, 112, 112]          36,864\n","          Conv2d-118         [-1, 64, 112, 112]           4,096\n","     BatchNorm2d-119         [-1, 64, 112, 112]             128\n","            ReLU-120         [-1, 64, 112, 112]               0\n","          Conv2d-121         [-1, 64, 112, 112]          36,864\n","          Conv2d-122         [-1, 64, 112, 112]           4,096\n","     BatchNorm2d-123         [-1, 64, 112, 112]             128\n","            ReLU-124         [-1, 64, 112, 112]               0\n","          Upsize-125         [-1, 64, 112, 112]               0\n"," ConvTranspose2d-126         [-1, 32, 224, 224]          18,432\n","          Conv2d-127         [-1, 32, 224, 224]           9,216\n","          Conv2d-128         [-1, 32, 224, 224]           1,024\n","     BatchNorm2d-129         [-1, 32, 224, 224]              64\n","            ReLU-130         [-1, 32, 224, 224]               0\n","          Conv2d-131         [-1, 32, 224, 224]           9,216\n","          Conv2d-132         [-1, 32, 224, 224]           1,024\n","     BatchNorm2d-133         [-1, 32, 224, 224]              64\n","            ReLU-134         [-1, 32, 224, 224]               0\n","          Upsize-135         [-1, 32, 224, 224]               0\n","          Conv2d-136          [-1, 3, 224, 224]              99\n","================================================================\n","Total params: 12,384,643\n","Trainable params: 12,384,643\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 1.15\n","Forward/backward pass size (MB): 453.79\n","Params size (MB): 47.24\n","Estimated Total Size (MB): 502.18\n","----------------------------------------------------------------\n","time: 2.98 s\n"],"name":"stdout"},{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:2973: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n","  \"See the documentation of nn.Upsample for details.\".format(mode))\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"pvAHJI3ox7Of"},"source":["## train : Modified"]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"6960af10-37a7-4fc2-ce07-5c515b69100b","executionInfo":{"status":"ok","timestamp":1590244655968,"user_tz":-330,"elapsed":10631,"user":{"displayName":"Suman Vamsi","photoUrl":"","userId":"17013667235091068730"}},"id":"k-SEP3B4x7O5","colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%matplotlib inline\n","import matplotlib.pyplot as plt\n","from tqdm import tqdm\n","import gc\n","\n","from lib.modelSaveNLoad import *\n","\n","def train(model,criterion,device,trainloader,optimizer,epochs):\n","    train_loss_mask, train_loss_depth = [],[]\n","    model.train()\n","    pbar = tqdm(trainloader)\n","    ### Train #####\n","    ################\n","    for batch_idx, data in enumerate(pbar):\n","        #print('Batch ID: ',batch_idx+1)\n","        gc.collect()\n","        optimizer.zero_grad()\n","        bg    = data['bgK'].to(device)\n","        bgfg  = data['bgfgK'].to(device)\n","        maskGt  = data['maskK'].to(device)\n","        depthGt = data['depthK'].to(device)\n","        ###########\n","        try:\n","            z=torch.cat([bgfg,bg], dim=1)\n","            (maskPred,depthPred) = model(z)  #(mask,depth)\n","        except RuntimeError as e:\n","            if 'CUDA out of memory' in str(e):\n","                print('| WARNING: ran out of memory, retrying batch',sys.stdout)\n","                print('Net parameters are : {}'.format(net.parameters()))\n","                #set_trace()\n","                sys.stdout.flush()\n","                for p in net.parameters():\n","                    if p.grad is not None:\n","                        del p.grad  # free some memory\n","                torch.cuda.empty_cache()\n","                (maskPred,depthPred) = model(z)\n","            else:\n","                raise e\n","        ############\n","        loss_mask = criterion(maskPred,maskGt)\n","        train_loss_mask.append(loss_mask)\n","        loss_depth =criterion(depthPred,depthGt)\n","        train_loss_depth.append(loss_depth)\n","        loss = 2*loss_mask+loss_depth        \n","        loss_min = loss\n","        pbar.set_description(desc= \"Overall Loss={:.4f} Mask loss={:.2f} Depth loss={:.2f}\".format(loss.item(),loss_mask.item(), loss_depth.item()))\n","        loss.backward()\n","        optimizer.step()\n","        ###########\n","        ### Delete scope variables\n","        del bg, bgfg,maskGt,depthGt\n","        \n","        if batch_idx %50 == 0:\n","            print('batch_idx: {}'.format(batch_idx))\n","            print('loss: {}'.format(loss))\n","            print('Train Epoch: {}  [{}/{}  ({:.0f}%)]\\tLoss:{:.6f}'.format(\n","                epochs,batch_idx*len(data),len(trainloader.dataset),\n","                100.*batch_idx/len(trainloader),loss.item()))\n","            show(maskPred.detach().cpu())\n","            show(depthPred.detach().cpu())\n","            del maskPred,depthPred\n","    print('After compleation of training at epoch :{}'.format(batch_idx))\n","    show(maskPred.detach().cpu())\n","    show(depthPred.detach().cpu())\n","    del maskPred,depthPred\n","    # create checkpoint variable and add important data\n","    checkpoint = {\n","        'epoch': epochs,\n","        'valid_loss_min': loss,\n","        'state_dict': model.state_dict(),\n","        'optimizer': optimizer.state_dict(),\n","    }\n","\n","    return checkpoint\n","    '''\n","    # save checkpoint\n","    save_ckp(checkpoint, False, checkpoint_path='batch_1_chkp.pt', best_model_path='batch_1_best.pt')\n","    ## TODO: save the model if validation loss has decreased\n","    if loss <= loss_min:\n","        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(valid_loss_min,valid_loss))\n","        # save checkpoint as best model\n","        save_ckp(checkpoint, True, checkpoint_path='batch_1_chkp.pt', best_model_path='batch_1_best.pt')\n","        loss_min = loss\n","    '''\n","        \n","def test(model,criterion,device,testloader,epochs):\n","    test_loss_mask, test_loss_depth,test_loss = [],[],[]\n","    model.eval()\n","    pbar = tqdm(testloader)\n","    for batch_idx, data in enumerate(pbar):\n","        with torch.no_grad():\n","            #print('Batch ID: ',batch_idx+1)\n","            gc.collect()\n","            #optimizer.zero_grad()\n","            bg      = data['bgK'].to(device)\n","            bgfg    = data['bgfgK'].to(device)\n","            maskGt  = data['maskK'].to(device)\n","            depthGt = data['depthK'].to(device)\n","            ###########\n","            try:\n","                z=torch.cat([bgfg,bg], dim=1)\n","                (maskPred,depthPred) = model(z)  #(mask,depth)\n","            except RuntimeError as e:\n","                if 'CUDA out of memory' in str(e):\n","                    print('| WARNING: ran out of memory, retrying batch',sys.stdout)\n","                    print('Net parameters are : {}'.format(net.parameters()))\n","                    #set_trace()\n","                    sys.stdout.flush()\n","                    for p in net.parameters():\n","                        if p.grad is not None:\n","                            del p.grad  # free some memory\n","                    torch.cuda.empty_cache()\n","                    (maskPred,depthPred) = model(z)\n","                else:\n","                    raise e\n","            ############\n","            loss_mask = criterion(maskPred,maskGt).item()\n","            test_loss_mask.append(loss_mask)\n","            loss_depth =criterion(depthPred,depthGt).item()\n","            test_loss_depth.append(loss_depth)\n","            loss = 2*loss_mask+loss_depth \n","            test_loss.append(loss)       \n","            #pbar.set_description(desc= \"Overall Loss={:.4f} Mask loss={:.2f} Depth loss={:.2f}\".format(loss.item(),loss_mask.item(), loss_depth.item()))\n","            #pbar.set_description(desc= \"Overall Loss={:.4f} Mask loss={:.2f} Depth loss={:.2f}\".format(loss.item(),loss_mask.item(), loss_depth.item()))\n","            if batch_idx %50 == 0:\n","                print('batch_idx: {}'.format(batch_idx))\n","                print('loss: {}'.format(loss))\n","                print('Train Epoch: {}  [{}/{}  ({:.0f}%)]\\tLoss:{:.6f}'.format(\n","                    epochs,batch_idx*len(data),len(trainloader.dataset),\n","                    100.*batch_idx/len(trainloader),loss.item()))\n","                show(maskPred.detach().cpu())\n","                show(depthPred.detach().cpu())\n","       \n","                i = batch_idx\n","                print('inside save plot')\n","                saveplot(maskPred.detach().cpu(),'/content/'+str(epoch)+'_'+str()+'_predicted_mask.jpg')\n","                saveplot(maskGt.detach().cpu(),'/content/'+str(epoch)+'_'+str(i)+'_actual_mask.jpg')\n","                saveplot(depthPred.detach().cpu(),'/content/'+str(epoch)+'_'+str(i)+'_predicted_depth.jpg')\n","                saveplot(depthGt.detach().cpu(),'/content/'+str(epoch)+'_'+str(i)+'_actual_depth.jpg')\n","                \n","                del bg, bgfg,maskGt,depthGt\n","    #set_trace()\n","    print('\\nTest set: Avg loss: {:.4f}, Mask Loss: {:.2f}, Depth Loss: {:.2f}\\n'.format(np.mean(test_loss), np.mean(test_loss_mask), np.mean(test_loss_depth)))\n","    print('After compleation of Test at epoch :{}'.format(batch_idx))\n","    show(maskPred.detach().cpu())\n","    show(depthPred.detach().cpu())\n","    del maskPred,depthPred"],"execution_count":0,"outputs":[{"output_type":"stream","text":["time: 164 ms\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"H9sq9VStfgP3","colab_type":"code","outputId":"9439d292-d3a1-47fa-adab-9027bf3218e3","executionInfo":{"status":"ok","timestamp":1590245332925,"user_tz":-330,"elapsed":687578,"user":{"displayName":"Suman Vamsi","photoUrl":"","userId":"17013667235091068730"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1bhIXW1iH2lmpzFPrFagIej05fVYD9RD5"}},"source":["from lib.modelSaveNLoad import *\n","\n","EPOCHS = 5\n","loss = 1e+5\n","for epoch in range(EPOCHS):\n","    print(\"EPOCH:\", epoch)\n","    checkpoint = train(model, criterion, device, trainloader,optimizer, epochs=epoch)\n","    #save_ckp(checkpoint, False, checkpoint_path='batch_1_chkp.pt', best_model_path='batch_1_best.pt')\n","    ## TODO: save the model if validation loss has decreased\n","    #set_trace()\n","    if checkpoint['valid_loss_min'].item() < loss:\n","        print('Validation loss decreased ({:.6f} --> {:.6f}).  Saving model ...'.format(loss,checkpoint['valid_loss_min'].item()))\n","        # save checkpoint as best model\n","        torch.save(checkpoint,r'/content/drive/My Drive/EVA4/S15/modelWeights/checkpoint/batch_best.ckp.pt')\n","        #save_ckp(checkpoint, True, checkpoint_path='batch_1_chkp.pt', best_model_path='batch_1_best.pt')\n","        loss = checkpoint['valid_loss_min'].item()\n","    test(model,criterion,device,testloader,epoch)\n","\n","    "],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]},{"cell_type":"code","metadata":{"id":"NfSySOiRC6R4","colab_type":"code","colab":{}},"source":["\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_eV2OkYKgEHm","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}